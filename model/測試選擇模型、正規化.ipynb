{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "測試Useful Fitting 透過tf.data.Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPCjHfsNjVqy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7ORvyeZjmX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a42db4d-8005-49ad-bbf5-8c468220c183"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 12s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxHDwi6tmsJD"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxD-ISuDju1L",
        "outputId": "c5a5414b-36a7-4b72-d3af-6bd9df796e21"
      },
      "source": [
        "# 裝回tf.data.Dataset\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "ds_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((32, 32, 3), (10,)), types: (tf.float64, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85nDPeKdj7JH",
        "outputId": "601e0224-17bb-4de7-9fcb-f8e199e5dc62"
      },
      "source": [
        "# 取得單一batch\n",
        "\n",
        "one_batch = ds_train.batch(batch_size=128).take(1)\n",
        "\n",
        "for (x, y) in one_batch:\n",
        "    print(x.shape)\n",
        "    print(y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 32, 32, 3)\n",
            "(128, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BkrcF8hkTsr",
        "outputId": "c71f265b-af1e-4a94-8e2a-216bc32ce7fb"
      },
      "source": [
        "# 透過模型去擬合\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics='acc'\n",
        ")\n",
        "\n",
        "model.fit(one_batch.repeat(),epochs=20, steps_per_epoch=100, validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 31s 28ms/step - loss: 2.1611 - acc: 0.2389 - val_loss: 2.2715 - val_acc: 0.1643\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 1.8628 - acc: 0.3634 - val_loss: 2.1789 - val_acc: 0.2044\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 1.4618 - acc: 0.5195 - val_loss: 2.2548 - val_acc: 0.2165\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 1.0719 - acc: 0.7159 - val_loss: 2.4398 - val_acc: 0.2194\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.7487 - acc: 0.8519 - val_loss: 2.6736 - val_acc: 0.2240\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.5087 - acc: 0.9497 - val_loss: 2.9279 - val_acc: 0.2254\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.3414 - acc: 0.9835 - val_loss: 3.1942 - val_acc: 0.2281\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.2298 - acc: 0.9891 - val_loss: 3.4471 - val_acc: 0.2298\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.1569 - acc: 0.9933 - val_loss: 3.6865 - val_acc: 0.2299\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.1108 - acc: 1.0000 - val_loss: 3.8975 - val_acc: 0.2287\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0812 - acc: 1.0000 - val_loss: 4.0885 - val_acc: 0.2291\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0616 - acc: 1.0000 - val_loss: 4.2611 - val_acc: 0.2287\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 4.4153 - val_acc: 0.2285\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 4.5598 - val_acc: 0.2282\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 4.6889 - val_acc: 0.2286\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 4.8094 - val_acc: 0.2283\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 4.9218 - val_acc: 0.2281\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 5.0262 - val_acc: 0.2286\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 5.1255 - val_acc: 0.2288\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 5.2187 - val_acc: 0.2285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7bef33fb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-nkVvhlbry",
        "outputId": "a724459f-08e6-4602-992c-4bd6a4453700"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 2,442\n",
            "Trainable params: 2,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jxDACgYn1-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1a2274-9fc8-476f-cfa9-cf6c1a84ca66"
      },
      "source": [
        "# 上面是的確適合圖片的神經網路，那麼讓我們看看另外一個神經網路，單純用MLP去做\n",
        "\n",
        "model_mlp = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_mlp.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['acc']\n",
        ")\n",
        "model_mlp.fit(\n",
        "    x=one_batch.repeat(),\n",
        "    epochs=20,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 3s 21ms/step - loss: 1.4518 - acc: 0.5409 - val_loss: 2.5513 - val_acc: 0.2125\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.4192 - acc: 0.9570 - val_loss: 3.2334 - val_acc: 0.2162\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.1080 - acc: 1.0000 - val_loss: 3.8863 - val_acc: 0.2147\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0414 - acc: 1.0000 - val_loss: 4.3444 - val_acc: 0.2158\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 4.6720 - val_acc: 0.2145\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 4.9287 - val_acc: 0.2143\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 5.1437 - val_acc: 0.2144\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 5.3262 - val_acc: 0.2144\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 5.4875 - val_acc: 0.2142\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 5.6316 - val_acc: 0.2143\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 5.7622 - val_acc: 0.2141\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 5.8814 - val_acc: 0.2141\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 5.9929 - val_acc: 0.2145\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.0959 - val_acc: 0.2141\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.1922 - val_acc: 0.2140\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.2840 - val_acc: 0.2135\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 6.3700 - val_acc: 0.2134\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 1s 13ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 6.4530 - val_acc: 0.2136\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 6.5320 - val_acc: 0.2135\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 8.9740e-04 - acc: 1.0000 - val_loss: 6.6065 - val_acc: 0.2135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b8d93c250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYbq2fYm3_s0",
        "outputId": "1c1af260-cca6-49a2-a76b-674ec2056988"
      },
      "source": [
        "model_mlp.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                98336     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 98,666\n",
            "Trainable params: 98,666\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDdgxLj1n9Ag"
      },
      "source": [
        "> 透過single_batch去測試模型fit能力，雖然模型不大，但fit能力足夠，但很顯然general是差的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcnolMZaoNDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6899bf-304c-4807-a94f-f72d02b7f880"
      },
      "source": [
        "# 接著，去fit整個dataset\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.2186 - acc: 0.3148 - val_loss: 2.1223 - val_acc: 0.3189\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.0652 - acc: 0.3299 - val_loss: 2.0113 - val_acc: 0.3388\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.9690 - acc: 0.3429 - val_loss: 1.9278 - val_acc: 0.3555\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.9119 - acc: 0.3530 - val_loss: 1.8722 - val_acc: 0.3636\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.8627 - acc: 0.3625 - val_loss: 1.8305 - val_acc: 0.3742\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.8249 - acc: 0.3702 - val_loss: 1.8182 - val_acc: 0.3783\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7935 - acc: 0.3780 - val_loss: 1.7691 - val_acc: 0.3853\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.7700 - acc: 0.3835 - val_loss: 1.7528 - val_acc: 0.3864\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7454 - acc: 0.3890 - val_loss: 1.7288 - val_acc: 0.3963\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7257 - acc: 0.3935 - val_loss: 1.7091 - val_acc: 0.4012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b8ae32d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGwcmxMA4sVz",
        "outputId": "dc693c1f-0511-46c7-c724-5577f589904d"
      },
      "source": [
        "model_mlp.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.4048 - acc: 0.1007 - val_loss: 2.3028 - val_acc: 0.1000\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2946 - acc: 0.1067 - val_loss: 2.2797 - val_acc: 0.1323\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.2388 - acc: 0.1478 - val_loss: 2.1795 - val_acc: 0.1716\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.1388 - acc: 0.1754 - val_loss: 2.1051 - val_acc: 0.1765\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0929 - acc: 0.1754 - val_loss: 2.0801 - val_acc: 0.1754\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0709 - acc: 0.1812 - val_loss: 2.0617 - val_acc: 0.1797\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0592 - acc: 0.1786 - val_loss: 2.0533 - val_acc: 0.1836\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0530 - acc: 0.1863 - val_loss: 2.0529 - val_acc: 0.1828\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0479 - acc: 0.1891 - val_loss: 2.0447 - val_acc: 0.1844\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0405 - acc: 0.1895 - val_loss: 2.0466 - val_acc: 0.1930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b88de25d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdWhWyLr41at"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egGoLt_K5eei"
      },
      "source": [
        "> 這邊用全部資料可以發現，CNN模型雖然參數小，但是用正確的方式學習到參數，雖然只跑了10個epoch不足以達到適用的效果，但整體趨勢樂觀。而MLP則是效果不好，但也是有學習的趨勢。\n",
        "\n",
        "> 那我們再試看看，多一點epoch會如何(因為兩個模型可以看到都在學習中)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsOcA5wQ56ev",
        "outputId": "ace68b8a-9372-4d08-a0ca-f11d88dd80a9"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=90, validation_data=(x_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.7074 - acc: 0.3995 - val_loss: 1.7087 - val_acc: 0.3979\n",
            "Epoch 2/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6940 - acc: 0.4029 - val_loss: 1.6824 - val_acc: 0.4105\n",
            "Epoch 3/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6771 - acc: 0.4091 - val_loss: 1.6714 - val_acc: 0.4155\n",
            "Epoch 4/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6634 - acc: 0.4126 - val_loss: 1.6684 - val_acc: 0.4133\n",
            "Epoch 5/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6526 - acc: 0.4163 - val_loss: 1.6500 - val_acc: 0.4200\n",
            "Epoch 6/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6415 - acc: 0.4195 - val_loss: 1.6378 - val_acc: 0.4225\n",
            "Epoch 7/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.6321 - acc: 0.4233 - val_loss: 1.6447 - val_acc: 0.4230\n",
            "Epoch 8/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6225 - acc: 0.4251 - val_loss: 1.6369 - val_acc: 0.4254\n",
            "Epoch 9/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6132 - acc: 0.4294 - val_loss: 1.6268 - val_acc: 0.4233\n",
            "Epoch 10/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.6085 - acc: 0.4305 - val_loss: 1.6294 - val_acc: 0.4264\n",
            "Epoch 11/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5987 - acc: 0.4335 - val_loss: 1.6038 - val_acc: 0.4368\n",
            "Epoch 12/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5950 - acc: 0.4334 - val_loss: 1.6316 - val_acc: 0.4312\n",
            "Epoch 13/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5898 - acc: 0.4369 - val_loss: 1.5886 - val_acc: 0.4395\n",
            "Epoch 14/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5817 - acc: 0.4393 - val_loss: 1.5938 - val_acc: 0.4336\n",
            "Epoch 15/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5768 - acc: 0.4402 - val_loss: 1.5801 - val_acc: 0.4433\n",
            "Epoch 16/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5705 - acc: 0.4447 - val_loss: 1.5821 - val_acc: 0.4392\n",
            "Epoch 17/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5663 - acc: 0.4459 - val_loss: 1.5706 - val_acc: 0.4470\n",
            "Epoch 18/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5617 - acc: 0.4481 - val_loss: 1.5845 - val_acc: 0.4401\n",
            "Epoch 19/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5574 - acc: 0.4475 - val_loss: 1.5732 - val_acc: 0.4455\n",
            "Epoch 20/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5543 - acc: 0.4501 - val_loss: 1.5782 - val_acc: 0.4428\n",
            "Epoch 21/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5489 - acc: 0.4539 - val_loss: 1.5745 - val_acc: 0.4426\n",
            "Epoch 22/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5463 - acc: 0.4543 - val_loss: 1.5605 - val_acc: 0.4483\n",
            "Epoch 23/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5432 - acc: 0.4553 - val_loss: 1.5648 - val_acc: 0.4470\n",
            "Epoch 24/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5383 - acc: 0.4553 - val_loss: 1.5535 - val_acc: 0.4498\n",
            "Epoch 25/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5334 - acc: 0.4575 - val_loss: 1.5569 - val_acc: 0.4460\n",
            "Epoch 26/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5322 - acc: 0.4589 - val_loss: 1.5570 - val_acc: 0.4506\n",
            "Epoch 27/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5286 - acc: 0.4611 - val_loss: 1.5475 - val_acc: 0.4544\n",
            "Epoch 28/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5278 - acc: 0.4612 - val_loss: 1.5458 - val_acc: 0.4509\n",
            "Epoch 29/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5217 - acc: 0.4608 - val_loss: 1.5398 - val_acc: 0.4542\n",
            "Epoch 30/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5195 - acc: 0.4632 - val_loss: 1.5329 - val_acc: 0.4556\n",
            "Epoch 31/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5192 - acc: 0.4626 - val_loss: 1.5470 - val_acc: 0.4497\n",
            "Epoch 32/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5142 - acc: 0.4652 - val_loss: 1.5373 - val_acc: 0.4560\n",
            "Epoch 33/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5142 - acc: 0.4650 - val_loss: 1.5288 - val_acc: 0.4594\n",
            "Epoch 34/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5101 - acc: 0.4661 - val_loss: 1.5489 - val_acc: 0.4502\n",
            "Epoch 35/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5082 - acc: 0.4672 - val_loss: 1.5414 - val_acc: 0.4552\n",
            "Epoch 36/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5073 - acc: 0.4678 - val_loss: 1.5294 - val_acc: 0.4653\n",
            "Epoch 37/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5042 - acc: 0.4677 - val_loss: 1.5295 - val_acc: 0.4623\n",
            "Epoch 38/90\n",
            "391/391 [==============================] - 56s 144ms/step - loss: 1.5017 - acc: 0.4687 - val_loss: 1.5212 - val_acc: 0.4615\n",
            "Epoch 39/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5002 - acc: 0.4708 - val_loss: 1.5118 - val_acc: 0.4656\n",
            "Epoch 40/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4962 - acc: 0.4723 - val_loss: 1.5225 - val_acc: 0.4640\n",
            "Epoch 41/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4980 - acc: 0.4708 - val_loss: 1.5225 - val_acc: 0.4645\n",
            "Epoch 42/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4951 - acc: 0.4727 - val_loss: 1.5259 - val_acc: 0.4619\n",
            "Epoch 43/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4928 - acc: 0.4701 - val_loss: 1.5136 - val_acc: 0.4686\n",
            "Epoch 44/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4885 - acc: 0.4752 - val_loss: 1.5093 - val_acc: 0.4663\n",
            "Epoch 45/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4885 - acc: 0.4759 - val_loss: 1.5104 - val_acc: 0.4681\n",
            "Epoch 46/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4862 - acc: 0.4760 - val_loss: 1.5046 - val_acc: 0.4693\n",
            "Epoch 47/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4851 - acc: 0.4747 - val_loss: 1.5109 - val_acc: 0.4673\n",
            "Epoch 48/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4839 - acc: 0.4770 - val_loss: 1.5025 - val_acc: 0.4654\n",
            "Epoch 49/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4811 - acc: 0.4782 - val_loss: 1.5066 - val_acc: 0.4710\n",
            "Epoch 50/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4798 - acc: 0.4794 - val_loss: 1.4933 - val_acc: 0.4732\n",
            "Epoch 51/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4770 - acc: 0.4783 - val_loss: 1.4962 - val_acc: 0.4715\n",
            "Epoch 52/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4768 - acc: 0.4793 - val_loss: 1.5044 - val_acc: 0.4733\n",
            "Epoch 53/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4745 - acc: 0.4809 - val_loss: 1.4904 - val_acc: 0.4738\n",
            "Epoch 54/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4730 - acc: 0.4808 - val_loss: 1.4992 - val_acc: 0.4734\n",
            "Epoch 55/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4704 - acc: 0.4810 - val_loss: 1.5058 - val_acc: 0.4645\n",
            "Epoch 56/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4705 - acc: 0.4837 - val_loss: 1.5002 - val_acc: 0.4694\n",
            "Epoch 57/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4672 - acc: 0.4837 - val_loss: 1.4914 - val_acc: 0.4715\n",
            "Epoch 58/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4667 - acc: 0.4833 - val_loss: 1.4945 - val_acc: 0.4718\n",
            "Epoch 59/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4678 - acc: 0.4829 - val_loss: 1.4913 - val_acc: 0.4721\n",
            "Epoch 60/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4650 - acc: 0.4851 - val_loss: 1.4867 - val_acc: 0.4728\n",
            "Epoch 61/90\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.4600 - acc: 0.4865 - val_loss: 1.4930 - val_acc: 0.4689\n",
            "Epoch 62/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4611 - acc: 0.4849 - val_loss: 1.4802 - val_acc: 0.4799\n",
            "Epoch 63/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4611 - acc: 0.4861 - val_loss: 1.4835 - val_acc: 0.4768\n",
            "Epoch 64/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4588 - acc: 0.4864 - val_loss: 1.4734 - val_acc: 0.4825\n",
            "Epoch 65/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4569 - acc: 0.4871 - val_loss: 1.4778 - val_acc: 0.4780\n",
            "Epoch 66/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4572 - acc: 0.4873 - val_loss: 1.4844 - val_acc: 0.4744\n",
            "Epoch 67/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4555 - acc: 0.4886 - val_loss: 1.4753 - val_acc: 0.4797\n",
            "Epoch 68/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4527 - acc: 0.4890 - val_loss: 1.4776 - val_acc: 0.4812\n",
            "Epoch 69/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4512 - acc: 0.4897 - val_loss: 1.4717 - val_acc: 0.4810\n",
            "Epoch 70/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4528 - acc: 0.4877 - val_loss: 1.4846 - val_acc: 0.4747\n",
            "Epoch 71/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4507 - acc: 0.4909 - val_loss: 1.4699 - val_acc: 0.4841\n",
            "Epoch 72/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4496 - acc: 0.4903 - val_loss: 1.4746 - val_acc: 0.4831\n",
            "Epoch 73/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4497 - acc: 0.4891 - val_loss: 1.4808 - val_acc: 0.4747\n",
            "Epoch 74/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4473 - acc: 0.4900 - val_loss: 1.4714 - val_acc: 0.4807\n",
            "Epoch 75/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4467 - acc: 0.4902 - val_loss: 1.4746 - val_acc: 0.4848\n",
            "Epoch 76/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4446 - acc: 0.4923 - val_loss: 1.4813 - val_acc: 0.4811\n",
            "Epoch 77/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4453 - acc: 0.4919 - val_loss: 1.4614 - val_acc: 0.4835\n",
            "Epoch 78/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4418 - acc: 0.4951 - val_loss: 1.4770 - val_acc: 0.4812\n",
            "Epoch 79/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4404 - acc: 0.4936 - val_loss: 1.4672 - val_acc: 0.4811\n",
            "Epoch 80/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4430 - acc: 0.4928 - val_loss: 1.4740 - val_acc: 0.4778\n",
            "Epoch 81/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4405 - acc: 0.4907 - val_loss: 1.4633 - val_acc: 0.4837\n",
            "Epoch 82/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4385 - acc: 0.4952 - val_loss: 1.4685 - val_acc: 0.4786\n",
            "Epoch 83/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4398 - acc: 0.4928 - val_loss: 1.4571 - val_acc: 0.4867\n",
            "Epoch 84/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4353 - acc: 0.4941 - val_loss: 1.4562 - val_acc: 0.4830\n",
            "Epoch 85/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4352 - acc: 0.4957 - val_loss: 1.4594 - val_acc: 0.4849\n",
            "Epoch 86/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4340 - acc: 0.4956 - val_loss: 1.4655 - val_acc: 0.4817\n",
            "Epoch 87/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4327 - acc: 0.4962 - val_loss: 1.4636 - val_acc: 0.4782\n",
            "Epoch 88/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4332 - acc: 0.4955 - val_loss: 1.4548 - val_acc: 0.4882\n",
            "Epoch 89/90\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4327 - acc: 0.4972 - val_loss: 1.4800 - val_acc: 0.4777\n",
            "Epoch 90/90\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4325 - acc: 0.4961 - val_loss: 1.4554 - val_acc: 0.4903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b88578b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDRuIf9R5-B7",
        "outputId": "5e58f0c3-3947-400a-8c69-7773382c37d3"
      },
      "source": [
        "model_mlp.fit(x_train, y_train, batch_size=128, epochs=90, validation_data=(x_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0299 - acc: 0.1989 - val_loss: 2.0203 - val_acc: 0.2019\n",
            "Epoch 2/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 2.0050 - acc: 0.2146 - val_loss: 1.9867 - val_acc: 0.2236\n",
            "Epoch 3/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9727 - acc: 0.2417 - val_loss: 1.9450 - val_acc: 0.2535\n",
            "Epoch 4/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9431 - acc: 0.2545 - val_loss: 1.9359 - val_acc: 0.2595\n",
            "Epoch 5/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9352 - acc: 0.2584 - val_loss: 1.9300 - val_acc: 0.2609\n",
            "Epoch 6/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9279 - acc: 0.2586 - val_loss: 1.9246 - val_acc: 0.2601\n",
            "Epoch 7/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9249 - acc: 0.2571 - val_loss: 1.9235 - val_acc: 0.2586\n",
            "Epoch 8/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9238 - acc: 0.2585 - val_loss: 1.9216 - val_acc: 0.2592\n",
            "Epoch 9/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9203 - acc: 0.2601 - val_loss: 1.9233 - val_acc: 0.2526\n",
            "Epoch 10/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9189 - acc: 0.2614 - val_loss: 1.9188 - val_acc: 0.2550\n",
            "Epoch 11/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9176 - acc: 0.2607 - val_loss: 1.9221 - val_acc: 0.2606\n",
            "Epoch 12/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9168 - acc: 0.2608 - val_loss: 1.9237 - val_acc: 0.2615\n",
            "Epoch 13/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9127 - acc: 0.2657 - val_loss: 1.9133 - val_acc: 0.2669\n",
            "Epoch 14/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9035 - acc: 0.2712 - val_loss: 1.8982 - val_acc: 0.2759\n",
            "Epoch 15/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8812 - acc: 0.2912 - val_loss: 1.8798 - val_acc: 0.3036\n",
            "Epoch 16/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8584 - acc: 0.3066 - val_loss: 1.8611 - val_acc: 0.3059\n",
            "Epoch 17/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8520 - acc: 0.3103 - val_loss: 1.8504 - val_acc: 0.3116\n",
            "Epoch 18/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8374 - acc: 0.3211 - val_loss: 1.8323 - val_acc: 0.3206\n",
            "Epoch 19/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8254 - acc: 0.3266 - val_loss: 1.8475 - val_acc: 0.3192\n",
            "Epoch 20/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8165 - acc: 0.3310 - val_loss: 1.8200 - val_acc: 0.3346\n",
            "Epoch 21/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8129 - acc: 0.3332 - val_loss: 1.8373 - val_acc: 0.3211\n",
            "Epoch 22/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8078 - acc: 0.3359 - val_loss: 1.8194 - val_acc: 0.3316\n",
            "Epoch 23/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8055 - acc: 0.3383 - val_loss: 1.8134 - val_acc: 0.3379\n",
            "Epoch 24/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.8020 - acc: 0.3407 - val_loss: 1.8201 - val_acc: 0.3341\n",
            "Epoch 25/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7984 - acc: 0.3423 - val_loss: 1.8186 - val_acc: 0.3359\n",
            "Epoch 26/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7997 - acc: 0.3433 - val_loss: 1.8053 - val_acc: 0.3439\n",
            "Epoch 27/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7936 - acc: 0.3456 - val_loss: 1.8167 - val_acc: 0.3364\n",
            "Epoch 28/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7927 - acc: 0.3475 - val_loss: 1.7985 - val_acc: 0.3473\n",
            "Epoch 29/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7914 - acc: 0.3467 - val_loss: 1.8008 - val_acc: 0.3439\n",
            "Epoch 30/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7870 - acc: 0.3503 - val_loss: 1.7980 - val_acc: 0.3427\n",
            "Epoch 31/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7846 - acc: 0.3521 - val_loss: 1.8062 - val_acc: 0.3390\n",
            "Epoch 32/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7859 - acc: 0.3512 - val_loss: 1.7960 - val_acc: 0.3442\n",
            "Epoch 33/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7833 - acc: 0.3526 - val_loss: 1.8048 - val_acc: 0.3454\n",
            "Epoch 34/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7800 - acc: 0.3540 - val_loss: 1.8037 - val_acc: 0.3481\n",
            "Epoch 35/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7784 - acc: 0.3552 - val_loss: 1.7846 - val_acc: 0.3567\n",
            "Epoch 36/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7759 - acc: 0.3536 - val_loss: 1.7844 - val_acc: 0.3520\n",
            "Epoch 37/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7739 - acc: 0.3578 - val_loss: 1.7959 - val_acc: 0.3472\n",
            "Epoch 38/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7745 - acc: 0.3551 - val_loss: 1.7807 - val_acc: 0.3564\n",
            "Epoch 39/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7742 - acc: 0.3563 - val_loss: 1.7851 - val_acc: 0.3532\n",
            "Epoch 40/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7732 - acc: 0.3560 - val_loss: 1.7862 - val_acc: 0.3519\n",
            "Epoch 41/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7697 - acc: 0.3563 - val_loss: 1.7925 - val_acc: 0.3448\n",
            "Epoch 42/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7675 - acc: 0.3594 - val_loss: 1.7855 - val_acc: 0.3512\n",
            "Epoch 43/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7677 - acc: 0.3586 - val_loss: 1.8033 - val_acc: 0.3480\n",
            "Epoch 44/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7662 - acc: 0.3588 - val_loss: 1.7739 - val_acc: 0.3558\n",
            "Epoch 45/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7668 - acc: 0.3576 - val_loss: 1.7855 - val_acc: 0.3498\n",
            "Epoch 46/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7665 - acc: 0.3574 - val_loss: 1.7804 - val_acc: 0.3547\n",
            "Epoch 47/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7631 - acc: 0.3570 - val_loss: 1.7805 - val_acc: 0.3559\n",
            "Epoch 48/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7612 - acc: 0.3605 - val_loss: 1.7715 - val_acc: 0.3548\n",
            "Epoch 49/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7627 - acc: 0.3599 - val_loss: 1.7976 - val_acc: 0.3490\n",
            "Epoch 50/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7605 - acc: 0.3580 - val_loss: 1.7781 - val_acc: 0.3504\n",
            "Epoch 51/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7599 - acc: 0.3609 - val_loss: 1.7823 - val_acc: 0.3520\n",
            "Epoch 52/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7599 - acc: 0.3604 - val_loss: 1.7757 - val_acc: 0.3518\n",
            "Epoch 53/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7583 - acc: 0.3614 - val_loss: 1.7837 - val_acc: 0.3532\n",
            "Epoch 54/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7565 - acc: 0.3599 - val_loss: 1.7752 - val_acc: 0.3524\n",
            "Epoch 55/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7571 - acc: 0.3610 - val_loss: 1.8113 - val_acc: 0.3458\n",
            "Epoch 56/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7551 - acc: 0.3640 - val_loss: 1.7855 - val_acc: 0.3512\n",
            "Epoch 57/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7574 - acc: 0.3604 - val_loss: 1.7866 - val_acc: 0.3505\n",
            "Epoch 58/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7539 - acc: 0.3607 - val_loss: 1.7753 - val_acc: 0.3544\n",
            "Epoch 59/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7530 - acc: 0.3634 - val_loss: 1.7698 - val_acc: 0.3597\n",
            "Epoch 60/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7533 - acc: 0.3615 - val_loss: 1.7821 - val_acc: 0.3524\n",
            "Epoch 61/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7525 - acc: 0.3621 - val_loss: 1.7724 - val_acc: 0.3533\n",
            "Epoch 62/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7523 - acc: 0.3618 - val_loss: 1.7714 - val_acc: 0.3571\n",
            "Epoch 63/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7518 - acc: 0.3615 - val_loss: 1.7810 - val_acc: 0.3520\n",
            "Epoch 64/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7493 - acc: 0.3631 - val_loss: 1.7894 - val_acc: 0.3449\n",
            "Epoch 65/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7505 - acc: 0.3623 - val_loss: 1.7716 - val_acc: 0.3541\n",
            "Epoch 66/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7499 - acc: 0.3628 - val_loss: 1.7733 - val_acc: 0.3481\n",
            "Epoch 67/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7528 - acc: 0.3605 - val_loss: 1.7683 - val_acc: 0.3562\n",
            "Epoch 68/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7495 - acc: 0.3633 - val_loss: 1.7842 - val_acc: 0.3448\n",
            "Epoch 69/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7488 - acc: 0.3628 - val_loss: 1.7715 - val_acc: 0.3502\n",
            "Epoch 70/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7487 - acc: 0.3649 - val_loss: 1.7712 - val_acc: 0.3534\n",
            "Epoch 71/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7477 - acc: 0.3635 - val_loss: 1.7928 - val_acc: 0.3457\n",
            "Epoch 72/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7490 - acc: 0.3636 - val_loss: 1.7838 - val_acc: 0.3456\n",
            "Epoch 73/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7447 - acc: 0.3642 - val_loss: 1.7802 - val_acc: 0.3461\n",
            "Epoch 74/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7526 - acc: 0.3604 - val_loss: 1.8092 - val_acc: 0.3380\n",
            "Epoch 75/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7458 - acc: 0.3637 - val_loss: 1.7789 - val_acc: 0.3520\n",
            "Epoch 76/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7474 - acc: 0.3631 - val_loss: 1.7721 - val_acc: 0.3508\n",
            "Epoch 77/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7473 - acc: 0.3645 - val_loss: 1.7721 - val_acc: 0.3565\n",
            "Epoch 78/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7453 - acc: 0.3629 - val_loss: 1.7830 - val_acc: 0.3518\n",
            "Epoch 79/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7437 - acc: 0.3641 - val_loss: 1.7717 - val_acc: 0.3517\n",
            "Epoch 80/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7435 - acc: 0.3667 - val_loss: 1.7783 - val_acc: 0.3550\n",
            "Epoch 81/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7442 - acc: 0.3645 - val_loss: 1.7869 - val_acc: 0.3489\n",
            "Epoch 82/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7440 - acc: 0.3629 - val_loss: 1.7758 - val_acc: 0.3517\n",
            "Epoch 83/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7427 - acc: 0.3655 - val_loss: 1.7852 - val_acc: 0.3491\n",
            "Epoch 84/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7433 - acc: 0.3634 - val_loss: 1.7853 - val_acc: 0.3448\n",
            "Epoch 85/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7442 - acc: 0.3630 - val_loss: 1.7799 - val_acc: 0.3541\n",
            "Epoch 86/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7414 - acc: 0.3668 - val_loss: 1.8212 - val_acc: 0.3438\n",
            "Epoch 87/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7422 - acc: 0.3646 - val_loss: 1.7890 - val_acc: 0.3492\n",
            "Epoch 88/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7414 - acc: 0.3651 - val_loss: 1.7722 - val_acc: 0.3561\n",
            "Epoch 89/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7395 - acc: 0.3665 - val_loss: 1.7778 - val_acc: 0.3474\n",
            "Epoch 90/90\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7406 - acc: 0.3643 - val_loss: 1.7716 - val_acc: 0.3506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7bef05ac10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itUx0CBV6Bd6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpeVj1ob8KrR"
      },
      "source": [
        "> 可以發現MLP似乎到達了一個瓶頸，兩個模型其實都有些underfitting，那麼我們選擇表現較好的CNN類型去做擴充"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TbjMcCY98Yza",
        "outputId": "b5b5cae5-d0dc-4f1c-f5fc-7d99ee509536"
      },
      "source": [
        "model_cnn_multi = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_cnn_multi.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model_cnn_multi.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 9s 21ms/step - loss: 1.4443 - acc: 0.4812 - val_loss: 1.1029 - val_acc: 0.6073\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 1.0146 - acc: 0.6440 - val_loss: 0.9811 - val_acc: 0.6587\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.8223 - acc: 0.7161 - val_loss: 0.8745 - val_acc: 0.6993\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.6845 - acc: 0.7649 - val_loss: 0.8140 - val_acc: 0.7208\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.5691 - acc: 0.8021 - val_loss: 0.8027 - val_acc: 0.7243\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4776 - acc: 0.8333 - val_loss: 0.8597 - val_acc: 0.7250\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.3814 - acc: 0.8667 - val_loss: 0.8916 - val_acc: 0.7289\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.3146 - acc: 0.8894 - val_loss: 1.0443 - val_acc: 0.7126\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.2488 - acc: 0.9130 - val_loss: 1.0638 - val_acc: 0.7301\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.2050 - acc: 0.9285 - val_loss: 1.2973 - val_acc: 0.7129\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1822 - acc: 0.9349 - val_loss: 1.4084 - val_acc: 0.7114\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1670 - acc: 0.9422 - val_loss: 1.4473 - val_acc: 0.7167\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1519 - acc: 0.9475 - val_loss: 1.4766 - val_acc: 0.7245\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1318 - acc: 0.9529 - val_loss: 1.6156 - val_acc: 0.7148\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1250 - acc: 0.9565 - val_loss: 1.6910 - val_acc: 0.7218\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1243 - acc: 0.9574 - val_loss: 1.7139 - val_acc: 0.7184\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1130 - acc: 0.9606 - val_loss: 1.8112 - val_acc: 0.7155\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1310 - acc: 0.9556 - val_loss: 1.7901 - val_acc: 0.7254\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0906 - acc: 0.9684 - val_loss: 1.9764 - val_acc: 0.7220\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1033 - acc: 0.9663 - val_loss: 1.9768 - val_acc: 0.7205\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1125 - acc: 0.9621 - val_loss: 2.0079 - val_acc: 0.7166\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1006 - acc: 0.9669 - val_loss: 2.0909 - val_acc: 0.7169\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0863 - acc: 0.9716 - val_loss: 2.0807 - val_acc: 0.7248\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1095 - acc: 0.9652 - val_loss: 2.1379 - val_acc: 0.7200\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0882 - acc: 0.9715 - val_loss: 2.1883 - val_acc: 0.7210\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0892 - acc: 0.9715 - val_loss: 2.3017 - val_acc: 0.7105\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0979 - acc: 0.9685 - val_loss: 2.3525 - val_acc: 0.7189\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0746 - acc: 0.9756 - val_loss: 2.3849 - val_acc: 0.7151\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0934 - acc: 0.9709 - val_loss: 2.4114 - val_acc: 0.7082\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.1087 - acc: 0.9664 - val_loss: 2.5430 - val_acc: 0.7042\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0892 - acc: 0.9722 - val_loss: 2.4979 - val_acc: 0.7142\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0726 - acc: 0.9772 - val_loss: 2.4037 - val_acc: 0.7196\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0789 - acc: 0.9751 - val_loss: 2.5168 - val_acc: 0.7259\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0955 - acc: 0.9712 - val_loss: 2.6622 - val_acc: 0.7104\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0807 - acc: 0.9749 - val_loss: 2.5779 - val_acc: 0.7152\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0787 - acc: 0.9759 - val_loss: 2.5781 - val_acc: 0.7114\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0862 - acc: 0.9742 - val_loss: 2.6780 - val_acc: 0.7222\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0832 - acc: 0.9746 - val_loss: 2.6210 - val_acc: 0.7146\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0688 - acc: 0.9790 - val_loss: 2.6475 - val_acc: 0.7184\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0738 - acc: 0.9783 - val_loss: 2.7074 - val_acc: 0.7166\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0671 - acc: 0.9795 - val_loss: 2.6802 - val_acc: 0.7138\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0854 - acc: 0.9751 - val_loss: 2.8244 - val_acc: 0.7140\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0917 - acc: 0.9728 - val_loss: 2.8018 - val_acc: 0.7172\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0569 - acc: 0.9831 - val_loss: 2.7110 - val_acc: 0.7286\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0670 - acc: 0.9803 - val_loss: 3.0178 - val_acc: 0.7085\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0842 - acc: 0.9758 - val_loss: 2.9948 - val_acc: 0.7181\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0731 - acc: 0.9788 - val_loss: 2.9295 - val_acc: 0.7161\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0761 - acc: 0.9783 - val_loss: 3.0134 - val_acc: 0.7180\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0609 - acc: 0.9819 - val_loss: 2.9655 - val_acc: 0.7256\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0766 - acc: 0.9794 - val_loss: 3.3170 - val_acc: 0.7052\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0845 - acc: 0.9761 - val_loss: 3.0795 - val_acc: 0.7105\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.0651 - acc: 0.9811 - val_loss: 2.9690 - val_acc: 0.7180\n",
            "Epoch 53/100\n",
            "148/391 [==========>...................] - ETA: 4s - loss: 0.0447 - acc: 0.9861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-143329cb36d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnZL8P5-9chV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ph3UMe98KV"
      },
      "source": [
        "> 可以看到模型學習非常快，效果也不錯！但是馬上就overfitting了，這邊需要加強泛化能力\n",
        "\n",
        "> 發現沒有用activation 先用一下!\n",
        "\n",
        "- BatchNormalization\n",
        "    - 激活函數之前\n",
        "- Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWviXpTb_FEX",
        "outputId": "3a20065f-25cb-4ff4-f728-ba91d2f719f5"
      },
      "source": [
        "model_cnn_multi_av = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_cnn_multi_av.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model_cnn_multi_av.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 9s 21ms/step - loss: 1.5961 - acc: 0.4106 - val_loss: 1.3136 - val_acc: 0.5289\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 1.1705 - acc: 0.5785 - val_loss: 1.0379 - val_acc: 0.6357\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.9750 - acc: 0.6578 - val_loss: 1.0355 - val_acc: 0.6366\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.8616 - acc: 0.6973 - val_loss: 0.8995 - val_acc: 0.6814\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.7597 - acc: 0.7343 - val_loss: 0.8419 - val_acc: 0.7046\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.6854 - acc: 0.7605 - val_loss: 0.7990 - val_acc: 0.7273\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.6179 - acc: 0.7824 - val_loss: 0.8642 - val_acc: 0.7143\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.5494 - acc: 0.8077 - val_loss: 0.8137 - val_acc: 0.7241\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4914 - acc: 0.8270 - val_loss: 0.7870 - val_acc: 0.7434\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.4470 - acc: 0.8436 - val_loss: 0.8272 - val_acc: 0.7307\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.4040 - acc: 0.8563 - val_loss: 0.8869 - val_acc: 0.7194\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.3556 - acc: 0.8745 - val_loss: 0.8442 - val_acc: 0.7444\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.3120 - acc: 0.8899 - val_loss: 0.8918 - val_acc: 0.7385\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.2644 - acc: 0.9069 - val_loss: 0.8994 - val_acc: 0.7567\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.2371 - acc: 0.9164 - val_loss: 0.9643 - val_acc: 0.7480\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.2007 - acc: 0.9281 - val_loss: 1.1007 - val_acc: 0.7362\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1892 - acc: 0.9330 - val_loss: 1.1130 - val_acc: 0.7375\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1649 - acc: 0.9418 - val_loss: 1.1337 - val_acc: 0.7394\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1509 - acc: 0.9449 - val_loss: 1.2454 - val_acc: 0.7218\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1257 - acc: 0.9557 - val_loss: 1.2509 - val_acc: 0.7436\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1150 - acc: 0.9586 - val_loss: 1.3013 - val_acc: 0.7406\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1276 - acc: 0.9542 - val_loss: 1.5056 - val_acc: 0.7148\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1107 - acc: 0.9608 - val_loss: 1.4090 - val_acc: 0.7402\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0980 - acc: 0.9652 - val_loss: 1.4116 - val_acc: 0.7434\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.1126 - acc: 0.9603 - val_loss: 1.4103 - val_acc: 0.7404\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0907 - acc: 0.9680 - val_loss: 1.6164 - val_acc: 0.7391\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0970 - acc: 0.9656 - val_loss: 1.5074 - val_acc: 0.7452\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0848 - acc: 0.9702 - val_loss: 1.5986 - val_acc: 0.7467\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0957 - acc: 0.9660 - val_loss: 1.6248 - val_acc: 0.7369\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.0744 - acc: 0.9736 - val_loss: 1.7782 - val_acc: 0.7369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b92fdae50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbBb5v1gAALU"
      },
      "source": [
        "> 有activation function透過非線性的擬合能力，幫助模型效果更好了一些!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNSGN15B_iRa",
        "outputId": "24e9d9a6-39f5-41f1-fcdf-e90c8ca9ddd6"
      },
      "source": [
        "model_cnn_multi_av_bn = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_cnn_multi_av_bn.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model_cnn_multi_av_bn.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 11s 26ms/step - loss: 1.2068 - acc: 0.5682 - val_loss: 1.6515 - val_acc: 0.4216\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.8222 - acc: 0.7115 - val_loss: 1.3895 - val_acc: 0.5515\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.6715 - acc: 0.7649 - val_loss: 0.8497 - val_acc: 0.7076\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5778 - acc: 0.7990 - val_loss: 1.0218 - val_acc: 0.6727\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4928 - acc: 0.8275 - val_loss: 0.8761 - val_acc: 0.7135\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4182 - acc: 0.8556 - val_loss: 1.1508 - val_acc: 0.6502\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.3634 - acc: 0.8726 - val_loss: 1.2062 - val_acc: 0.6669\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.3030 - acc: 0.8933 - val_loss: 1.0054 - val_acc: 0.7106\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.2522 - acc: 0.9115 - val_loss: 1.4061 - val_acc: 0.6343\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.2070 - acc: 0.9272 - val_loss: 0.9494 - val_acc: 0.7487\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.1727 - acc: 0.9391 - val_loss: 1.0259 - val_acc: 0.7360\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.1445 - acc: 0.9502 - val_loss: 1.1523 - val_acc: 0.7334\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.1250 - acc: 0.9574 - val_loss: 1.1411 - val_acc: 0.7233\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.1153 - acc: 0.9591 - val_loss: 1.2001 - val_acc: 0.7316\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0994 - acc: 0.9648 - val_loss: 1.4070 - val_acc: 0.7147\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0898 - acc: 0.9683 - val_loss: 1.1891 - val_acc: 0.7479\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.0806 - acc: 0.9722 - val_loss: 1.6835 - val_acc: 0.6625\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.0843 - acc: 0.9707 - val_loss: 1.1805 - val_acc: 0.7502\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0664 - acc: 0.9768 - val_loss: 1.3284 - val_acc: 0.7295\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0699 - acc: 0.9750 - val_loss: 1.6473 - val_acc: 0.6961\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0661 - acc: 0.9768 - val_loss: 1.3564 - val_acc: 0.7399\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0663 - acc: 0.9760 - val_loss: 1.2330 - val_acc: 0.7537\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0627 - acc: 0.9779 - val_loss: 1.2497 - val_acc: 0.7549\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0482 - acc: 0.9833 - val_loss: 1.3790 - val_acc: 0.7527\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.0498 - acc: 0.9827 - val_loss: 1.6144 - val_acc: 0.7180\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0551 - acc: 0.9801 - val_loss: 1.5937 - val_acc: 0.7126\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0510 - acc: 0.9818 - val_loss: 1.2836 - val_acc: 0.7561\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0538 - acc: 0.9815 - val_loss: 1.3176 - val_acc: 0.7564\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.0406 - acc: 0.9862 - val_loss: 1.7442 - val_acc: 0.6999\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.0396 - acc: 0.9863 - val_loss: 1.9596 - val_acc: 0.7020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b92db7e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHJtW9fO_7gO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgxT7ahnALCR"
      },
      "source": [
        "> 加入BN之後，效果: 可以看到generalize有些許提升，但並不穩定。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx2mTZRQEwM3"
      },
      "source": [
        "> [試試看Dropout](https://kknews.cc/zh-tw/code/mnvee3p.html) --> CNN Dropout 意義不大，因為神經元本來就很少!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JnEGxFfBheR",
        "outputId": "07b29791-e2bd-48c7-ca61-124548dc069e"
      },
      "source": [
        "model_cnn_multi_av_drop = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, padding='same'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.GlobalMaxPooling2D(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_cnn_multi_av_drop.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model_cnn_multi_av_drop.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 12s 28ms/step - loss: 1.7398 - acc: 0.3495 - val_loss: 2.0828 - val_acc: 0.2929\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.4094 - acc: 0.4841 - val_loss: 1.9627 - val_acc: 0.3518\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.2644 - acc: 0.5430 - val_loss: 1.8666 - val_acc: 0.4210\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.1783 - acc: 0.5779 - val_loss: 1.8704 - val_acc: 0.3473\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.1108 - acc: 0.6016 - val_loss: 1.7396 - val_acc: 0.4727\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.0594 - acc: 0.6198 - val_loss: 1.7191 - val_acc: 0.4521\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.0122 - acc: 0.6407 - val_loss: 1.6688 - val_acc: 0.5048\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.9900 - acc: 0.6478 - val_loss: 1.7251 - val_acc: 0.4189\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.9532 - acc: 0.6594 - val_loss: 1.5734 - val_acc: 0.5318\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.9296 - acc: 0.6736 - val_loss: 1.5761 - val_acc: 0.5249\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.9208 - acc: 0.6727 - val_loss: 1.5761 - val_acc: 0.5231\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.8863 - acc: 0.6854 - val_loss: 1.5521 - val_acc: 0.5410\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.8815 - acc: 0.6893 - val_loss: 1.5169 - val_acc: 0.5352\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.8637 - acc: 0.6948 - val_loss: 1.5505 - val_acc: 0.5264\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.8461 - acc: 0.7019 - val_loss: 1.4648 - val_acc: 0.5824\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.8376 - acc: 0.7055 - val_loss: 1.4150 - val_acc: 0.6134\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.8279 - acc: 0.7086 - val_loss: 1.3959 - val_acc: 0.6174\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.8168 - acc: 0.7144 - val_loss: 1.4950 - val_acc: 0.5413\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.8076 - acc: 0.7167 - val_loss: 1.4517 - val_acc: 0.5730\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.7996 - acc: 0.7174 - val_loss: 1.4107 - val_acc: 0.5738\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.7920 - acc: 0.7213 - val_loss: 1.4874 - val_acc: 0.5465\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.7862 - acc: 0.7243 - val_loss: 1.4247 - val_acc: 0.5772\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.7817 - acc: 0.7238 - val_loss: 1.4277 - val_acc: 0.5842\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.7773 - acc: 0.7280 - val_loss: 1.4058 - val_acc: 0.6160\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.7711 - acc: 0.7294 - val_loss: 1.4109 - val_acc: 0.6056\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.7571 - acc: 0.7332 - val_loss: 1.3082 - val_acc: 0.6490\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.7563 - acc: 0.7350 - val_loss: 1.3681 - val_acc: 0.5937\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.7476 - acc: 0.7370 - val_loss: 1.3497 - val_acc: 0.6351\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.7479 - acc: 0.7349 - val_loss: 1.3322 - val_acc: 0.6562\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.7326 - acc: 0.7438 - val_loss: 1.3701 - val_acc: 0.5911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b92a4ddd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80NCTaUHFu5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngibi6ruIH1d"
      },
      "source": [
        "> 可以看到，的確反而讓模型更難以學習!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZovIZLYIVZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras實現BERT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeTOr0Mu8cpT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "from pprint import pprint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMcSZpoY-KLg",
        "outputId": "355296dc-53e3-43cd-fc69-394d93567f07"
      },
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    MAX_LEN = 256\n",
        "    BATCH_SIZE = 128\n",
        "    LR = 0.001\n",
        "    VOCAB_SIZE = 30000\n",
        "    EMBED_DIM = 128\n",
        "    NUM_HEAD = 8  # used in bert model\n",
        "    FF_DIM = 128  # used in bert model\n",
        "    NUM_LAYERS = 12\n",
        "\n",
        "\n",
        "config = Config()\n",
        "config"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NdzwQCe1Esp",
        "outputId": "91cdb1d6-4a98-4756-9aa1-292faf3fc798"
      },
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz        # 下載\n",
        "!tar -xf aclImdb_v1.tar.gz                                                      # 解壓縮"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  54.5M      0  0:00:01  0:00:01 --:--:-- 54.5M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvBA7myo-Ugh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2e6061-b8e6-4427-ca19-fee32b649929"
      },
      "source": [
        "def get_text_list_from_files(files):\n",
        "    text_list = []\n",
        "    for name in files:\n",
        "        with open(name) as f:\n",
        "            for line in f:\n",
        "                text_list.append(line)\n",
        "    return text_list\n",
        "\n",
        "\n",
        "def get_data_from_text_files(folder_name):\n",
        "    pos_files = glob.glob('aclImdb/' + folder_name + \"/pos/*.txt\")\n",
        "    pos_texts = get_text_list_from_files(pos_files)\n",
        "    neg_files = glob.glob('aclImdb/' + folder_name + '/neg/*.txt')\n",
        "    neg_texts = get_text_list_from_files(neg_files)\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            'review': pos_texts + neg_texts,\n",
        "            'sentiment': [0] * len(pos_texts) + [1] * len(neg_texts)\n",
        "        }\n",
        "    )\n",
        "    df = df.sample(len(df)).reset_index(drop=True)      # shuffle + reset_index\n",
        "    return df\n",
        "\n",
        "train_df = get_data_from_text_files('train')\n",
        "test_df = get_data_from_text_files('test')\n",
        "\n",
        "all_data = train_df.append(other=test_df)               # df.append(other): 直接append到後面 \n",
        "all_data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwydIntaDIwe"
      },
      "source": [
        "def custom_standarization(input_data):\n",
        "    \"\"\"\n",
        "        客製化的處理text資料, 用於text layer。\n",
        "        處理:\n",
        "            小寫、去除html tag、去除標點符號\n",
        "    \"\"\"\n",
        "    lowercase = tf.strings.lower(input=input_data)\n",
        "    stripped_html = tf.strings.regex_replace(\n",
        "        input=lowercase,\n",
        "        pattern=\"<br />\",\n",
        "        rewrite=' '\n",
        "    )\n",
        "    return tf.strings.regex_replace(\n",
        "        input=stripped_html,\n",
        "        pattern=re.escape(pattern=\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"),\n",
        "        rewrite=''\n",
        "    )\n",
        "\n",
        "\n",
        "def get_vectorize_layer(texts, vocab_size, max_seq, special_tokens=[\"MASK\"]):\n",
        "    \"\"\"Build Text vectorization layer\n",
        "\n",
        "    Args:\n",
        "      texts (list): List of string i.e input texts\n",
        "      vocab_size (int): vocab size\n",
        "      max_seq (int): Maximum sequence lenght.\n",
        "      special_tokens (list, optional): List of special tokens. Defaults to ['[MASK]'].\n",
        "\n",
        "    Returns:\n",
        "        layers.Layer: Return TextVectorization Keras Layer\n",
        "    \"\"\"\n",
        "    vectorizer_layer = TextVectorization(\n",
        "        max_tokens=vocab_size,\n",
        "        standardize=custom_standarization,\n",
        "        output_mode='int',\n",
        "        output_sequence_length=max_seq\n",
        "    )\n",
        "    vectorizer_layer.adapt(texts)           # fit\n",
        "\n",
        "    # 插入mask token\n",
        "    vocab = vectorizer_layer.get_vocabulary()   # 30000\n",
        "    vocab = vocab[2 : vocab_size - len(special_tokens)] + [\"[mask]\"]    # 0:2 ---> '', '[UNK]', 不要這兩個why?\n",
        "    vectorizer_layer.set_vocabulary(vocab)      # 29998\n",
        "    return vectorizer_layer\n",
        "\n",
        "\n",
        "# 文字處理layer init\n",
        "vectorize_layer = get_vectorize_layer(\n",
        "    all_data.review.values.tolist(),\n",
        "    config.VOCAB_SIZE,\n",
        "    config.MAX_LEN,\n",
        "    special_tokens=[\"[mask]\"],\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCs9wYMR4IPG",
        "outputId": "ca3ce9e1-169c-42dd-b0f5-69e31f7b26a8"
      },
      "source": [
        "# MASK TOEKN看看\n",
        "\n",
        "mask_token_id = vectorize_layer([['[mask]']]).numpy()[0][0]   # return (1, max_len)\n",
        "mask_token_id"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQH7-NZ7p3F"
      },
      "source": [
        "def encode(texts):\n",
        "    \"\"\"\n",
        "        將文字輸入做處理、轉換成模型可處理的vector，也可將其變成end-to-end model，\n",
        "        此方法是先在資料集處理。\n",
        "    \"\"\"\n",
        "    encoded_texts = vectorize_layer(texts)\n",
        "    return encoded_texts.numpy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FmAlAesygg8",
        "outputId": "ace83b9b-b12b-44d0-c70a-b90c70add315"
      },
      "source": [
        "encode(train_df.review.values)      # 輸入轉換成向量"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   9,  599,   10, ...,    0,    0,    0],\n",
              "       [   9,   25,    6, ...,    0,    0,    0],\n",
              "       [   3,  185,  291, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 856,   34,    5, ...,    0,    0,    0],\n",
              "       [3150,    9,   80, ...,    0,    0,    0],\n",
              "       [   9,  197,   10, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iko0DmbEy_Lc",
        "outputId": "8e9aa42f-98f6-4c0d-db18-c4c519c0f2b4"
      },
      "source": [
        "vectorize_layer.get_vocabulary()[:3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcs06CA4aCY2",
        "outputId": "b1cee0f5-0522-45be-a31e-c7f1cb552a35"
      },
      "source": [
        "# masked 總數估計\n",
        "\n",
        "25000 * 256 * 0.15"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "960000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nrZeJjxeUYD"
      },
      "source": [
        "### masked inputs and labels 釋例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TiDl4oVXTYW"
      },
      "source": [
        "### masked inputs and labels 釋例\n",
        "\n",
        "encoded_texts = encode(train_df.review.values)  # (25000, 256) ---> 25000筆, 句子長度為256, 也就是256個word。\n",
        "# print(encoded_texts.shape)\n",
        "\n",
        "input_mask = np.random.rand(*encoded_texts.shape) < 0.15        # (25000, 256) ---> boolean matrix, 根據論文mask 15%\n",
        "input_mask[encoded_texts <= 2] = False                            # ['', '[UNK]', 'the'] 是不去mask的。\n",
        "\n",
        "labels = (-1) * np.ones(encoded_texts.shape, dtype=int)         # ---> 真實mask的labels, -1代表忽略\n",
        "labels[input_mask] = encoded_texts[input_mask]                  # 給予真實的word token, 真正masked的資料之答案\n",
        "\n",
        "# print(labels[input_mask].shape)                                 # 586446, 可能每次會不一樣, 根據seed, 代表的是: 在訓練語言模型時, 會預測的Word總數。\n",
        "#### 上面完成了mask資料的y部分(預測的地方)\n",
        "\n",
        "#### 輸入部分\n",
        "encoded_texts_masked = np.copy(encoded_texts)       # 複製, 要修改\n",
        "input_mask_2mask = input_mask & (np.random.rand(*encoded_texts.shape) < 0.90)       # (25000, 256) 的boolean matrix, 根據論文15%裡面有90%使用[mask], \n",
        "encoded_texts_masked[input_mask_2mask] = mask_token_id          # 將其word token改成[mask]的token, 也就是29999, 數量會是上面596446的大概9成: 528488\n",
        "\n",
        "# 剩下10%去隨機token\n",
        "input_mask_2random = input_mask * (np.random.rand(*encoded_texts.shape) < 0.10)\n",
        "encoded_texts_masked[input_mask_2random] = np.random.randint(\n",
        "    low=3,\n",
        "    high=mask_token_id,\n",
        "    size=input_mask_2random.sum()\n",
        ")\n",
        "\n",
        "## 最後一步: 樣本權重設定, 一般是數值weight, 0代表忽略\n",
        "sample_weights = np.ones(labels.shape)              # (25000, 256)\n",
        "sample_weights[labels == -1] = 0\n",
        "\n",
        "y_labels = np.copy(encoded_texts)                   # (25000, 256), 原始句子, 也就是真實答案"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wwjd-JQecEZ"
      },
      "source": [
        "#### Masked之後的輸入token\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRKXMrfqeaaq",
        "outputId": "7f4f0ff5-7b5e-4733-9f0c-46a044e3b192"
      },
      "source": [
        "encoded_texts_masked, encoded_texts_masked.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[    9,   599,    10, ...,     0,     0,     0],\n",
              "        [    9,    25, 29999, ...,     0,     0,     0],\n",
              "        [    3,   185,   291, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  856,    34,     5, ...,     0,     0,     0],\n",
              "        [ 3150,     9,    80, ...,     0,     0,     0],\n",
              "        [29999,   197, 29999, ...,     0,     0,     0]]), (25000, 256))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG_pKwSXetuO"
      },
      "source": [
        "#### 真實labels, 原始句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Rmd1P_ex7n",
        "outputId": "6a45cfb1-6afd-42bc-b89c-d3930ce328a6"
      },
      "source": [
        "y_labels, y_labels.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   9,  599,   10, ...,    0,    0,    0],\n",
              "        [   9,   25,    6, ...,    0,    0,    0],\n",
              "        [   3,  185,  291, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 856,   34,    5, ...,    0,    0,    0],\n",
              "        [3150,    9,   80, ...,    0,    0,    0],\n",
              "        [   9,  197,   10, ...,    0,    0,    0]]), (25000, 256))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF5stsHAe0Iy"
      },
      "source": [
        "#### 樣本權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyGVR8cVe4Qg",
        "outputId": "ed7b61dc-c33c-4af5-eca5-76e8debb0287"
      },
      "source": [
        "sample_weights, sample_weights.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 1., ..., 0., 0., 0.]]), (25000, 256))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BavYDLFDxNY1"
      },
      "source": [
        "def get_masked_input_and_labels(encoded_texts):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    # 準備label(target)\n",
        "    # 根據BERT論文, 將15%的資料做masking\n",
        "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15      # boolean matrix\n",
        "    inp_mask[encoded_texts <= 2] = False                        # <=2的token是特殊token('', '[UNK]'),不mask, 但這邊好像把'the'也不mask了\n",
        "    # 將目標預設為-1,  代表忽略\n",
        "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
        "    # set labels for masked tokens\n",
        "    labels[inp_mask] = encoded_texts[inp_mask]                  # 這就是被mask的真實label, 其餘為-1是忽略的\n",
        "\n",
        "    # 準備輸入\n",
        "    encoded_texts_masked = np.copy(encoded_texts)\n",
        "    # 根據BERT論文, 將15%將要mask的資料裡面, 90%去真正使用[mask]\n",
        "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
        "    encoded_texts_masked[inp_mask_2mask] = mask_token_id        # 真正mask的資料, x_data\n",
        "\n",
        "    # 剩下10%去random token\n",
        "    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 0.10)\n",
        "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
        "        low=3, high=mask_token_id, size=inp_mask_2random.sum()\n",
        "    )       # token(3~mask_token_id(不包含)), 都可能\n",
        "\n",
        "    # 準備樣本權重去pass to fit() method\n",
        "    sample_weights = np.ones(labels.shape)\n",
        "    sample_weights[labels == -1] = 0            # 忽略的權重會直接變成0, 就不會更新該樣本權重\n",
        "\n",
        "    y_labels = np.copy(encoded_texts)           # y_label, 真實答案\n",
        "\n",
        "    return encoded_texts_masked, y_labels, sample_weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NBadpY40Ic1"
      },
      "source": [
        "# 訓練資料準備\n",
        "\n",
        "# 這是語義分析的資料\n",
        "x_train = encode(train_df.review.values)\n",
        "y_train = train_df.sentiment.values\n",
        "train_classifier_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        tensors=(x_train, y_train)\n",
        "    ).shuffle(1000).batch(config.BATCH_SIZE)\n",
        ")\n",
        "\n",
        "\n",
        "x_test = encode(test_df.review.values)\n",
        "y_test = test_df.sentiment.values\n",
        "test_classifier_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(\n",
        "    config.BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Build dataset for end to end model input (will be used at the end)\n",
        "test_raw_classifier_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_df.review.values, y_test)\n",
        ").batch(config.BATCH_SIZE)\n",
        "\n",
        "\n",
        "# MLM 訓練資料\n",
        "x_all_review = encode(all_data.review.values)\n",
        "x_masked_train, y_masked_labels, sample_weights = get_masked_input_and_labels(\n",
        "    x_all_review\n",
        ")\n",
        "\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_masked_train, y_masked_labels, sample_weights)\n",
        ").shuffle(1000).batch(config.BATCH_SIZE)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jPbDQu0_063"
      },
      "source": [
        "### BERT model建立"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPV6B9gl97dy"
      },
      "source": [
        "def bert_module(query, key, value, i):\n",
        "    \"\"\"\n",
        "        Encoder block\n",
        "    \"\"\"\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=config.NUM_HEAD,\n",
        "        key_dim=config.EMBED_DIM // config.NUM_HEAD,\n",
        "        name=f'encoder_{i}/multiheadattention'\n",
        "    )(query, key, value)\n",
        "    attention_output = layers.Dropout(rate=0.1, name=f'encoder_{i}/att_dropout')(attention_output)\n",
        "    attention_output = layers.LayerNormalization(\n",
        "        epsilon=1e-1, name=f'encoder_{i}/att_layernormalization'\n",
        "    )(query + attention_output)                 # short-cut\n",
        "\n",
        "    # ffn\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(config.FF_DIM, activation='relu'),\n",
        "        layers.Dense(config.EMBED_DIM),          \n",
        "    ], name=f\"encoder_{i}/ffn\")\n",
        "    ffn_output = ffn(attention_output)\n",
        "    ffn_output = layers.Dropout(0.1, name=f\"encoder_{i}/ffn_dropout\")(\n",
        "        ffn_output\n",
        "    )\n",
        "    sequence_output = layers.LayerNormalization(\n",
        "        epsilon=1e-6, name=f\"encoder_{i}/ffn_layernormalization\"\n",
        "    )(attention_output + ffn_output)            # short-cut\n",
        "    return sequence_output\n",
        "\n",
        "\n",
        "def get_pos_encoding_matrix(max_len, d_emb):\n",
        "    \"\"\"\n",
        "        初始化的參數, 放入postional embedding讓其繼續學習。\n",
        "    \"\"\"\n",
        "    pos_enc = np.array(\n",
        "        [\n",
        "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
        "            if pos != 0\n",
        "            else np.zeros(d_emb)\n",
        "            for pos in range(max_len)\n",
        "        ]\n",
        "    )\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
        "    return pos_enc\n",
        "\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
        "    reduction=tf.keras.losses.Reduction.NONE\n",
        ")\n",
        "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")       # : Computes the (weighted) mean of the given values."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmUKcbQVH6Jz"
      },
      "source": [
        "#### [sample_weight](https://keras.io/zh/models/model/)\n",
        "- 就是在說訓練中, 樣本權重會使用、注意哪一些，常用在序列相關的資料中!mask data也是!\n",
        "#### [Model.fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit?hl=zh-cn#%E6%94%AF%E6%8C%81_sample_weight_%E5%92%8C_class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0jE2Mk_G6uQ"
      },
      "source": [
        "# MLM 模型\n",
        "\n",
        "class MaskedLanguageModel(tf.keras.Model):\n",
        "    def train_step(self, inputs):\n",
        "        # override 訓練步驟, mode.fit()的客製化\n",
        "        if len(inputs) == 3:\n",
        "            features, labels, sample_weight = inputs\n",
        "        else:\n",
        "            features, labels = inputs\n",
        "            sample_weight = None\n",
        "        \n",
        "        # tf梯度紀錄, forward\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions =  self(features, training=True)        # 前面建好的model layers\n",
        "            loss = loss_fn(\n",
        "                y_true=labels,\n",
        "                y_pred=predictions,\n",
        "                sample_weight=sample_weight                     # 重點之一, model.compile也可以設定, 但不知道效果一樣嗎?\n",
        "            )\n",
        "        \n",
        "        # 梯度計算, backward\n",
        "        trainable_vars = self.trainable_variables               # Model的模型訓練參數\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # 梯度更新\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # 計算model metrics\n",
        "        loss_tracker.update_state(loss, sample_weight=sample_weight)    # 重點之一, metrics設定那些才列入計算\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {\"loss\": loss_tracker.result()}          # 平常使用keras看到的高階API, return dict(metrics: value)\n",
        "    \n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [loss_tracker]\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STVwrv5IZ2lY",
        "outputId": "b098b144-5448-4d6c-eacb-ad674a8eda81"
      },
      "source": [
        "mask_token_id"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QULLsVpWKy3k",
        "outputId": "bc462aae-d122-4852-f811-596ae240c71a"
      },
      "source": [
        "def create_masked_language_bert_model():\n",
        "    \"\"\"\n",
        "        建造MLM with BERT\n",
        "    \"\"\"\n",
        "    inputs = keras.Input(shape=(config.MAX_LEN,), dtype='int64')\n",
        "    word_embedding = layers.Embedding(\n",
        "        input_dim=config.VOCAB_SIZE,\n",
        "        output_dim=config.EMBED_DIM,\n",
        "        name='word_embedding'\n",
        "    )(inputs)\n",
        "    position_embeddings = layers.Embedding(\n",
        "        input_dim=config.MAX_LEN,\n",
        "        output_dim=config.EMBED_DIM,\n",
        "        weights=[get_pos_encoding_matrix(config.MAX_LEN, config.EMBED_DIM)],    # 完全讓其自己學也可以\n",
        "        name=\"position_embedding\",\n",
        "    )(tf.range(start=0, limit=config.MAX_LEN, delta=1))\n",
        "    # 其實還需要一個segment embedding, 但沒有NSP任務, 先忽略\n",
        "    embedding =  word_embedding + position_embeddings\n",
        "    encoder_output = embedding\n",
        "    \n",
        "    # Encoder block的堆疊\n",
        "    for i in range(config.NUM_LAYERS):\n",
        "        encoder_output = bert_module(encoder_output, encoder_output, encoder_output, i)\n",
        "\n",
        "    mlm_output = layers.Dense(config.VOCAB_SIZE, name='mlm_cls', activation='softmax')(encoder_output)\n",
        "    mlm_model = MaskedLanguageModel(inputs, mlm_output, name='masked_bert_model')\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
        "    mlm_model.compile(optimizer=optimizer)      # 不需要loss 是因為前面MLM已經設定了\n",
        "    return mlm_model\n",
        "\n",
        "\n",
        "# token <-> index轉換的dict\n",
        "id2token = dict(enumerate(vectorize_layer.get_vocabulary()))\n",
        "token2id = {y: x for x, y in id2token.items()}\n",
        "\n",
        "class MaskedTextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "        Callback使用, 每一個epoch之後的操作\n",
        "    \"\"\"\n",
        "    def __init__(self, sample_tokens, top_k=5):\n",
        "        self.sample_tokens = sample_tokens\n",
        "        self.k = top_k\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return \" \".join([id2token[t] for t in tokens if t != 0])\n",
        "\n",
        "    def convert_ids_to_tokens(self, id):\n",
        "        return id2token[id]\n",
        "\n",
        "    # 先要override的method, 在epoch結束會做的事情! 觀察用\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        prediction = self.model.predict(self.sample_tokens)     # (batch_size=1, 256, 30000)\n",
        "        print(prediction.shape)\n",
        "\n",
        "        masked_index = np.where(self.sample_tokens == mask_token_id) \n",
        "        print(masked_index)                             # (array([0]), array([4])), 為什有0是因為np.where\n",
        "        masked_index = masked_index[1]                  # 故此處真正要的是index 1, 也就是[4]\n",
        "        print(masked_index)                             # [4]: mask token的位置\n",
        "        mask_prediction = prediction[0][masked_index]   # mask的預測值, 因為是分類, 有vocab_size這麼多個機率, 找top_k個就好!\n",
        "        print(mask_prediction)\n",
        "\n",
        "        top_indices = mask_prediction[0].argsort()[-self.k :][::-1]     # argsort()會將機率的index由小到大排序, 故先找到最後面的k個, 再從後往前數\n",
        "        print(top_indices)                                              # 例: [19 24 1371 103 122]\n",
        "\n",
        "        values = mask_prediction[0][top_indices]                        # 例: [0.5538519  0.130241   0.07007366 0.04236298 0.01845231]\n",
        "        print(values)\n",
        "\n",
        "        for i in range(len(top_indices)):\n",
        "            p = top_indices[i]                  # word token, 也就是index\n",
        "            v = values[i]                       # 機率\n",
        "            tokens = np.copy(sample_tokens[0])\n",
        "            tokens[masked_index[0]] = p\n",
        "            result = {\n",
        "                \"input_text\": self.decode(sample_tokens[0].numpy()),\n",
        "                \"prediction\": self.decode(tokens),\n",
        "                \"probability\": v,\n",
        "                \"predicted mask token\": self.convert_ids_to_tokens(p),\n",
        "            }\n",
        "            pprint(result)\n",
        "        \n",
        "            # {'input_text': 'i have watched this [mask] and it was awesome',\n",
        "            # 'predicted mask token': 'worst',\n",
        "            # 'prediction': 'i have watched this worst and it was awesome',\n",
        "            # 'probability': 0.022767955}\n",
        "\n",
        "\n",
        "sample_tokens = vectorize_layer([\"I have watched this [mask] and it was awesome\"])\n",
        "generator_callback = MaskedTextGenerator(sample_tokens.numpy())\n",
        "\n",
        "bert_masked_model = create_masked_language_bert_model()\n",
        "bert_masked_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"masked_bert_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 256, 128)     3840000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 256, 128)     0           word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/multiheadattention (M (None, 256, 128)     66048       tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_dropout (Dropout) (None, 256, 128)     0           encoder_0/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 256, 128)     0           tf.__operators__.add[0][0]       \n",
            "                                                                 encoder_0/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn (Sequential)      (None, 256, 128)     33024       encoder_0/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_0/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 256, 128)     0           encoder_0/att_layernormalization[\n",
            "                                                                 encoder_0/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/multiheadattention (M (None, 256, 128)     66048       encoder_0/ffn_layernormalization[\n",
            "                                                                 encoder_0/ffn_layernormalization[\n",
            "                                                                 encoder_0/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/att_dropout (Dropout) (None, 256, 128)     0           encoder_1/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 256, 128)     0           encoder_0/ffn_layernormalization[\n",
            "                                                                 encoder_1/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/ffn (Sequential)      (None, 256, 128)     33024       encoder_1/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_1/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 256, 128)     0           encoder_1/att_layernormalization[\n",
            "                                                                 encoder_1/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/multiheadattention (M (None, 256, 128)     66048       encoder_1/ffn_layernormalization[\n",
            "                                                                 encoder_1/ffn_layernormalization[\n",
            "                                                                 encoder_1/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/att_dropout (Dropout) (None, 256, 128)     0           encoder_2/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 256, 128)     0           encoder_1/ffn_layernormalization[\n",
            "                                                                 encoder_2/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/ffn (Sequential)      (None, 256, 128)     33024       encoder_2/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_2/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 256, 128)     0           encoder_2/att_layernormalization[\n",
            "                                                                 encoder_2/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_2/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/multiheadattention (M (None, 256, 128)     66048       encoder_2/ffn_layernormalization[\n",
            "                                                                 encoder_2/ffn_layernormalization[\n",
            "                                                                 encoder_2/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/att_dropout (Dropout) (None, 256, 128)     0           encoder_3/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 256, 128)     0           encoder_2/ffn_layernormalization[\n",
            "                                                                 encoder_3/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/ffn (Sequential)      (None, 256, 128)     33024       encoder_3/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_3/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 256, 128)     0           encoder_3/att_layernormalization[\n",
            "                                                                 encoder_3/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_3/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/multiheadattention (M (None, 256, 128)     66048       encoder_3/ffn_layernormalization[\n",
            "                                                                 encoder_3/ffn_layernormalization[\n",
            "                                                                 encoder_3/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/att_dropout (Dropout) (None, 256, 128)     0           encoder_4/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 256, 128)     0           encoder_3/ffn_layernormalization[\n",
            "                                                                 encoder_4/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/ffn (Sequential)      (None, 256, 128)     33024       encoder_4/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_4/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 256, 128)     0           encoder_4/att_layernormalization[\n",
            "                                                                 encoder_4/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_4/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/multiheadattention (M (None, 256, 128)     66048       encoder_4/ffn_layernormalization[\n",
            "                                                                 encoder_4/ffn_layernormalization[\n",
            "                                                                 encoder_4/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/att_dropout (Dropout) (None, 256, 128)     0           encoder_5/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 256, 128)     0           encoder_4/ffn_layernormalization[\n",
            "                                                                 encoder_5/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/ffn (Sequential)      (None, 256, 128)     33024       encoder_5/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_5/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 256, 128)     0           encoder_5/att_layernormalization[\n",
            "                                                                 encoder_5/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_5/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/multiheadattention (M (None, 256, 128)     66048       encoder_5/ffn_layernormalization[\n",
            "                                                                 encoder_5/ffn_layernormalization[\n",
            "                                                                 encoder_5/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/att_dropout (Dropout) (None, 256, 128)     0           encoder_6/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 256, 128)     0           encoder_5/ffn_layernormalization[\n",
            "                                                                 encoder_6/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/ffn (Sequential)      (None, 256, 128)     33024       encoder_6/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_6/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 256, 128)     0           encoder_6/att_layernormalization[\n",
            "                                                                 encoder_6/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_6/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/multiheadattention (M (None, 256, 128)     66048       encoder_6/ffn_layernormalization[\n",
            "                                                                 encoder_6/ffn_layernormalization[\n",
            "                                                                 encoder_6/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/att_dropout (Dropout) (None, 256, 128)     0           encoder_7/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 256, 128)     0           encoder_6/ffn_layernormalization[\n",
            "                                                                 encoder_7/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/ffn (Sequential)      (None, 256, 128)     33024       encoder_7/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_7/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 256, 128)     0           encoder_7/att_layernormalization[\n",
            "                                                                 encoder_7/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_7/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/multiheadattention (M (None, 256, 128)     66048       encoder_7/ffn_layernormalization[\n",
            "                                                                 encoder_7/ffn_layernormalization[\n",
            "                                                                 encoder_7/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/att_dropout (Dropout) (None, 256, 128)     0           encoder_8/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_17 (TFOpLa (None, 256, 128)     0           encoder_7/ffn_layernormalization[\n",
            "                                                                 encoder_8/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_17[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/ffn (Sequential)      (None, 256, 128)     33024       encoder_8/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_8/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_18 (TFOpLa (None, 256, 128)     0           encoder_8/att_layernormalization[\n",
            "                                                                 encoder_8/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_8/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_18[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/multiheadattention (M (None, 256, 128)     66048       encoder_8/ffn_layernormalization[\n",
            "                                                                 encoder_8/ffn_layernormalization[\n",
            "                                                                 encoder_8/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/att_dropout (Dropout) (None, 256, 128)     0           encoder_9/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_19 (TFOpLa (None, 256, 128)     0           encoder_8/ffn_layernormalization[\n",
            "                                                                 encoder_9/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_19[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/ffn (Sequential)      (None, 256, 128)     33024       encoder_9/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_9/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_20 (TFOpLa (None, 256, 128)     0           encoder_9/att_layernormalization[\n",
            "                                                                 encoder_9/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_9/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_20[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/multiheadattention ( (None, 256, 128)     66048       encoder_9/ffn_layernormalization[\n",
            "                                                                 encoder_9/ffn_layernormalization[\n",
            "                                                                 encoder_9/ffn_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/att_dropout (Dropout (None, 256, 128)     0           encoder_10/multiheadattention[0][\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_21 (TFOpLa (None, 256, 128)     0           encoder_9/ffn_layernormalization[\n",
            "                                                                 encoder_10/att_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/att_layernormalizati (None, 256, 128)     256         tf.__operators__.add_21[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/ffn (Sequential)     (None, 256, 128)     33024       encoder_10/att_layernormalization\n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/ffn_dropout (Dropout (None, 256, 128)     0           encoder_10/ffn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_22 (TFOpLa (None, 256, 128)     0           encoder_10/att_layernormalization\n",
            "                                                                 encoder_10/ffn_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_10/ffn_layernormalizati (None, 256, 128)     256         tf.__operators__.add_22[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/multiheadattention ( (None, 256, 128)     66048       encoder_10/ffn_layernormalization\n",
            "                                                                 encoder_10/ffn_layernormalization\n",
            "                                                                 encoder_10/ffn_layernormalization\n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/att_dropout (Dropout (None, 256, 128)     0           encoder_11/multiheadattention[0][\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_23 (TFOpLa (None, 256, 128)     0           encoder_10/ffn_layernormalization\n",
            "                                                                 encoder_11/att_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/att_layernormalizati (None, 256, 128)     256         tf.__operators__.add_23[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/ffn (Sequential)     (None, 256, 128)     33024       encoder_11/att_layernormalization\n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/ffn_dropout (Dropout (None, 256, 128)     0           encoder_11/ffn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_24 (TFOpLa (None, 256, 128)     0           encoder_11/att_layernormalization\n",
            "                                                                 encoder_11/ffn_dropout[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "encoder_11/ffn_layernormalizati (None, 256, 128)     256         tf.__operators__.add_24[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mlm_cls (Dense)                 (None, 256, 30000)   3870000     encoder_11/ffn_layernormalization\n",
            "==================================================================================================\n",
            "Total params: 8,905,008\n",
            "Trainable params: 8,905,008\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpiEdc65KD_x",
        "outputId": "11e12db1-4e48-4640-e815-27b3b6c22324"
      },
      "source": [
        "\"\"\"\n",
        "    **np.where解說: https://numpy.org/doc/stable/reference/generated/numpy.where.html\n",
        "    2種用法:\n",
        "        1. np.where(condition): return True的位置(tuple)。\n",
        "            假受condtion為一個(1, 256)的ndarray/tensor, 且裡面有一個True在[0, 4]的位置, 則會return (0, 4)\n",
        "            若為(1, 1, 256), ... 且裡面有一個True在[0, 0, 4] --- return (0, 0, 4)\n",
        "            故代表, 每一個會return 一個tuple, 而tuple的順序值, 為各個維度的index。\n",
        "        2. np.where(condition, x, y): return conditon資料, True用x替代, False用y替代\n",
        "\"\"\"\n",
        "\n",
        "np.where(sample_tokens == mask_token_id)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0]), array([4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3XuL2G7Z0Y8"
      },
      "source": [
        "for id_ in sample_tokens[0]:\n",
        "    print(id_.numpy(), id2token[id_.numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLt-rXENwmw"
      },
      "source": [
        "# MLM訓練\n",
        "\n",
        "bert_masked_model.fit(mlm_ds, epochs=5, callbacks=[generator_callback])\n",
        "bert_masked_model.save(\"bert_mlm_imdb.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ha0EIyvB98u",
        "outputId": "b6f0b0a4-b8fd-42f0-eb95-8cb48ad3d320"
      },
      "source": [
        "# 更了解輸入、輸出\n",
        "\n",
        "one_batch = mlm_ds.take(1)\n",
        "\n",
        "for one_ds in one_batch:\n",
        "    x, y, weights = one_ds\n",
        "    print(x)\n",
        "    print(y)\n",
        "    print(weights)\n",
        "\n",
        "    print(bert_masked_model.predict(one_batch))     # (batch_size, max_len, vocab_size): 預測出所有的機率。\n",
        "    "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[    9  2075   547 ...     0     0     0]\n",
            " [    1     4   303 ...     0     0     0]\n",
            " [    9 29999 29999 ...     0     0     0]\n",
            " ...\n",
            " [ 2849   549     3 ...     0     0     0]\n",
            " [   40 29999    66 ...     0     0     0]\n",
            " [  193  2684 10974 ... 11642     7   299]], shape=(128, 256), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[    9  2075   547 ...     0     0     0]\n",
            " [    1     4   303 ...     0     0     0]\n",
            " [    9   471    48 ...     0     0     0]\n",
            " ...\n",
            " [ 2849   549     3 ...     0     0     0]\n",
            " [   40    23    66 ...     0     0     0]\n",
            " [  193  2684 10974 ... 11642     7   299]], shape=(128, 256), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(128, 256), dtype=float64)\n",
            "(128, 256, 30000)\n",
            "[[[5.9711203e-07 7.2227135e-07 6.1290308e-07 ... 2.3189561e-06\n",
            "   5.3074524e-07 5.8734702e-07]\n",
            "  [5.9711124e-07 7.2226896e-07 6.1289751e-07 ... 2.3189484e-06\n",
            "   5.3074245e-07 5.8734503e-07]\n",
            "  [5.9711385e-07 7.2227289e-07 6.1289967e-07 ... 2.3189630e-06\n",
            "   5.3074587e-07 5.8734878e-07]\n",
            "  ...\n",
            "  [5.9711243e-07 7.2226908e-07 6.1290348e-07 ... 2.3189689e-06\n",
            "   5.3074660e-07 5.8734742e-07]\n",
            "  [5.9711351e-07 7.2227249e-07 6.1290461e-07 ... 2.3189752e-06\n",
            "   5.3074655e-07 5.8734844e-07]\n",
            "  [5.9711584e-07 7.2227596e-07 6.1290461e-07 ... 2.3189798e-06\n",
            "   5.3074859e-07 5.8735071e-07]]\n",
            "\n",
            " [[5.9711402e-07 7.2227169e-07 6.1290393e-07 ... 2.3189637e-06\n",
            "   5.3074643e-07 5.8734832e-07]\n",
            "  [5.9711164e-07 7.2226811e-07 6.1289563e-07 ... 2.3189457e-06\n",
            "   5.3074228e-07 5.8734486e-07]\n",
            "  [5.9711545e-07 7.2227272e-07 6.1290075e-07 ... 2.3189625e-06\n",
            "   5.3074518e-07 5.8734804e-07]\n",
            "  ...\n",
            "  [5.9711277e-07 7.2226959e-07 6.1290331e-07 ... 2.3189705e-06\n",
            "   5.3074643e-07 5.8734776e-07]\n",
            "  [5.9711311e-07 7.2227277e-07 6.1290484e-07 ... 2.3189739e-06\n",
            "   5.3074672e-07 5.8734810e-07]\n",
            "  [5.9711579e-07 7.2227584e-07 6.1290456e-07 ... 2.3189793e-06\n",
            "   5.3074854e-07 5.8735060e-07]]\n",
            "\n",
            " [[5.9711346e-07 7.2227101e-07 6.1290336e-07 ... 2.3189637e-06\n",
            "   5.3074643e-07 5.8734781e-07]\n",
            "  [5.9711095e-07 7.2226868e-07 6.1289728e-07 ... 2.3189496e-06\n",
            "   5.3074325e-07 5.8734474e-07]\n",
            "  [5.9711329e-07 7.2227152e-07 6.1289916e-07 ... 2.3189589e-06\n",
            "   5.3074535e-07 5.8734713e-07]\n",
            "  ...\n",
            "  [5.9711277e-07 7.2226959e-07 6.1290393e-07 ... 2.3189705e-06\n",
            "   5.3074643e-07 5.8734776e-07]\n",
            "  [5.9711334e-07 7.2227232e-07 6.1290444e-07 ... 2.3189702e-06\n",
            "   5.3074689e-07 5.8734776e-07]\n",
            "  [5.9711607e-07 7.2227618e-07 6.1290484e-07 ... 2.3189782e-06\n",
            "   5.3074774e-07 5.8735088e-07]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[5.9711317e-07 7.2227135e-07 6.1290427e-07 ... 2.3189607e-06\n",
            "   5.3074575e-07 5.8734702e-07]\n",
            "  [5.9711095e-07 7.2226868e-07 6.1289728e-07 ... 2.3189496e-06\n",
            "   5.3074325e-07 5.8734423e-07]\n",
            "  [5.9711482e-07 7.2227272e-07 6.1290069e-07 ... 2.3189646e-06\n",
            "   5.3074615e-07 5.8734969e-07]\n",
            "  ...\n",
            "  [5.9711289e-07 7.2226965e-07 6.1290399e-07 ... 2.3189707e-06\n",
            "   5.3074700e-07 5.8734901e-07]\n",
            "  [5.9711311e-07 7.2227277e-07 6.1290541e-07 ... 2.3189759e-06\n",
            "   5.3074626e-07 5.8734861e-07]\n",
            "  [5.9711556e-07 7.2227562e-07 6.1290496e-07 ... 2.3189787e-06\n",
            "   5.3074831e-07 5.8735043e-07]]\n",
            "\n",
            " [[5.9711340e-07 7.2227164e-07 6.1290393e-07 ... 2.3189614e-06\n",
            "   5.3074649e-07 5.8734832e-07]\n",
            "  [5.9711078e-07 7.2226709e-07 6.1289711e-07 ... 2.3189468e-06\n",
            "   5.3074262e-07 5.8734349e-07]\n",
            "  [5.9711408e-07 7.2227107e-07 6.1289984e-07 ... 2.3189618e-06\n",
            "   5.3074552e-07 5.8734901e-07]\n",
            "  ...\n",
            "  [5.9711277e-07 7.2227090e-07 6.1290388e-07 ... 2.3189680e-06\n",
            "   5.3074592e-07 5.8734776e-07]\n",
            "  [5.9711408e-07 7.2227249e-07 6.1290518e-07 ... 2.3189750e-06\n",
            "   5.3074649e-07 5.8734901e-07]\n",
            "  [5.9711488e-07 7.2227618e-07 6.1290604e-07 ... 2.3189782e-06\n",
            "   5.3074774e-07 5.8735088e-07]]\n",
            "\n",
            " [[5.9711334e-07 7.2227158e-07 6.1290325e-07 ... 2.3189634e-06\n",
            "   5.3074638e-07 5.8734719e-07]\n",
            "  [5.9711061e-07 7.2226828e-07 6.1289694e-07 ... 2.3189507e-06\n",
            "   5.3074297e-07 5.8734446e-07]\n",
            "  [5.9711397e-07 7.2227169e-07 6.1289927e-07 ... 2.3189614e-06\n",
            "   5.3074598e-07 5.8734832e-07]\n",
            "  ...\n",
            "  [5.9711198e-07 7.2227056e-07 6.1290416e-07 ... 2.3189691e-06\n",
            "   5.3074569e-07 5.8734747e-07]\n",
            "  [5.9711346e-07 7.2227175e-07 6.1290336e-07 ... 2.3189748e-06\n",
            "   5.3074547e-07 5.8734946e-07]\n",
            "  [5.9711499e-07 7.2227493e-07 6.1290439e-07 ... 2.3189764e-06\n",
            "   5.3074734e-07 5.8734992e-07]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMSMM_G9kd9o"
      },
      "source": [
        "### 結果\n",
        "- 根據觀察, cloze task並沒有訓練好, 故合理推測其實應沒有學習到應有的語意關係\n",
        "- 可能原因\n",
        "    - Encoder 太深\n",
        "    - 訓練資料不夠多"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUnuA19wPhqe"
      },
      "source": [
        "### BERT的強大 - Finetune\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJoCEf5ZPVul",
        "outputId": "b9bc0d63-bd50-4b99-d7c8-43e3e19afb33"
      },
      "source": [
        "# 使用預訓練模型\n",
        "mlm_model = keras.models.load_model(\n",
        "    \"bert_mlm_imdb.h5\", custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        ")\n",
        "\n",
        "pretrained_bert_model = tf.keras.Model(\n",
        "    mlm_model.input, mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output # 到這邊剛好是MLM分類任務前, 也就是學到的語意關係\n",
        ")\n",
        "\n",
        "# 凍結之前訓練的權重, 可選擇\n",
        "pretrained_bert_model.trainable = False\n",
        "\n",
        "def create_classifier_bert_model():\n",
        "    inputs = layers.Input((config.MAX_LEN,), dtype=tf.int64)\n",
        "    sequence_output = pretrained_bert_model(inputs)\n",
        "    pooled_output = layers.GlobalMaxPooling1D()(sequence_output)        # 類似flattn, 原先3維\n",
        "    hidden_layer = layers.Dense(64, activation=\"relu\")(pooled_output)   \n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)       # 二分類問題, 故Dense(1)\n",
        "    classifer_model = keras.Model(inputs, outputs, name=\"classification\")\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    classifer_model.compile(\n",
        "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return classifer_model\n",
        "\n",
        "classifer_model = create_classifier_bert_model()\n",
        "classifer_model.summary()\n",
        "\n",
        "# Train the classifier with frozen BERT stage(凍結下的訓練)\n",
        "classifer_model.fit(\n",
        "    train_classifier_ds,\n",
        "    epochs=5,\n",
        "    validation_data=test_classifier_ds,\n",
        ")\n",
        "\n",
        "# Unfreeze the BERT model for fine-tuning(不凍結下訓練, 代表MLM的參數也會跟著變動)\n",
        "pretrained_bert_model.trainable = True\n",
        "optimizer = keras.optimizers.Adam()\n",
        "classifer_model.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "classifer_model.fit(\n",
        "    train_classifier_ds,\n",
        "    epochs=5,\n",
        "    validation_data=test_classifier_ds,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, 256, 128)          3939584   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,947,905\n",
            "Trainable params: 8,321\n",
            "Non-trainable params: 3,939,584\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 15s 18ms/step - loss: 0.7165 - accuracy: 0.5016 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.7002 - accuracy: 0.5031 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6979 - accuracy: 0.5004 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6971 - accuracy: 0.4932 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6957 - accuracy: 0.4937 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 46s 57ms/step - loss: 0.6964 - accuracy: 0.4980 - val_loss: 0.7738 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.7762 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.7829 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.7551 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.7546 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f66983cae50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0-8CejpQa0y"
      },
      "source": [
        "### end-to-end\n",
        "- 之前的textvector之在資料集方面處理的, 也可以透過把layer embed 到model內, 得到end-to-end的模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK3ezbsrQmCM",
        "outputId": "5d4ea8ce-787e-433f-c0f0-8dba43a7b365"
      },
      "source": [
        "def get_end_to_end(model):\n",
        "    \"\"\"\n",
        "        基於原先的模型, 將輸入處多放入一個\"文本處理\"layer也就是: TextVectorization得到的layer,\n",
        "        就可以得到end-to-end model\n",
        "    \"\"\"\n",
        "    inputs_string = keras.Input(shape=(1,), dtype=\"string\")     # 文本(inputs)\n",
        "    indices = vectorize_layer(inputs_string)                    # 轉成向量\n",
        "    outputs = model(indices)                                    # outputs\n",
        "    end_to_end_model = keras.Model(inputs_string, outputs, name=\"end_to_end_model\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
        "    end_to_end_model.compile(\n",
        "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return end_to_end_model\n",
        "\n",
        "\n",
        "end_to_end_classification_model = get_end_to_end(classifer_model)\n",
        "end_to_end_classification_model.evaluate(test_raw_classifier_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 9s 10ms/step - loss: 0.7526 - accuracy: 0.5028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7545887231826782, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6O4_D98mIKp"
      },
      "source": [
        "### 修正\n",
        "- Encoder\n",
        "    12 -> 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLBaHurcmhlO",
        "outputId": "5c5bc28e-b1e6-42f9-c3f7-e7ea92bd4f51"
      },
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    MAX_LEN = 256\n",
        "    BATCH_SIZE = 128\n",
        "    LR = 0.001\n",
        "    VOCAB_SIZE = 30000\n",
        "    EMBED_DIM = 128\n",
        "    NUM_HEAD = 8  # used in bert model\n",
        "    FF_DIM = 128  # used in bert model\n",
        "    NUM_LAYERS = 1\n",
        "\n",
        "\n",
        "config = Config()\n",
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVwPtdZhRL5Q",
        "outputId": "3a9e6842-2564-427b-eb17-20e3cc91132f"
      },
      "source": [
        "sample_tokens = vectorize_layer([\"I have watched this [mask] and it was awesome\"])\n",
        "generator_callback = MaskedTextGenerator(sample_tokens.numpy())\n",
        "\n",
        "bert_masked_model_1layer = create_masked_language_bert_model()\n",
        "bert_masked_model_1layer.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"masked_bert_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 256, 128)     3840000     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_125 (TFOpL (None, 256, 128)     0           word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/multiheadattention (M (None, 256, 128)     66048       tf.__operators__.add_125[0][0]   \n",
            "                                                                 tf.__operators__.add_125[0][0]   \n",
            "                                                                 tf.__operators__.add_125[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_dropout (Dropout) (None, 256, 128)     0           encoder_0/multiheadattention[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_126 (TFOpL (None, 256, 128)     0           tf.__operators__.add_125[0][0]   \n",
            "                                                                 encoder_0/att_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/att_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_126[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn (Sequential)      (None, 256, 128)     33024       encoder_0/att_layernormalization[\n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_dropout (Dropout) (None, 256, 128)     0           encoder_0/ffn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_127 (TFOpL (None, 256, 128)     0           encoder_0/att_layernormalization[\n",
            "                                                                 encoder_0/ffn_dropout[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0/ffn_layernormalizatio (None, 256, 128)     256         tf.__operators__.add_127[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mlm_cls (Dense)                 (None, 256, 30000)   3870000     encoder_0/ffn_layernormalization[\n",
            "==================================================================================================\n",
            "Total params: 7,809,584\n",
            "Trainable params: 7,809,584\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAWh3lgjmtol",
        "outputId": "b955a5a3-ea05-4dbb-fc2d-a1bfb9ef6b80"
      },
      "source": [
        "bert_masked_model_1layer.fit(mlm_ds, epochs=5, callbacks=[generator_callback])\n",
        "bert_masked_model_1layer.save(\"bert_mlm_imdb_1layer.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 237s 151ms/step - loss: 7.1679\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66bcf44b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(1, 256, 30000)\n",
            "(array([0]), array([4]))\n",
            "[4]\n",
            "[[6.066066e-08 7.209404e-08 6.055639e-08 ... 2.872794e-06 5.329966e-07\n",
            "  7.219587e-08]]\n",
            "[10  9  3 19  5]\n",
            "[0.04216674 0.03485606 0.03185284 0.02736021 0.01999529]\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'this',\n",
            " 'prediction': 'i have watched this this and it was awesome',\n",
            " 'probability': 0.042166743}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'i',\n",
            " 'prediction': 'i have watched this i and it was awesome',\n",
            " 'probability': 0.03485606}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'a',\n",
            " 'prediction': 'i have watched this a and it was awesome',\n",
            " 'probability': 0.03185284}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie',\n",
            " 'prediction': 'i have watched this movie and it was awesome',\n",
            " 'probability': 0.027360214}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'of',\n",
            " 'prediction': 'i have watched this of and it was awesome',\n",
            " 'probability': 0.019995295}\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 235s 151ms/step - loss: 6.7003\n",
            "(1, 256, 30000)\n",
            "(array([0]), array([4]))\n",
            "[4]\n",
            "[[1.5941689e-08 1.7956349e-08 1.6543915e-08 ... 3.2054832e-06\n",
            "  8.1048036e-08 2.0439359e-08]]\n",
            "[  24   19    7 1371  236]\n",
            "[0.1442383  0.12774321 0.03840918 0.03824802 0.02276796]\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'film',\n",
            " 'prediction': 'i have watched this film and it was awesome',\n",
            " 'probability': 0.1442383}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie',\n",
            " 'prediction': 'i have watched this movie and it was awesome',\n",
            " 'probability': 0.12774321}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'is',\n",
            " 'prediction': 'i have watched this is and it was awesome',\n",
            " 'probability': 0.038409185}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie!',\n",
            " 'prediction': 'i have watched this movie! and it was awesome',\n",
            " 'probability': 0.03824802}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'worst',\n",
            " 'prediction': 'i have watched this worst and it was awesome',\n",
            " 'probability': 0.022767955}\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 235s 151ms/step - loss: 6.1178\n",
            "(1, 256, 30000)\n",
            "(array([0]), array([4]))\n",
            "[4]\n",
            "[[2.9248046e-09 3.0976881e-09 2.8288334e-09 ... 4.0698313e-07\n",
            "  8.3580813e-09 3.1841361e-09]]\n",
            "[  19 1371   24  236   28]\n",
            "[0.24436265 0.10856409 0.0889897  0.03967827 0.02818749]\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie',\n",
            " 'prediction': 'i have watched this movie and it was awesome',\n",
            " 'probability': 0.24436265}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie!',\n",
            " 'prediction': 'i have watched this movie! and it was awesome',\n",
            " 'probability': 0.10856409}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'film',\n",
            " 'prediction': 'i have watched this film and it was awesome',\n",
            " 'probability': 0.088989705}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'worst',\n",
            " 'prediction': 'i have watched this worst and it was awesome',\n",
            " 'probability': 0.03967827}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'one',\n",
            " 'prediction': 'i have watched this one and it was awesome',\n",
            " 'probability': 0.028187485}\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 236s 151ms/step - loss: 5.6985\n",
            "(1, 256, 30000)\n",
            "(array([0]), array([4]))\n",
            "[4]\n",
            "[[3.6879197e-10 3.9983994e-10 3.6787795e-10 ... 1.0033107e-07\n",
            "  1.0423412e-09 3.7345885e-10]]\n",
            "[  19   24 1371  103  122]\n",
            "[0.5538519  0.130241   0.07007366 0.04236298 0.01845231]\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie',\n",
            " 'prediction': 'i have watched this movie and it was awesome',\n",
            " 'probability': 0.5538519}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'film',\n",
            " 'prediction': 'i have watched this film and it was awesome',\n",
            " 'probability': 0.130241}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie!',\n",
            " 'prediction': 'i have watched this movie! and it was awesome',\n",
            " 'probability': 0.07007366}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie.',\n",
            " 'prediction': 'i have watched this movie. and it was awesome',\n",
            " 'probability': 0.04236298}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'film.',\n",
            " 'prediction': 'i have watched this film. and it was awesome',\n",
            " 'probability': 0.018452313}\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 236s 151ms/step - loss: 5.2289\n",
            "(1, 256, 30000)\n",
            "(array([0]), array([4]))\n",
            "[4]\n",
            "[[1.0933817e-11 1.2226158e-11 1.0941828e-11 ... 1.0728989e-07\n",
            "  2.4392388e-10 1.2207028e-11]]\n",
            "[  19   24 1048  103  789]\n",
            "[0.4460333  0.33436406 0.01941711 0.01724243 0.01374847]\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie',\n",
            " 'prediction': 'i have watched this movie and it was awesome',\n",
            " 'probability': 0.4460333}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'film',\n",
            " 'prediction': 'i have watched this film and it was awesome',\n",
            " 'probability': 0.33436406}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'sequel',\n",
            " 'prediction': 'i have watched this sequel and it was awesome',\n",
            " 'probability': 0.019417105}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'movie.',\n",
            " 'prediction': 'i have watched this movie. and it was awesome',\n",
            " 'probability': 0.017242432}\n",
            "{'input_text': 'i have watched this [mask] and it was awesome',\n",
            " 'predicted mask token': 'flick',\n",
            " 'prediction': 'i have watched this flick and it was awesome',\n",
            " 'probability': 0.013748465}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXmCGABenCXv",
        "outputId": "a1af46f1-d04a-47dd-9a7b-274bfd43b31e"
      },
      "source": [
        "def user_bert_for_pretrained(model_file='bert_mlm_imdb_1layer.h5'):# 使用預訓練模型\n",
        "    mlm_model = keras.models.load_model(\n",
        "        model_file, custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        "    )\n",
        "\n",
        "    pretrained_bert_model = tf.keras.Model(\n",
        "        mlm_model.input, mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output # 到這邊剛好是MLM分類任務前, 也就是學到的語意關係\n",
        "    )\n",
        "\n",
        "    # 凍結之前訓練的權重, 可選擇\n",
        "    pretrained_bert_model.trainable = False\n",
        "\n",
        "    def create_classifier_bert_model():\n",
        "        inputs = layers.Input((config.MAX_LEN,), dtype=tf.int64)\n",
        "        sequence_output = pretrained_bert_model(inputs)\n",
        "        pooled_output = layers.GlobalMaxPooling1D()(sequence_output)        # 類似flattn, 原先3維\n",
        "        hidden_layer = layers.Dense(64, activation=\"relu\")(pooled_output)   \n",
        "        outputs = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)       # 二分類問題, 故Dense(1)\n",
        "        classifer_model = keras.Model(inputs, outputs, name=\"classification\")\n",
        "        optimizer = keras.optimizers.Adam()\n",
        "        classifer_model.compile(\n",
        "            optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        "        )\n",
        "        return classifer_model\n",
        "\n",
        "    classifer_model = create_classifier_bert_model()\n",
        "    classifer_model.summary()\n",
        "\n",
        "    # Train the classifier with frozen BERT stage(凍結下的訓練)\n",
        "    classifer_model.fit(\n",
        "        train_classifier_ds,\n",
        "        epochs=5,\n",
        "        validation_data=test_classifier_ds,\n",
        "    )\n",
        "\n",
        "    # Unfreeze the BERT model for fine-tuning(不凍結下訓練, 代表MLM的參數也會跟著變動)\n",
        "    pretrained_bert_model.trainable = True\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    classifer_model.compile(\n",
        "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    classifer_model.fit(\n",
        "        train_classifier_ds,\n",
        "        epochs=5,\n",
        "        validation_data=test_classifier_ds,\n",
        "    )\n",
        "    return classifer_model\n",
        "\n",
        "classifier_bert_1layer = user_bert_for_pretrained()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "model_2 (Functional)         (None, 256, 128)          3939584   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,947,905\n",
            "Trainable params: 8,321\n",
            "Non-trainable params: 3,939,584\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 15s 18ms/step - loss: 0.7533 - accuracy: 0.5322 - val_loss: 0.6586 - val_accuracy: 0.6062\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6702 - accuracy: 0.5928 - val_loss: 0.6525 - val_accuracy: 0.6181\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6597 - accuracy: 0.6091 - val_loss: 0.6491 - val_accuracy: 0.6174\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6551 - accuracy: 0.6148 - val_loss: 0.6963 - val_accuracy: 0.5622\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6492 - accuracy: 0.6221 - val_loss: 0.6774 - val_accuracy: 0.5808\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 49s 61ms/step - loss: 0.5724 - accuracy: 0.6957 - val_loss: 0.3667 - val_accuracy: 0.8364\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.3046 - accuracy: 0.8714 - val_loss: 0.3885 - val_accuracy: 0.8316\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.1467 - accuracy: 0.9434 - val_loss: 0.4810 - val_accuracy: 0.8376\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.6785 - val_accuracy: 0.8339\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 47s 59ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.8669 - val_accuracy: 0.8154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyyQGZGqm0Vv",
        "outputId": "f961b44a-41a2-4bad-83df-f737de1df174"
      },
      "source": [
        "classifier_bert_1layer.evaluate(test_classifier_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8669 - accuracy: 0.8154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8669344782829285, 0.8154000043869019]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMLSpfNGo0sN"
      },
      "source": [
        "### Encoder layers改變結果\n",
        "- 可以發現第一個epoch loss就降得很快, 測試語句也很快的找出正確答案, 可以得知有部分抓取語意。\n",
        "- 另外也發現, 有沒有凍結參數效果差很多, 如果沒有凍結, 效果fine tune得很快, 但結論有待商榷。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CIbYC1ZoJrw"
      },
      "source": [
        "> 下次加超參數fine-tune、NSP任務、wordpiece等等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0dRfhnPoTGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
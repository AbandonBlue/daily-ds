{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-new-layer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_-2t5z3pFsZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFa-wRspVne"
      },
      "source": [
        "# 透過keras layer創建一個自己的dense-layer\n",
        "# 參數在Layer會自動追蹤\n",
        "\n",
        "class DenseLayer(layers.Layer):\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        b_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype='float32'),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=b_init(shape=(units,), dtype='float32'),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "# class Linear(keras.layers.Layer):\n",
        "#     def __init__(self, units=32, input_dim=32):\n",
        "#         super(Linear, self).__init__()\n",
        "#         w_init = tf.random_normal_initializer()\n",
        "#         self.w = tf.Variable(\n",
        "#             initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "#             trainable=True,\n",
        "#         )\n",
        "#         b_init = tf.zeros_initializer()\n",
        "#         self.b = tf.Variable(\n",
        "#             initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
        "#         )\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVlnjQHcqatR",
        "outputId": "0a1ecb07-a97e-47db-8803-9d015e55a7a5"
      },
      "source": [
        "x = tf.ones((3, 3))\n",
        "linear_layer = DenseLayer(4, 3)\n",
        "# linear_layer = Linear(4, 3)\n",
        "y = linear_layer(x)\n",
        "\n",
        "y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[ 0.1382047 , -0.0191696 ,  0.19688514, -0.01656014],\n",
              "       [ 0.1382047 , -0.0191696 ,  0.19688514, -0.01656014],\n",
              "       [ 0.1382047 , -0.0191696 ,  0.19688514, -0.01656014]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VtQKa_FqrZo"
      },
      "source": [
        "assert linear_layer.weights == [linear_layer.w, linear_layer.b]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBq30QvsHDq"
      },
      "source": [
        "# 但上面比較繁瑣，可以透過add_weight()幫助快速建立模型參數\n",
        "\n",
        "class Linear(layers.Layer):\n",
        "    def __init__(self, input_dim, units):\n",
        "        super(Linear, self).__init__()\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_dim, units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65V_fuphs7dX",
        "outputId": "7924b2a7-cf96-4789-a78f-3fdde9474c7d"
      },
      "source": [
        "x = tf.ones((12, 3))\n",
        "la = Linear(3, 20)\n",
        "y = la(x)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]\n",
            " [-0.01628886  0.0107303  -0.15734124  0.02500769  0.02952196  0.02679781\n",
            "   0.05750535  0.01565486 -0.00667565 -0.03137799  0.03977148  0.1601704\n",
            "   0.04061134 -0.08541013  0.06478705 -0.13211325  0.05892086  0.02591803\n",
            "   0.04086535  0.01551829]], shape=(12, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0ibusxttE91",
        "outputId": "89b6d2d7-9922-4972-dde3-88e19d7e8698"
      },
      "source": [
        "# 模型內也可以有不可訓練參數，誤差反向傳地就會不記錄其梯度\n",
        "\n",
        "\n",
        "class ComputeSum(layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeSum, self).__init__()\n",
        "        self.total = tf.Variable(\n",
        "            initial_value=tf.ones(input_dim,),\n",
        "            trainable=False\n",
        "        )\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
        "        # https://www.tensorflow.org/api_docs/python/tf/Variable#assign_add\n",
        "        return self.total\n",
        "\n",
        "\n",
        "\n",
        "x = tf.ones((3, 6))\n",
        "cs = ComputeSum(6)\n",
        "y = cs(x)\n",
        "print(y.numpy())        # [1+3]*6\n",
        "\n",
        "y = cs(x)\n",
        "print(y.numpy())        # [4 + 3] * 6"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4. 4. 4. 4. 4. 4.]\n",
            "[7. 7. 7. 7. 7. 7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mniFHsXFukfo",
        "outputId": "3e421fc0-42f4-4a21-ab95-73fcaec98956"
      },
      "source": [
        "# 觀看layer的權重資訊\n",
        "\n",
        "print(len(cs.weights))\n",
        "\n",
        "print(len(cs.non_trainable_weights))\n",
        "\n",
        "print(len(cs.trainable_weights))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwhdZj19vtL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58cadfe9-63ec-4952-ba5a-9514abfb5b67"
      },
      "source": [
        "cs.trainable_weights"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMhZn0dPvwG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fef23a2-729d-429e-a0a4-1960b45ba054"
      },
      "source": [
        "cs.non_trainable_variables"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=(6,) dtype=float32, numpy=array([7., 7., 7., 7., 7., 7.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhREJi0EvxxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2bba762-82f1-494b-8e25-b673a9638e7c"
      },
      "source": [
        "cs.non_trainable_weights"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=(6,) dtype=float32, numpy=array([7., 7., 7., 7., 7., 7.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wcyt65zvzde"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2WhigGhE1dX"
      },
      "source": [
        "### 最好的應用狀況是: 當不知道input_shape時, layer參數不好設定\n",
        "- 透過keras api 的 build function去實現!\n",
        "- 注意: The __call__() method of your layer will automatically run build the first time it is called. You now have a layer that's lazy and thus easier to use:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt3Vad-uFBi8"
      },
      "source": [
        "class Linear(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(Linear, self).__init__()\n",
        "        self.units = units\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units, ),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "    \n",
        "    def call(self, x):\n",
        "        return tf.matmul(x, self.w) + self.b"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfgZZya-GOjZ",
        "outputId": "58cd14b0-3728-4574-9815-54c21ebefb14"
      },
      "source": [
        "# 起初不知道input_shape\n",
        "linear = Linear(32)\n",
        "\n",
        "# dummy data\n",
        "x = tf.ones((16000, 128))\n",
        "\n",
        "# 動態建立參數\n",
        "y = linear(x)\n",
        "\n",
        "print(y.shape)\n",
        "\n",
        "del x, y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6UJIEVrGtaC",
        "outputId": "197ee21c-98ee-4386-9e84-f6d43c46ea75"
      },
      "source": [
        "# Layers are recursively composable\n",
        "# If you assign a Layer instance as attribute of another Layer, the outer layer will start tracking the weights of the inner layer.\n",
        "# 很方便, 會自動追蹤，才可以巢狀建立layer\n",
        "# We recommend creating such sublayers in the __init__() method (since the sublayers will typically have a build method, they will be built when the outer layer gets built).\n",
        "# 會自動建立, 實際上也是有build的!\n",
        "\n",
        "# Let's assume we are reusing the Linear class\n",
        "# with a `build` method that we defined above.\n",
        "\n",
        "\n",
        "class MLPBlock(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        self.linear_1 = Linear(32)\n",
        "        self.linear_2 = Linear(32)\n",
        "        self.linear_3 = Linear(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return self.linear_3(x)\n",
        "\n",
        "\n",
        "mlp = MLPBlock()\n",
        "y = mlp(tf.ones(shape=(3, 64)))  # The first call to the `mlp` will create the weights\n",
        "print(\"weights:\", len(mlp.weights))\n",
        "print(\"trainable weights:\", len(mlp.trainable_weights))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 6\n",
            "trainable weights: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30FQt3VgIIF3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
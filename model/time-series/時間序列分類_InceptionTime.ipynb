{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "時間序列分類 - InceptionTime.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fucAU-iH6rN"
      },
      "source": [
        "## 簡介\n",
        "- InceptionTime模型為一深度學習時間序列分類模型，透過conv1d截取不同的時間序列patter，類似GoogleNet的概念建立模型。\n",
        "- 像是CNN類高層layer抓取細緻的pattern, 低層layer抓取粗略的pattern，InceptionTime也是依此原理(因為conv1d)。\n",
        "- 在深度學習方法算是快速有效率。\n",
        "- 2018論文"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZHNUekQGy7A"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WHZpXA9V89M"
      },
      "source": [
        "# load the dataset\n",
        "\n",
        "# 法一\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhItxdMyWUPe"
      },
      "source": [
        "train = pd.read_csv(root_url + \"FordA_TRAIN.tsv\", sep='\\t', header=None)\n",
        "test = pd.read_csv(root_url + \"FordA_TEST.tsv\", sep='\\t', header=None)\n",
        "\n",
        "x_train, y_train = train.iloc[:, 1:].values, train.iloc[:, 0].values\n",
        "x_test, y_test = test.iloc[:, 1:].values, test.iloc[:, 0].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz3Cp3FeV--2",
        "outputId": "17d404cd-6c12-47f4-e7f4-70814348f07b"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3601, 500), (3601,), (1320, 500), (1320,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpdi1bb7WHqD",
        "outputId": "81a53e32-ccd3-4a54-fd9c-706b8b85f164"
      },
      "source": [
        "# reshape\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], -1)\n",
        "\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3601, 500, 1), (1320, 500, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9hvKwbWLUh"
      },
      "source": [
        "# 其實也可以.fit的時候shuffle=True\n",
        "# permute\n",
        "\n",
        "idx = np.random.permutation(len(train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7AGsNrhWNwP",
        "outputId": "a7d816d7-37ed-483d-c74f-66f8528e4897"
      },
      "source": [
        "# label -1 ---> 0\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0\n",
        "\n",
        "np.unique(y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVdHHu44I25P"
      },
      "source": [
        "### Inception Module\n",
        "- 最關鍵的Module, 類似GoogleNet的Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_voI6sNIxRv"
      },
      "source": [
        "class InceptionModule(layers.Layer):\n",
        "    def __init__(self, filters=32, **kwargs):\n",
        "        super(InceptionModule, self).__init__(**kwargs)\n",
        "\n",
        "        self.bottleneck = self._default_conv1d(filters, kernel_size=1)\n",
        "        self.maxpool1d = layers.MaxPool1D(pool_size=3, strides=1, padding='same')\n",
        "        self.conv1d_1 = self._default_conv1d(filters, kernel_size=10)\n",
        "        self.conv1d_2 = self._default_conv1d(filters, kernel_size=20)\n",
        "        self.conv1d_3 = self._default_conv1d(filters, kernel_size=40)\n",
        "        self.conv1d_4 = self._default_conv1d(filters, kernel_size=1)\n",
        "        self.concate = layers.Concatenate(axis=2)\n",
        "        self.batch_norm = layers.BatchNormalization()\n",
        "        self.activation = layers.ReLU()\n",
        "\n",
        "    def _default_conv1d(self, filters, kernel_size):\n",
        "        return layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, padding='same', activation='relu', use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        bottleneck = self.bottleneck(x)\n",
        "        conv1d_1 = self.conv1d_1(bottleneck)\n",
        "        conv1d_2 = self.conv1d_2(bottleneck)\n",
        "        conv1d_3 = self.conv1d_3(bottleneck)\n",
        "\n",
        "        maxpool1d = self.maxpool1d(x)\n",
        "        conv1d_4 = self.conv1d_4(maxpool1d)\n",
        "\n",
        "        return self.activation(self.batch_norm(self.concate([conv1d_1, conv1d_2, conv1d_3, conv1d_4])))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lRdDed0LlZU"
      },
      "source": [
        "def get_model_inceptionTime(x, n_module, units=[32, 16], output_units=1):\n",
        "    inputs = layers.Input(shape=(x.shape[1:]))\n",
        "    x = inputs\n",
        "\n",
        "    for i in range(n_module):\n",
        "        if i % 3 == 2:\n",
        "            previout_x = x\n",
        "            x = InceptionModule()(x) + previout_x\n",
        "        else:\n",
        "            x = InceptionModule()(x)\n",
        "    \n",
        "    outputs = layers.GlobalAveragePooling1D()(x)\n",
        "    for unit in units:\n",
        "        outputs = layers.Dense(units=unit, activation='relu')(outputs)\n",
        "    outputs = layers.Dense(units=output_units, activation='softmax')(outputs)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model   "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5onfiL-QiDk"
      },
      "source": [
        "model_1 = get_model_inceptionTime(x_train, 3, [32, 16], 2)\n",
        "model_2 = get_model_inceptionTime(x_train, 3, [32, 16], 2)\n",
        "model_3 = get_model_inceptionTime(x_train, 3, [32, 16], 2)\n",
        "model_4 = get_model_inceptionTime(x_train, 3, [32, 16], 2)\n",
        "# model.build(input_shape=x.shape)\n",
        "# model.summary()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj9Q9DK_QygF"
      },
      "source": [
        "# tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7JNvEFzVq9J",
        "outputId": "c649a6a7-e02f-4bb9-f6ae-4ceb1a042586"
      },
      "source": [
        "# 模型訓練\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "\n",
        "# 存最好的、lr下降、提早停止\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model_1.h5', save_best_only=True, monitor='val_loss'\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=50, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "history_1 = model_1.fit(\n",
        "    x_train, y_train, batch_size, epochs, validation_split=0.2, verbose=1\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 4s 20ms/step - loss: 0.4860 - acc: 0.7347 - val_loss: 0.2912 - val_acc: 0.8641\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.2210 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.8877\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2018 - acc: 0.9191 - val_loss: 0.2513 - val_acc: 0.8932\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1994 - acc: 0.9208 - val_loss: 0.2165 - val_acc: 0.9182\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1697 - acc: 0.9330 - val_loss: 0.1889 - val_acc: 0.9154\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1683 - acc: 0.9358 - val_loss: 0.1938 - val_acc: 0.9293\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1495 - acc: 0.9378 - val_loss: 0.3322 - val_acc: 0.8793\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1460 - acc: 0.9396 - val_loss: 0.1730 - val_acc: 0.9307\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1591 - acc: 0.9385 - val_loss: 0.1802 - val_acc: 0.9376\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1408 - acc: 0.9441 - val_loss: 0.2169 - val_acc: 0.9057\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1311 - acc: 0.9497 - val_loss: 0.1689 - val_acc: 0.9265\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1256 - acc: 0.9497 - val_loss: 0.2141 - val_acc: 0.9279\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1292 - acc: 0.9500 - val_loss: 0.1536 - val_acc: 0.9376\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1360 - acc: 0.9424 - val_loss: 0.1502 - val_acc: 0.9417\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1143 - acc: 0.9556 - val_loss: 0.1679 - val_acc: 0.9334\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1114 - acc: 0.9583 - val_loss: 0.1578 - val_acc: 0.9390\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1025 - acc: 0.9611 - val_loss: 0.1538 - val_acc: 0.9348\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1182 - acc: 0.9556 - val_loss: 0.1543 - val_acc: 0.9431\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1241 - acc: 0.9493 - val_loss: 0.1670 - val_acc: 0.9293\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1015 - acc: 0.9604 - val_loss: 0.1723 - val_acc: 0.9445\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0896 - acc: 0.9681 - val_loss: 0.1881 - val_acc: 0.9334\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0974 - acc: 0.9656 - val_loss: 0.1590 - val_acc: 0.9445\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0809 - acc: 0.9701 - val_loss: 0.1682 - val_acc: 0.9390\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0788 - acc: 0.9691 - val_loss: 0.1645 - val_acc: 0.9390\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0714 - acc: 0.9712 - val_loss: 0.1592 - val_acc: 0.9376\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0734 - acc: 0.9729 - val_loss: 0.2409 - val_acc: 0.9209\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0746 - acc: 0.9694 - val_loss: 0.1836 - val_acc: 0.9362\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0796 - acc: 0.9667 - val_loss: 0.1743 - val_acc: 0.9445\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0833 - acc: 0.9681 - val_loss: 0.1628 - val_acc: 0.9417\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0864 - acc: 0.9694 - val_loss: 0.1887 - val_acc: 0.9362\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0680 - acc: 0.9740 - val_loss: 0.1981 - val_acc: 0.9348\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0639 - acc: 0.9764 - val_loss: 0.1661 - val_acc: 0.9417\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0520 - acc: 0.9837 - val_loss: 0.1839 - val_acc: 0.9362\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0745 - acc: 0.9715 - val_loss: 0.1708 - val_acc: 0.9390\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0409 - acc: 0.9844 - val_loss: 0.2154 - val_acc: 0.9431\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0355 - acc: 0.9882 - val_loss: 0.2338 - val_acc: 0.9390\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0430 - acc: 0.9830 - val_loss: 0.2303 - val_acc: 0.9209\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0481 - acc: 0.9837 - val_loss: 0.3136 - val_acc: 0.9265\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0401 - acc: 0.9844 - val_loss: 0.2406 - val_acc: 0.9362\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0565 - acc: 0.9778 - val_loss: 0.2137 - val_acc: 0.9348\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0440 - acc: 0.9833 - val_loss: 0.2202 - val_acc: 0.9390\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0413 - acc: 0.9837 - val_loss: 0.2212 - val_acc: 0.9348\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0219 - acc: 0.9913 - val_loss: 0.2602 - val_acc: 0.9390\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0269 - acc: 0.9924 - val_loss: 0.2641 - val_acc: 0.9404\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0189 - acc: 0.9948 - val_loss: 0.2795 - val_acc: 0.9320\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0673 - acc: 0.9774 - val_loss: 0.2444 - val_acc: 0.9376\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0380 - acc: 0.9837 - val_loss: 0.2616 - val_acc: 0.9376\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.2600 - val_acc: 0.9376\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0499 - acc: 0.9833 - val_loss: 0.2078 - val_acc: 0.9348\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0187 - acc: 0.9948 - val_loss: 0.2240 - val_acc: 0.9487\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.3072 - val_acc: 0.9376\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 0.3658 - val_acc: 0.9307\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.3084 - val_acc: 0.9417\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.2667 - val_acc: 0.9404\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.3575 - val_acc: 0.9293\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.4077 - val_acc: 0.9307\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0935 - acc: 0.9667 - val_loss: 0.2205 - val_acc: 0.9279\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.2764 - val_acc: 0.9334\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.2807 - val_acc: 0.9417\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.2735 - val_acc: 0.9431\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0339 - acc: 0.9892 - val_loss: 0.2101 - val_acc: 0.9390\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0258 - acc: 0.9910 - val_loss: 0.2954 - val_acc: 0.9320\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0284 - acc: 0.9903 - val_loss: 0.2936 - val_acc: 0.9431\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0241 - acc: 0.9910 - val_loss: 0.2797 - val_acc: 0.9417\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.3771 - val_acc: 0.9209\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.3482 - val_acc: 0.9376\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.3728 - val_acc: 0.9293\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.5027 - val_acc: 0.9223\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0525 - acc: 0.9812 - val_loss: 0.2351 - val_acc: 0.9404\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0099 - acc: 0.9983 - val_loss: 0.2941 - val_acc: 0.9459\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.3146 - val_acc: 0.9417\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.3323 - val_acc: 0.9431\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.3452 - val_acc: 0.9390\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.3537 - val_acc: 0.9390\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.3875 - val_acc: 0.9404\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.5132 - val_acc: 0.9279\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0889 - acc: 0.9712 - val_loss: 0.2555 - val_acc: 0.9251\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0199 - acc: 0.9920 - val_loss: 0.3210 - val_acc: 0.9320\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.3306 - val_acc: 0.9362\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.3542 - val_acc: 0.9334\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.4030 - val_acc: 0.9237\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.3828 - val_acc: 0.9376\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.4292 - val_acc: 0.9376\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.4018 - val_acc: 0.9390\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.9202e-04 - acc: 0.9997 - val_loss: 0.4551 - val_acc: 0.9390\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.3173e-04 - acc: 0.9997 - val_loss: 0.4997 - val_acc: 0.9320\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.5765e-04 - acc: 1.0000 - val_loss: 0.5475 - val_acc: 0.9348\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.9913e-04 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.9251\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.5525 - val_acc: 0.9334\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1098 - acc: 0.9642 - val_loss: 0.2104 - val_acc: 0.9362\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0292 - acc: 0.9892 - val_loss: 0.3106 - val_acc: 0.9348\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.2951 - val_acc: 0.9348\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0562 - acc: 0.9792 - val_loss: 0.2979 - val_acc: 0.9237\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0168 - acc: 0.9934 - val_loss: 0.3159 - val_acc: 0.9307\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.3253 - val_acc: 0.9293\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0075 - acc: 0.9972 - val_loss: 0.3547 - val_acc: 0.9348\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.4012 - val_acc: 0.9390\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.4299 - val_acc: 0.9334\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.4859e-04 - acc: 1.0000 - val_loss: 0.4511 - val_acc: 0.9376\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.7554e-04 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9390\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9568e-04 - acc: 1.0000 - val_loss: 0.4741 - val_acc: 0.9390\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5007e-04 - acc: 1.0000 - val_loss: 0.4873 - val_acc: 0.9390\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1123e-04 - acc: 1.0000 - val_loss: 0.4973 - val_acc: 0.9390\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0352e-04 - acc: 1.0000 - val_loss: 0.5071 - val_acc: 0.9390\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.0404e-05 - acc: 1.0000 - val_loss: 0.5175 - val_acc: 0.9376\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.6400e-05 - acc: 1.0000 - val_loss: 0.5244 - val_acc: 0.9376\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.4827e-05 - acc: 1.0000 - val_loss: 0.5310 - val_acc: 0.9376\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.7450e-05 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.9376\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3834e-05 - acc: 1.0000 - val_loss: 0.5438 - val_acc: 0.9390\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.6390e-05 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.9376\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4120e-05 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.9390\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.0065e-05 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.9390\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.6310e-05 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.9376\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.4268e-05 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.9376\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.1994e-05 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.9376\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9842e-05 - acc: 1.0000 - val_loss: 0.5832 - val_acc: 0.9376\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8577e-05 - acc: 1.0000 - val_loss: 0.5890 - val_acc: 0.9390\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6680e-05 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.9390\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5121e-05 - acc: 1.0000 - val_loss: 0.5990 - val_acc: 0.9376\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4078e-05 - acc: 1.0000 - val_loss: 0.6033 - val_acc: 0.9390\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2832e-05 - acc: 1.0000 - val_loss: 0.6078 - val_acc: 0.9390\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1763e-05 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.9376\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0994e-05 - acc: 1.0000 - val_loss: 0.6166 - val_acc: 0.9390\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0381e-05 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.9390\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.3629e-06 - acc: 1.0000 - val_loss: 0.6258 - val_acc: 0.9390\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.8830e-06 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 0.9390\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.2961e-06 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.9376\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.4088e-06 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.9390\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.8835e-06 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.9376\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.5143e-06 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.9376\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.8825e-06 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.9376\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.2691e-06 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.9376\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.5644e-06 - acc: 1.0000 - val_loss: 0.6659 - val_acc: 0.9362\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8268e-06 - acc: 1.0000 - val_loss: 0.6727 - val_acc: 0.9376\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.3924e-06 - acc: 1.0000 - val_loss: 0.6803 - val_acc: 0.9390\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.0402e-06 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.9376\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.4891e-06 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.9390\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.3340e-06 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 0.9390\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.1252e-06 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.9376\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.7659e-06 - acc: 1.0000 - val_loss: 0.7186 - val_acc: 0.9390\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5864e-06 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 0.9404\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3464e-06 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.9390\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0093e-06 - acc: 1.0000 - val_loss: 0.7700 - val_acc: 0.9390\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.4366e-07 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.9390\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.3144e-07 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.9390\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.8711e-07 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.9404\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.3144e-07 - acc: 1.0000 - val_loss: 0.8200 - val_acc: 0.9390\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.7455e-07 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.9404\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3481e-07 - acc: 1.0000 - val_loss: 0.8454 - val_acc: 0.9404\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.4649e-07 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.9376\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9462e-07 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.9404\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.2165e-07 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.9390\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.0485e-07 - acc: 1.0000 - val_loss: 0.8805 - val_acc: 0.9390\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.8097e-07 - acc: 1.0000 - val_loss: 0.8897 - val_acc: 0.9404\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6284e-07 - acc: 1.0000 - val_loss: 0.8968 - val_acc: 0.9376\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.5108e-07 - acc: 1.0000 - val_loss: 0.9017 - val_acc: 0.9376\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.1478e-07 - acc: 1.0000 - val_loss: 0.9184 - val_acc: 0.9404\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.0121e-07 - acc: 1.0000 - val_loss: 0.9286 - val_acc: 0.9404\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.6263e-07 - acc: 1.0000 - val_loss: 0.9401 - val_acc: 0.9362\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.7202e-07 - acc: 1.0000 - val_loss: 0.9483 - val_acc: 0.9404\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5555e-07 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.9390\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4396e-07 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.9404\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5203e-07 - acc: 1.0000 - val_loss: 0.9602 - val_acc: 0.9404\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5377e-07 - acc: 1.0000 - val_loss: 0.9673 - val_acc: 0.9404\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3436e-07 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.9376\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2509e-07 - acc: 1.0000 - val_loss: 0.9873 - val_acc: 0.9404\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1573e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9404\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1130e-07 - acc: 1.0000 - val_loss: 1.0020 - val_acc: 0.9404\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.8347e-08 - acc: 1.0000 - val_loss: 1.0089 - val_acc: 0.9404\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.2842e-08 - acc: 1.0000 - val_loss: 1.0146 - val_acc: 0.9404\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.1683e-08 - acc: 1.0000 - val_loss: 1.0224 - val_acc: 0.9390\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3841e-07 - acc: 1.0000 - val_loss: 1.0314 - val_acc: 0.9390\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0840e-07 - acc: 1.0000 - val_loss: 1.0210 - val_acc: 0.9390\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.6327e-08 - acc: 1.0000 - val_loss: 1.0309 - val_acc: 0.9390\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.3222e-08 - acc: 1.0000 - val_loss: 1.0359 - val_acc: 0.9376\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.8562e-08 - acc: 1.0000 - val_loss: 1.0413 - val_acc: 0.9376\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.5657e-08 - acc: 1.0000 - val_loss: 1.0445 - val_acc: 0.9376\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.3164e-08 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.9404\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.7369e-08 - acc: 1.0000 - val_loss: 1.0580 - val_acc: 0.9390\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.2982e-08 - acc: 1.0000 - val_loss: 1.0639 - val_acc: 0.9390\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.3975e-08 - acc: 1.0000 - val_loss: 1.0705 - val_acc: 0.9390\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.6483e-08 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.9417\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.2568e-08 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.9404\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.9712e-08 - acc: 1.0000 - val_loss: 1.0833 - val_acc: 0.9390\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.4993e-08 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.9390\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9529e-08 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.9376\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.2799e-08 - acc: 1.0000 - val_loss: 1.0968 - val_acc: 0.9376\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.9654e-08 - acc: 1.0000 - val_loss: 1.1012 - val_acc: 0.9390\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4645e-08 - acc: 1.0000 - val_loss: 1.1103 - val_acc: 0.9417\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9612e-08 - acc: 1.0000 - val_loss: 1.1166 - val_acc: 0.9417\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.4148e-08 - acc: 1.0000 - val_loss: 1.1127 - val_acc: 0.9404\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.1748e-08 - acc: 1.0000 - val_loss: 1.1193 - val_acc: 0.9404\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.0465e-08 - acc: 1.0000 - val_loss: 1.1220 - val_acc: 0.9404\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7898e-08 - acc: 1.0000 - val_loss: 1.1264 - val_acc: 0.9376\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.9388e-08 - acc: 1.0000 - val_loss: 1.1322 - val_acc: 0.9404\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.3362e-08 - acc: 1.0000 - val_loss: 1.1348 - val_acc: 0.9404\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.5166e-08 - acc: 1.0000 - val_loss: 1.1354 - val_acc: 0.9376\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7857e-08 - acc: 1.0000 - val_loss: 1.1383 - val_acc: 0.9390\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7236e-08 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.9404\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.2310e-08 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.9390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7wM1F6HaHO-",
        "outputId": "12af9f2c-847a-4e04-eee2-bd03d857914d"
      },
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model_2.h5', save_best_only=True, monitor='val_loss'\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=50, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    x_train, y_train, batch_size, epochs, validation_split=0.2, verbose=1\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 4s 21ms/step - loss: 0.4178 - acc: 0.7990 - val_loss: 0.2419 - val_acc: 0.9001\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2203 - acc: 0.9132 - val_loss: 0.2031 - val_acc: 0.9237\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1894 - acc: 0.9288 - val_loss: 0.1851 - val_acc: 0.9334\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1887 - acc: 0.9278 - val_loss: 0.1905 - val_acc: 0.9334\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1722 - acc: 0.9340 - val_loss: 0.1932 - val_acc: 0.9320\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1797 - acc: 0.9267 - val_loss: 0.1965 - val_acc: 0.9334\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1845 - acc: 0.9240 - val_loss: 0.2004 - val_acc: 0.9237\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1618 - acc: 0.9319 - val_loss: 0.1747 - val_acc: 0.9362\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1501 - acc: 0.9399 - val_loss: 0.2099 - val_acc: 0.9265\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1492 - acc: 0.9410 - val_loss: 0.1576 - val_acc: 0.9334\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1456 - acc: 0.9438 - val_loss: 0.1669 - val_acc: 0.9390\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1395 - acc: 0.9448 - val_loss: 0.1849 - val_acc: 0.9265\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1211 - acc: 0.9514 - val_loss: 0.1542 - val_acc: 0.9431\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1310 - acc: 0.9483 - val_loss: 0.2071 - val_acc: 0.9209\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1268 - acc: 0.9469 - val_loss: 0.1809 - val_acc: 0.9348\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1215 - acc: 0.9552 - val_loss: 0.1548 - val_acc: 0.9376\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1131 - acc: 0.9576 - val_loss: 0.1477 - val_acc: 0.9348\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1071 - acc: 0.9573 - val_loss: 0.1705 - val_acc: 0.9362\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1187 - acc: 0.9566 - val_loss: 0.1826 - val_acc: 0.9320\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1005 - acc: 0.9635 - val_loss: 0.1825 - val_acc: 0.9376\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1083 - acc: 0.9590 - val_loss: 0.1586 - val_acc: 0.9390\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0990 - acc: 0.9653 - val_loss: 0.2214 - val_acc: 0.9154\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1022 - acc: 0.9642 - val_loss: 0.1702 - val_acc: 0.9320\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1088 - acc: 0.9587 - val_loss: 0.1899 - val_acc: 0.9293\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0968 - acc: 0.9628 - val_loss: 0.2123 - val_acc: 0.9279\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0836 - acc: 0.9701 - val_loss: 0.2383 - val_acc: 0.9265\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0869 - acc: 0.9667 - val_loss: 0.1629 - val_acc: 0.9404\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0759 - acc: 0.9719 - val_loss: 0.1830 - val_acc: 0.9404\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0860 - acc: 0.9681 - val_loss: 0.1580 - val_acc: 0.9376\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0647 - acc: 0.9747 - val_loss: 0.1910 - val_acc: 0.9417\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0605 - acc: 0.9781 - val_loss: 0.2533 - val_acc: 0.9307\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0764 - acc: 0.9708 - val_loss: 0.1774 - val_acc: 0.9307\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0577 - acc: 0.9809 - val_loss: 0.1985 - val_acc: 0.9223\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0668 - acc: 0.9750 - val_loss: 0.1950 - val_acc: 0.9265\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0603 - acc: 0.9771 - val_loss: 0.2333 - val_acc: 0.9390\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0600 - acc: 0.9792 - val_loss: 0.2119 - val_acc: 0.9334\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0450 - acc: 0.9837 - val_loss: 0.2303 - val_acc: 0.9376\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0311 - acc: 0.9903 - val_loss: 0.2453 - val_acc: 0.9362\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0633 - acc: 0.9799 - val_loss: 0.2254 - val_acc: 0.9307\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0534 - acc: 0.9792 - val_loss: 0.2118 - val_acc: 0.9293\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0294 - acc: 0.9889 - val_loss: 0.2781 - val_acc: 0.9237\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0352 - acc: 0.9858 - val_loss: 0.2660 - val_acc: 0.9390\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0363 - acc: 0.9861 - val_loss: 0.2507 - val_acc: 0.9404\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0530 - acc: 0.9819 - val_loss: 0.2052 - val_acc: 0.9279\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0549 - acc: 0.9767 - val_loss: 0.2210 - val_acc: 0.9307\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.2950 - val_acc: 0.9320\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.4682 - val_acc: 0.9154\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0269 - acc: 0.9892 - val_loss: 0.3204 - val_acc: 0.9348\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0946 - acc: 0.9649 - val_loss: 0.2422 - val_acc: 0.9085\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0428 - acc: 0.9837 - val_loss: 0.2513 - val_acc: 0.9348\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.2946 - val_acc: 0.9376\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.3807 - val_acc: 0.9334\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.3811 - val_acc: 0.9376\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 0.4088 - val_acc: 0.9293\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.4474 - val_acc: 0.9307\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.4409 - val_acc: 0.9348\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.4830 - val_acc: 0.9376\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.4787 - val_acc: 0.9320\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0032 - acc: 0.9986 - val_loss: 0.5473 - val_acc: 0.9348\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0807 - acc: 0.9750 - val_loss: 0.2172 - val_acc: 0.9209\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0323 - acc: 0.9878 - val_loss: 0.3012 - val_acc: 0.9334\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0295 - acc: 0.9896 - val_loss: 0.3054 - val_acc: 0.9417\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0293 - acc: 0.9906 - val_loss: 0.3468 - val_acc: 0.9251\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0290 - acc: 0.9872 - val_loss: 0.2757 - val_acc: 0.9237\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0179 - acc: 0.9944 - val_loss: 0.3190 - val_acc: 0.9376\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0307 - acc: 0.9889 - val_loss: 0.3110 - val_acc: 0.9293\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0207 - acc: 0.9944 - val_loss: 0.3335 - val_acc: 0.9265\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.4130 - val_acc: 0.9307\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.4493 - val_acc: 0.9334\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.4613 - val_acc: 0.9362\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.4798 - val_acc: 0.9376\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 8.3680e-04 - acc: 0.9997 - val_loss: 0.5109 - val_acc: 0.9376\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.5023 - val_acc: 0.9307\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.5002 - val_acc: 0.9376\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.2879e-04 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.9348\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.9366e-04 - acc: 0.9997 - val_loss: 0.5490 - val_acc: 0.9348\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.3645e-04 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.9362\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.2168e-04 - acc: 1.0000 - val_loss: 0.5816 - val_acc: 0.9362\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3892e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.9362\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2596e-04 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.9348\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.6379e-05 - acc: 1.0000 - val_loss: 0.6258 - val_acc: 0.9348\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.7705e-05 - acc: 1.0000 - val_loss: 0.6379 - val_acc: 0.9348\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.5365e-05 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.9334\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.7222e-05 - acc: 1.0000 - val_loss: 0.6600 - val_acc: 0.9334\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.6181e-05 - acc: 1.0000 - val_loss: 0.6677 - val_acc: 0.9334\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.4742e-05 - acc: 1.0000 - val_loss: 0.6774 - val_acc: 0.9348\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9464e-05 - acc: 1.0000 - val_loss: 0.6854 - val_acc: 0.9334\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.8739e-05 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.9334\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.4062e-05 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.9334\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.0633e-05 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.9334\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8833e-05 - acc: 1.0000 - val_loss: 0.7180 - val_acc: 0.9348\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5897e-05 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.9362\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5824e-05 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.9376\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8002e-05 - acc: 1.0000 - val_loss: 0.7376 - val_acc: 0.9334\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2564e-05 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.9334\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 0.7582 - val_acc: 0.9334\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.9315e-06 - acc: 1.0000 - val_loss: 0.7664 - val_acc: 0.9334\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.0229e-06 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.9334\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.0516e-06 - acc: 1.0000 - val_loss: 0.7821 - val_acc: 0.9362\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.4543e-06 - acc: 1.0000 - val_loss: 0.7826 - val_acc: 0.9334\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.6538e-06 - acc: 1.0000 - val_loss: 0.7925 - val_acc: 0.9334\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.5319e-06 - acc: 1.0000 - val_loss: 0.8038 - val_acc: 0.9348\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.2215e-06 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.9334\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.1007e-06 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.9334\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3242e-06 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 0.9334\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.1611e-06 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.9334\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.6412e-06 - acc: 1.0000 - val_loss: 0.8325 - val_acc: 0.9334\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.2485e-06 - acc: 1.0000 - val_loss: 0.8367 - val_acc: 0.9348\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.0513e-06 - acc: 1.0000 - val_loss: 0.8472 - val_acc: 0.9334\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.8579e-06 - acc: 1.0000 - val_loss: 0.8530 - val_acc: 0.9334\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.5125e-06 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.9334\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.3124e-06 - acc: 1.0000 - val_loss: 0.8668 - val_acc: 0.9348\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1098e-06 - acc: 1.0000 - val_loss: 0.8817 - val_acc: 0.9334\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9093e-06 - acc: 1.0000 - val_loss: 0.8810 - val_acc: 0.9348\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9779e-06 - acc: 1.0000 - val_loss: 0.8908 - val_acc: 0.9334\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8795e-06 - acc: 1.0000 - val_loss: 0.8898 - val_acc: 0.9348\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5428e-06 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.9334\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5072e-06 - acc: 1.0000 - val_loss: 0.9192 - val_acc: 0.9334\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.4023e-06 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.9348\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3007e-06 - acc: 1.0000 - val_loss: 0.9222 - val_acc: 0.9334\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1370e-06 - acc: 1.0000 - val_loss: 0.9241 - val_acc: 0.9348\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1856e-06 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.9348\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.4916e-07 - acc: 1.0000 - val_loss: 0.9356 - val_acc: 0.9348\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.8105e-07 - acc: 1.0000 - val_loss: 0.9414 - val_acc: 0.9348\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.4996e-07 - acc: 1.0000 - val_loss: 0.9479 - val_acc: 0.9348\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.9159e-07 - acc: 1.0000 - val_loss: 0.9398 - val_acc: 0.9334\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 8.7791e-07 - acc: 1.0000 - val_loss: 0.9571 - val_acc: 0.9362\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.3963e-07 - acc: 1.0000 - val_loss: 0.9685 - val_acc: 0.9348\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.0583e-07 - acc: 1.0000 - val_loss: 0.9660 - val_acc: 0.9348\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.5351e-07 - acc: 1.0000 - val_loss: 0.9717 - val_acc: 0.9348\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.2698e-07 - acc: 1.0000 - val_loss: 0.9799 - val_acc: 0.9362\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.9052e-07 - acc: 1.0000 - val_loss: 0.9873 - val_acc: 0.9362\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.7343e-07 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.9348\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.2037e-07 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.9348\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.9772e-07 - acc: 1.0000 - val_loss: 0.9968 - val_acc: 0.9348\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.5915e-07 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.9348\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.5513e-07 - acc: 1.0000 - val_loss: 1.0028 - val_acc: 0.9348\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3539e-07 - acc: 1.0000 - val_loss: 1.0037 - val_acc: 0.9320\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.0377e-07 - acc: 1.0000 - val_loss: 1.0078 - val_acc: 0.9320\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8837e-07 - acc: 1.0000 - val_loss: 1.0188 - val_acc: 0.9348\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.5837e-07 - acc: 1.0000 - val_loss: 1.0233 - val_acc: 0.9348\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4239e-07 - acc: 1.0000 - val_loss: 1.0280 - val_acc: 0.9348\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.2145e-07 - acc: 1.0000 - val_loss: 1.0331 - val_acc: 0.9348\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.2207e-07 - acc: 1.0000 - val_loss: 1.0344 - val_acc: 0.9334\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.8535e-07 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.9334\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.8775e-07 - acc: 1.0000 - val_loss: 1.0463 - val_acc: 0.9348\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.5700e-07 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.9348\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.5199e-07 - acc: 1.0000 - val_loss: 1.0530 - val_acc: 0.9334\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.3999e-07 - acc: 1.0000 - val_loss: 1.0569 - val_acc: 0.9334\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.2339e-07 - acc: 1.0000 - val_loss: 1.0624 - val_acc: 0.9348\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.1151e-07 - acc: 1.0000 - val_loss: 1.0683 - val_acc: 0.9348\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9773e-07 - acc: 1.0000 - val_loss: 1.0753 - val_acc: 0.9348\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8862e-07 - acc: 1.0000 - val_loss: 1.0738 - val_acc: 0.9334\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8163e-07 - acc: 1.0000 - val_loss: 1.0806 - val_acc: 0.9334\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6424e-07 - acc: 1.0000 - val_loss: 1.0813 - val_acc: 0.9334\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.6540e-07 - acc: 1.0000 - val_loss: 1.0856 - val_acc: 0.9348\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.6308e-07 - acc: 1.0000 - val_loss: 1.0913 - val_acc: 0.9334\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.4665e-07 - acc: 1.0000 - val_loss: 1.1034 - val_acc: 0.9348\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3812e-07 - acc: 1.0000 - val_loss: 1.1019 - val_acc: 0.9334\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3014e-07 - acc: 1.0000 - val_loss: 1.1132 - val_acc: 0.9348\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2546e-07 - acc: 1.0000 - val_loss: 1.1095 - val_acc: 0.9334\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1557e-07 - acc: 1.0000 - val_loss: 1.1183 - val_acc: 0.9334\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0663e-07 - acc: 1.0000 - val_loss: 1.1173 - val_acc: 0.9334\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0948e-07 - acc: 1.0000 - val_loss: 1.1215 - val_acc: 0.9348\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0385e-07 - acc: 1.0000 - val_loss: 1.1254 - val_acc: 0.9348\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.7768e-08 - acc: 1.0000 - val_loss: 1.1301 - val_acc: 0.9348\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.4001e-08 - acc: 1.0000 - val_loss: 1.1344 - val_acc: 0.9334\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.4108e-08 - acc: 1.0000 - val_loss: 1.1435 - val_acc: 0.9334\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.8479e-08 - acc: 1.0000 - val_loss: 1.1448 - val_acc: 0.9334\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.5664e-08 - acc: 1.0000 - val_loss: 1.1505 - val_acc: 0.9334\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.2146e-08 - acc: 1.0000 - val_loss: 1.1565 - val_acc: 0.9334\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.9000e-08 - acc: 1.0000 - val_loss: 1.1645 - val_acc: 0.9334\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.0408e-08 - acc: 1.0000 - val_loss: 1.1631 - val_acc: 0.9334\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.1591e-08 - acc: 1.0000 - val_loss: 1.1616 - val_acc: 0.9348\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.0888e-08 - acc: 1.0000 - val_loss: 1.1748 - val_acc: 0.9334\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.0556e-08 - acc: 1.0000 - val_loss: 1.1740 - val_acc: 0.9334\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.3230e-08 - acc: 1.0000 - val_loss: 1.1831 - val_acc: 0.9334\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.0788e-08 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.9334\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.9132e-08 - acc: 1.0000 - val_loss: 1.1885 - val_acc: 0.9334\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.5614e-08 - acc: 1.0000 - val_loss: 1.1969 - val_acc: 0.9334\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3544e-08 - acc: 1.0000 - val_loss: 1.1987 - val_acc: 0.9334\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.1226e-08 - acc: 1.0000 - val_loss: 1.1991 - val_acc: 0.9348\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.1599e-08 - acc: 1.0000 - val_loss: 1.2056 - val_acc: 0.9334\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8867e-08 - acc: 1.0000 - val_loss: 1.2113 - val_acc: 0.9334\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.3445e-08 - acc: 1.0000 - val_loss: 1.2095 - val_acc: 0.9348\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4480e-08 - acc: 1.0000 - val_loss: 1.2177 - val_acc: 0.9334\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.2410e-08 - acc: 1.0000 - val_loss: 1.2240 - val_acc: 0.9334\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.9926e-08 - acc: 1.0000 - val_loss: 1.2222 - val_acc: 0.9348\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.9513e-08 - acc: 1.0000 - val_loss: 1.2333 - val_acc: 0.9334\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7691e-08 - acc: 1.0000 - val_loss: 1.2362 - val_acc: 0.9334\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.5580e-08 - acc: 1.0000 - val_loss: 1.2382 - val_acc: 0.9348\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.5787e-08 - acc: 1.0000 - val_loss: 1.2408 - val_acc: 0.9348\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.5746e-08 - acc: 1.0000 - val_loss: 1.2478 - val_acc: 0.9348\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.2807e-08 - acc: 1.0000 - val_loss: 1.2544 - val_acc: 0.9334\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1896e-08 - acc: 1.0000 - val_loss: 1.2601 - val_acc: 0.9334\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1027e-08 - acc: 1.0000 - val_loss: 1.2569 - val_acc: 0.9348\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9744e-08 - acc: 1.0000 - val_loss: 1.2631 - val_acc: 0.9348\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9040e-08 - acc: 1.0000 - val_loss: 1.2693 - val_acc: 0.9348\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.7550e-08 - acc: 1.0000 - val_loss: 1.2742 - val_acc: 0.9348\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6640e-08 - acc: 1.0000 - val_loss: 1.2737 - val_acc: 0.9348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqVnPrisaY9B",
        "outputId": "b7bfbe6c-6996-46c2-81fb-fbc40c7a6410"
      },
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model_3.h5', save_best_only=True, monitor='val_loss'\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=50, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "history_3 = model_3.fit(\n",
        "    x_train, y_train, batch_size, epochs, validation_split=0.2, verbose=1\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 3s 20ms/step - loss: 0.4790 - acc: 0.7372 - val_loss: 0.3111 - val_acc: 0.8558\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2095 - acc: 0.9153 - val_loss: 0.2492 - val_acc: 0.9140\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2114 - acc: 0.9139 - val_loss: 0.2201 - val_acc: 0.9182\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1976 - acc: 0.9167 - val_loss: 0.2535 - val_acc: 0.9043\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1749 - acc: 0.9351 - val_loss: 0.2307 - val_acc: 0.9182\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1584 - acc: 0.9392 - val_loss: 0.1743 - val_acc: 0.9320\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1473 - acc: 0.9455 - val_loss: 0.1814 - val_acc: 0.9307\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1536 - acc: 0.9392 - val_loss: 0.1671 - val_acc: 0.9320\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1424 - acc: 0.9465 - val_loss: 0.2410 - val_acc: 0.9154\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1414 - acc: 0.9444 - val_loss: 0.1718 - val_acc: 0.9362\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1315 - acc: 0.9469 - val_loss: 0.1551 - val_acc: 0.9404\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1308 - acc: 0.9493 - val_loss: 0.3534 - val_acc: 0.8793\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1358 - acc: 0.9434 - val_loss: 0.1566 - val_acc: 0.9334\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1199 - acc: 0.9524 - val_loss: 0.1520 - val_acc: 0.9376\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1164 - acc: 0.9559 - val_loss: 0.1541 - val_acc: 0.9362\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1164 - acc: 0.9563 - val_loss: 0.1665 - val_acc: 0.9445\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1227 - acc: 0.9528 - val_loss: 0.1645 - val_acc: 0.9404\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1205 - acc: 0.9552 - val_loss: 0.2166 - val_acc: 0.9223\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1046 - acc: 0.9594 - val_loss: 0.1705 - val_acc: 0.9348\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0972 - acc: 0.9604 - val_loss: 0.1447 - val_acc: 0.9417\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1096 - acc: 0.9583 - val_loss: 0.1486 - val_acc: 0.9431\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0910 - acc: 0.9639 - val_loss: 0.1492 - val_acc: 0.9487\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0878 - acc: 0.9674 - val_loss: 0.1579 - val_acc: 0.9390\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0847 - acc: 0.9694 - val_loss: 0.2608 - val_acc: 0.9098\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0876 - acc: 0.9663 - val_loss: 0.1630 - val_acc: 0.9473\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0823 - acc: 0.9670 - val_loss: 0.2077 - val_acc: 0.9445\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0841 - acc: 0.9649 - val_loss: 0.1697 - val_acc: 0.9417\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0824 - acc: 0.9715 - val_loss: 0.1498 - val_acc: 0.9417\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0843 - acc: 0.9694 - val_loss: 0.1696 - val_acc: 0.9487\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0725 - acc: 0.9740 - val_loss: 0.1907 - val_acc: 0.9473\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0616 - acc: 0.9764 - val_loss: 0.2517 - val_acc: 0.9320\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0561 - acc: 0.9795 - val_loss: 0.1849 - val_acc: 0.9390\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0510 - acc: 0.9799 - val_loss: 0.1831 - val_acc: 0.9417\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0471 - acc: 0.9851 - val_loss: 0.2093 - val_acc: 0.9417\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0479 - acc: 0.9819 - val_loss: 0.2181 - val_acc: 0.9376\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0630 - acc: 0.9736 - val_loss: 0.2104 - val_acc: 0.9431\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0671 - acc: 0.9733 - val_loss: 0.1881 - val_acc: 0.9362\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0468 - acc: 0.9833 - val_loss: 0.2022 - val_acc: 0.9376\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0230 - acc: 0.9920 - val_loss: 0.2718 - val_acc: 0.9390\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0401 - acc: 0.9844 - val_loss: 0.2965 - val_acc: 0.9293\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0560 - acc: 0.9771 - val_loss: 0.1980 - val_acc: 0.9265\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0548 - acc: 0.9757 - val_loss: 0.2543 - val_acc: 0.9404\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0311 - acc: 0.9878 - val_loss: 0.4770 - val_acc: 0.9057\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0443 - acc: 0.9830 - val_loss: 0.2342 - val_acc: 0.9459\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0280 - acc: 0.9906 - val_loss: 0.2741 - val_acc: 0.9334\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0355 - acc: 0.9847 - val_loss: 0.2819 - val_acc: 0.9376\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.2947 - val_acc: 0.9417\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0256 - acc: 0.9910 - val_loss: 0.2886 - val_acc: 0.9362\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0208 - acc: 0.9920 - val_loss: 0.2861 - val_acc: 0.9376\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.4194 - val_acc: 0.9237\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0598 - acc: 0.9792 - val_loss: 0.2357 - val_acc: 0.9390\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.3269 - val_acc: 0.9417\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.3068 - val_acc: 0.9404\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.3301 - val_acc: 0.9390\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.3398 - val_acc: 0.9431\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.3801 - val_acc: 0.9362\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0209 - acc: 0.9917 - val_loss: 0.4191 - val_acc: 0.9404\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0604 - acc: 0.9778 - val_loss: 0.2379 - val_acc: 0.9307\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0259 - acc: 0.9903 - val_loss: 0.3119 - val_acc: 0.9390\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0201 - acc: 0.9913 - val_loss: 0.3137 - val_acc: 0.9307\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0162 - acc: 0.9937 - val_loss: 0.3779 - val_acc: 0.9417\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0246 - acc: 0.9906 - val_loss: 0.3946 - val_acc: 0.9390\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0931 - acc: 0.9681 - val_loss: 0.2159 - val_acc: 0.9445\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.2941 - val_acc: 0.9376\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0053 - acc: 0.9990 - val_loss: 0.3444 - val_acc: 0.9404\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.3580 - val_acc: 0.9417\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.3746 - val_acc: 0.9376\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.3908 - val_acc: 0.9390\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.4207 - val_acc: 0.9376\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.4575 - val_acc: 0.9307\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.4907 - val_acc: 0.9348\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.4851 - val_acc: 0.9362\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.1979e-04 - acc: 0.9997 - val_loss: 0.5580 - val_acc: 0.9362\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.0858e-04 - acc: 0.9997 - val_loss: 0.5771 - val_acc: 0.9320\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0743 - acc: 0.9753 - val_loss: 0.2071 - val_acc: 0.9237\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0607 - acc: 0.9726 - val_loss: 0.2492 - val_acc: 0.9279\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0142 - acc: 0.9965 - val_loss: 0.4301 - val_acc: 0.9334\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.4176 - val_acc: 0.9348\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.3916 - val_acc: 0.9348\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.5499 - val_acc: 0.9209\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.4434 - val_acc: 0.9362\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0332 - acc: 0.9872 - val_loss: 0.3518 - val_acc: 0.9376\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0050 - acc: 0.9990 - val_loss: 0.4451 - val_acc: 0.9334\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.4411 - val_acc: 0.9404\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.4735 - val_acc: 0.9334\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.4934 - val_acc: 0.9376\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.2451e-04 - acc: 0.9997 - val_loss: 0.5349 - val_acc: 0.9348\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.5823e-04 - acc: 1.0000 - val_loss: 0.5589 - val_acc: 0.9390\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.3044e-04 - acc: 1.0000 - val_loss: 0.5798 - val_acc: 0.9376\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8005e-04 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.9362\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3109e-04 - acc: 1.0000 - val_loss: 0.6146 - val_acc: 0.9362\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1507e-04 - acc: 1.0000 - val_loss: 0.6234 - val_acc: 0.9362\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.2846e-05 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.9376\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.9397e-05 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.9376\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.7922e-05 - acc: 1.0000 - val_loss: 0.6666 - val_acc: 0.9376\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.5236e-05 - acc: 1.0000 - val_loss: 0.6702 - val_acc: 0.9376\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.1369e-05 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.9362\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.9859e-05 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.9362\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.3505e-05 - acc: 1.0000 - val_loss: 0.7002 - val_acc: 0.9362\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.9877e-05 - acc: 1.0000 - val_loss: 0.7053 - val_acc: 0.9362\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.5651e-05 - acc: 1.0000 - val_loss: 0.7138 - val_acc: 0.9362\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.4112e-05 - acc: 1.0000 - val_loss: 0.7196 - val_acc: 0.9362\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9726e-05 - acc: 1.0000 - val_loss: 0.7279 - val_acc: 0.9362\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8226e-05 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 0.9362\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6161e-05 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.9376\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4327e-05 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.9376\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2906e-05 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.9376\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2163e-05 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.9362\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1538e-05 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9376\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0606e-05 - acc: 1.0000 - val_loss: 0.7741 - val_acc: 0.9348\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.7137e-06 - acc: 1.0000 - val_loss: 0.7815 - val_acc: 0.9348\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.1874e-06 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.9376\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.3701e-06 - acc: 1.0000 - val_loss: 0.7932 - val_acc: 0.9362\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.6180e-06 - acc: 1.0000 - val_loss: 0.7993 - val_acc: 0.9362\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.0752e-06 - acc: 1.0000 - val_loss: 0.8010 - val_acc: 0.9376\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.7945e-06 - acc: 1.0000 - val_loss: 0.8088 - val_acc: 0.9362\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.9530e-06 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.9362\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.2274e-06 - acc: 1.0000 - val_loss: 0.8167 - val_acc: 0.9362\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.4257e-06 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.9362\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.9675e-06 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.9362\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.6025e-06 - acc: 1.0000 - val_loss: 0.8361 - val_acc: 0.9376\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.7332e-06 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.9390\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4868e-06 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.9390\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.9089e-06 - acc: 1.0000 - val_loss: 0.8506 - val_acc: 0.9390\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6914e-06 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.9390\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7605e-06 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.9376\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.3127e-06 - acc: 1.0000 - val_loss: 0.8639 - val_acc: 0.9376\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1711e-06 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.9362\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.0070e-06 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.9362\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8795e-06 - acc: 1.0000 - val_loss: 0.8784 - val_acc: 0.9376\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8035e-06 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.9362\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6400e-06 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.9376\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4718e-06 - acc: 1.0000 - val_loss: 0.8906 - val_acc: 0.9376\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4441e-06 - acc: 1.0000 - val_loss: 0.8922 - val_acc: 0.9348\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3597e-06 - acc: 1.0000 - val_loss: 0.8983 - val_acc: 0.9376\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2113e-06 - acc: 1.0000 - val_loss: 0.9026 - val_acc: 0.9376\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2258e-06 - acc: 1.0000 - val_loss: 0.9037 - val_acc: 0.9348\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0907e-06 - acc: 1.0000 - val_loss: 0.9085 - val_acc: 0.9348\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0105e-06 - acc: 1.0000 - val_loss: 0.9129 - val_acc: 0.9376\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.5578e-07 - acc: 1.0000 - val_loss: 0.9170 - val_acc: 0.9348\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.5228e-07 - acc: 1.0000 - val_loss: 0.9217 - val_acc: 0.9376\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.9885e-07 - acc: 1.0000 - val_loss: 0.9263 - val_acc: 0.9376\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.5956e-07 - acc: 1.0000 - val_loss: 0.9283 - val_acc: 0.9362\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.5065e-07 - acc: 1.0000 - val_loss: 0.9315 - val_acc: 0.9362\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.0863e-07 - acc: 1.0000 - val_loss: 0.9365 - val_acc: 0.9376\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.2056e-07 - acc: 1.0000 - val_loss: 0.9411 - val_acc: 0.9376\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.1066e-07 - acc: 1.0000 - val_loss: 0.9435 - val_acc: 0.9362\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.6783e-07 - acc: 1.0000 - val_loss: 0.9460 - val_acc: 0.9362\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.4432e-07 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.9362\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.3302e-07 - acc: 1.0000 - val_loss: 0.9542 - val_acc: 0.9376\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.6386e-07 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 0.9376\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.3224e-07 - acc: 1.0000 - val_loss: 0.9629 - val_acc: 0.9390\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3571e-07 - acc: 1.0000 - val_loss: 0.9650 - val_acc: 0.9362\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.1428e-07 - acc: 1.0000 - val_loss: 0.9670 - val_acc: 0.9362\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8245e-07 - acc: 1.0000 - val_loss: 0.9724 - val_acc: 0.9362\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.6399e-07 - acc: 1.0000 - val_loss: 0.9757 - val_acc: 0.9362\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4495e-07 - acc: 1.0000 - val_loss: 0.9791 - val_acc: 0.9362\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.3436e-07 - acc: 1.0000 - val_loss: 0.9831 - val_acc: 0.9348\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.0046e-07 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.9362\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.8866e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9348\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.7662e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9348\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6606e-07 - acc: 1.0000 - val_loss: 0.9971 - val_acc: 0.9362\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.4504e-07 - acc: 1.0000 - val_loss: 1.0012 - val_acc: 0.9362\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.4164e-07 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.9362\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1900e-07 - acc: 1.0000 - val_loss: 1.0077 - val_acc: 0.9362\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.1586e-07 - acc: 1.0000 - val_loss: 1.0110 - val_acc: 0.9362\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9860e-07 - acc: 1.0000 - val_loss: 1.0134 - val_acc: 0.9362\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9115e-07 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.9362\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.7430e-07 - acc: 1.0000 - val_loss: 1.0221 - val_acc: 0.9362\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6995e-07 - acc: 1.0000 - val_loss: 1.0255 - val_acc: 0.9362\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6271e-07 - acc: 1.0000 - val_loss: 1.0269 - val_acc: 0.9362\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5389e-07 - acc: 1.0000 - val_loss: 1.0307 - val_acc: 0.9362\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4752e-07 - acc: 1.0000 - val_loss: 1.0346 - val_acc: 0.9362\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3485e-07 - acc: 1.0000 - val_loss: 1.0389 - val_acc: 0.9362\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3448e-07 - acc: 1.0000 - val_loss: 1.0408 - val_acc: 0.9362\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2492e-07 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.9362\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2049e-07 - acc: 1.0000 - val_loss: 1.0483 - val_acc: 0.9362\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0903e-07 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.9362\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0501e-07 - acc: 1.0000 - val_loss: 1.0557 - val_acc: 0.9362\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0894e-07 - acc: 1.0000 - val_loss: 1.0575 - val_acc: 0.9362\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.0814e-08 - acc: 1.0000 - val_loss: 1.0619 - val_acc: 0.9362\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.1062e-08 - acc: 1.0000 - val_loss: 1.0653 - val_acc: 0.9362\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.6716e-08 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.9362\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.9390e-08 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.9362\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.5747e-08 - acc: 1.0000 - val_loss: 1.0734 - val_acc: 0.9362\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.3388e-08 - acc: 1.0000 - val_loss: 1.0762 - val_acc: 0.9362\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.9207e-08 - acc: 1.0000 - val_loss: 1.0798 - val_acc: 0.9362\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.4530e-08 - acc: 1.0000 - val_loss: 1.0827 - val_acc: 0.9362\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.2999e-08 - acc: 1.0000 - val_loss: 1.0865 - val_acc: 0.9362\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.9853e-08 - acc: 1.0000 - val_loss: 1.0881 - val_acc: 0.9348\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.8280e-08 - acc: 1.0000 - val_loss: 1.0917 - val_acc: 0.9362\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.5838e-08 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.9362\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.1409e-08 - acc: 1.0000 - val_loss: 1.0981 - val_acc: 0.9362\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.8636e-08 - acc: 1.0000 - val_loss: 1.1011 - val_acc: 0.9362\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.7145e-08 - acc: 1.0000 - val_loss: 1.1034 - val_acc: 0.9362\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.5448e-08 - acc: 1.0000 - val_loss: 1.1069 - val_acc: 0.9362\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.1765e-08 - acc: 1.0000 - val_loss: 1.1101 - val_acc: 0.9362\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9281e-08 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.9362\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.9033e-08 - acc: 1.0000 - val_loss: 1.1147 - val_acc: 0.9348\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.8619e-08 - acc: 1.0000 - val_loss: 1.1185 - val_acc: 0.9362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJZ0nSX5ab3B",
        "outputId": "ea63fbde-794f-4e78-f4b8-5cb293760569"
      },
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model_4.h5', save_best_only=True, monitor='val_loss'\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=50, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "history_4 = model_4.fit(\n",
        "    x_train, y_train, batch_size, epochs, validation_split=0.2, verbose=1\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 4s 23ms/step - loss: 0.5960 - acc: 0.6410 - val_loss: 0.3052 - val_acc: 0.8696\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.2497 - acc: 0.8993 - val_loss: 0.2162 - val_acc: 0.9154\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1966 - acc: 0.9229 - val_loss: 0.2001 - val_acc: 0.9265\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1977 - acc: 0.9222 - val_loss: 0.1873 - val_acc: 0.9293\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2010 - acc: 0.9167 - val_loss: 0.1965 - val_acc: 0.9307\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1761 - acc: 0.9302 - val_loss: 0.1927 - val_acc: 0.9279\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1612 - acc: 0.9375 - val_loss: 0.1945 - val_acc: 0.9279\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1579 - acc: 0.9365 - val_loss: 0.2255 - val_acc: 0.9112\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1468 - acc: 0.9413 - val_loss: 0.1632 - val_acc: 0.9334\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1443 - acc: 0.9462 - val_loss: 0.1744 - val_acc: 0.9376\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1543 - acc: 0.9378 - val_loss: 0.1679 - val_acc: 0.9320\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1446 - acc: 0.9424 - val_loss: 0.1692 - val_acc: 0.9307\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1404 - acc: 0.9476 - val_loss: 0.1769 - val_acc: 0.9307\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1417 - acc: 0.9490 - val_loss: 0.1611 - val_acc: 0.9334\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1219 - acc: 0.9517 - val_loss: 0.1700 - val_acc: 0.9320\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1263 - acc: 0.9514 - val_loss: 0.1511 - val_acc: 0.9431\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1223 - acc: 0.9507 - val_loss: 0.2279 - val_acc: 0.9112\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1303 - acc: 0.9476 - val_loss: 0.1598 - val_acc: 0.9362\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1221 - acc: 0.9538 - val_loss: 0.1590 - val_acc: 0.9362\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1264 - acc: 0.9490 - val_loss: 0.1664 - val_acc: 0.9320\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.1082 - acc: 0.9583 - val_loss: 0.1671 - val_acc: 0.9265\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1055 - acc: 0.9583 - val_loss: 0.1822 - val_acc: 0.9320\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.1075 - acc: 0.9587 - val_loss: 0.1658 - val_acc: 0.9404\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0981 - acc: 0.9625 - val_loss: 0.1884 - val_acc: 0.9307\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0957 - acc: 0.9639 - val_loss: 0.1631 - val_acc: 0.9348\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0887 - acc: 0.9694 - val_loss: 0.1820 - val_acc: 0.9431\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0923 - acc: 0.9681 - val_loss: 0.1749 - val_acc: 0.9362\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0920 - acc: 0.9618 - val_loss: 0.1824 - val_acc: 0.9334\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0818 - acc: 0.9674 - val_loss: 0.1881 - val_acc: 0.9362\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0675 - acc: 0.9767 - val_loss: 0.2062 - val_acc: 0.9348\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0797 - acc: 0.9722 - val_loss: 0.2311 - val_acc: 0.9168\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0560 - acc: 0.9823 - val_loss: 0.2088 - val_acc: 0.9265\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0650 - acc: 0.9736 - val_loss: 0.2366 - val_acc: 0.9265\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0636 - acc: 0.9760 - val_loss: 0.2173 - val_acc: 0.9390\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0625 - acc: 0.9774 - val_loss: 0.1912 - val_acc: 0.9390\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0560 - acc: 0.9785 - val_loss: 0.2557 - val_acc: 0.9334\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.2214 - val_acc: 0.9362\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0454 - acc: 0.9854 - val_loss: 0.2459 - val_acc: 0.9320\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0409 - acc: 0.9840 - val_loss: 0.3116 - val_acc: 0.9182\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0426 - acc: 0.9858 - val_loss: 0.2840 - val_acc: 0.9334\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0550 - acc: 0.9802 - val_loss: 0.2407 - val_acc: 0.9390\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0350 - acc: 0.9885 - val_loss: 0.2791 - val_acc: 0.9320\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0258 - acc: 0.9931 - val_loss: 0.3351 - val_acc: 0.9279\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0438 - acc: 0.9830 - val_loss: 0.2971 - val_acc: 0.9376\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0276 - acc: 0.9899 - val_loss: 0.3240 - val_acc: 0.9320\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.4637 - val_acc: 0.9237\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0264 - acc: 0.9913 - val_loss: 0.3583 - val_acc: 0.9182\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0660 - acc: 0.9764 - val_loss: 0.2750 - val_acc: 0.9237\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0247 - acc: 0.9920 - val_loss: 0.3289 - val_acc: 0.9320\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0382 - acc: 0.9868 - val_loss: 0.3100 - val_acc: 0.9237\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.3796 - val_acc: 0.9196\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0235 - acc: 0.9917 - val_loss: 0.3564 - val_acc: 0.9348\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.4063 - val_acc: 0.9237\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0542 - acc: 0.9823 - val_loss: 0.2903 - val_acc: 0.9348\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0214 - acc: 0.9931 - val_loss: 0.3750 - val_acc: 0.9154\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0177 - acc: 0.9924 - val_loss: 0.4032 - val_acc: 0.9334\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.4880 - val_acc: 0.9154\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0560 - acc: 0.9830 - val_loss: 0.3286 - val_acc: 0.9279\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0177 - acc: 0.9951 - val_loss: 0.3866 - val_acc: 0.9223\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.3912 - val_acc: 0.9320\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.4087 - val_acc: 0.9320\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.4185 - val_acc: 0.9320\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.4389 - val_acc: 0.9348\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 0.5028 - val_acc: 0.9307\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0038 - acc: 0.9993 - val_loss: 0.5224 - val_acc: 0.9307\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.5157 - val_acc: 0.9307\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.5570 - val_acc: 0.9279\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.5361 - val_acc: 0.9307\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.5516 - val_acc: 0.9334\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.6204 - val_acc: 0.9126\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0572 - acc: 0.9809 - val_loss: 0.3238 - val_acc: 0.9168\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0433 - acc: 0.9872 - val_loss: 0.3166 - val_acc: 0.9334\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0234 - acc: 0.9931 - val_loss: 0.4411 - val_acc: 0.9237\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0386 - acc: 0.9847 - val_loss: 0.5351 - val_acc: 0.8766\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0288 - acc: 0.9892 - val_loss: 0.3911 - val_acc: 0.9334\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.4609 - val_acc: 0.9320\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.4968 - val_acc: 0.9307\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.5223 - val_acc: 0.9320\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.5216 - val_acc: 0.9293\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.5682 - val_acc: 0.9265\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.5897 - val_acc: 0.9279\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.5693 - val_acc: 0.9279\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.6271 - val_acc: 0.9279\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 0.6426 - val_acc: 0.9251\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.6794 - val_acc: 0.9237\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.6794 - val_acc: 0.9307\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 0.6967 - val_acc: 0.9265\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0246 - acc: 0.9948 - val_loss: 0.4406 - val_acc: 0.9237\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0856 - acc: 0.9660 - val_loss: 0.2628 - val_acc: 0.9307\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0252 - acc: 0.9924 - val_loss: 0.3311 - val_acc: 0.9293\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0240 - acc: 0.9906 - val_loss: 0.3578 - val_acc: 0.9320\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0176 - acc: 0.9931 - val_loss: 0.3968 - val_acc: 0.9265\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0133 - acc: 0.9955 - val_loss: 0.4023 - val_acc: 0.9223\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0627 - acc: 0.9760 - val_loss: 0.3448 - val_acc: 0.9334\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0200 - acc: 0.9931 - val_loss: 0.3259 - val_acc: 0.9265\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.4192 - val_acc: 0.9293\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.5042 - val_acc: 0.9293\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.5748 - val_acc: 0.9251\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.5594 - val_acc: 0.9320\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.5726 - val_acc: 0.9348\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.6373 - val_acc: 0.9279\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.9840e-04 - acc: 0.9997 - val_loss: 0.6419 - val_acc: 0.9279\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.4143e-04 - acc: 0.9997 - val_loss: 0.6930 - val_acc: 0.9279\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.4717e-04 - acc: 0.9997 - val_loss: 0.6754 - val_acc: 0.9265\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.6492e-04 - acc: 0.9997 - val_loss: 0.6680 - val_acc: 0.9279\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.2621e-04 - acc: 1.0000 - val_loss: 0.7236 - val_acc: 0.9265\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.1891e-04 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 0.9279\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6175e-04 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.9279\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6670e-04 - acc: 1.0000 - val_loss: 0.7881 - val_acc: 0.9293\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.7057e-04 - acc: 1.0000 - val_loss: 0.7799 - val_acc: 0.9307\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0457e-04 - acc: 1.0000 - val_loss: 0.8124 - val_acc: 0.9293\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.2922e-05 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.9279\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.4814e-05 - acc: 1.0000 - val_loss: 0.8180 - val_acc: 0.9265\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.9421e-05 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.9293\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.1896e-05 - acc: 1.0000 - val_loss: 0.8469 - val_acc: 0.9293\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.0373e-05 - acc: 1.0000 - val_loss: 0.8643 - val_acc: 0.9293\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.6388e-05 - acc: 1.0000 - val_loss: 0.8720 - val_acc: 0.9293\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.9766e-05 - acc: 1.0000 - val_loss: 0.8798 - val_acc: 0.9293\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.3907e-05 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.9279\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.9988e-05 - acc: 1.0000 - val_loss: 0.8965 - val_acc: 0.9293\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.4921e-05 - acc: 1.0000 - val_loss: 0.9031 - val_acc: 0.9279\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1115e-05 - acc: 1.0000 - val_loss: 0.9139 - val_acc: 0.9265\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.2104e-05 - acc: 1.0000 - val_loss: 0.9067 - val_acc: 0.9279\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.8353e-05 - acc: 1.0000 - val_loss: 0.9329 - val_acc: 0.9265\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8329e-05 - acc: 1.0000 - val_loss: 0.9331 - val_acc: 0.9265\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5441e-05 - acc: 1.0000 - val_loss: 0.9447 - val_acc: 0.9265\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3498e-05 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.9265\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1852e-05 - acc: 1.0000 - val_loss: 0.9561 - val_acc: 0.9279\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0999e-05 - acc: 1.0000 - val_loss: 0.9685 - val_acc: 0.9265\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0315e-05 - acc: 1.0000 - val_loss: 0.9664 - val_acc: 0.9279\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.6925e-06 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9265\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.3581e-06 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9293\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.0649e-06 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9293\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 7.2657e-06 - acc: 1.0000 - val_loss: 1.0014 - val_acc: 0.9293\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.5470e-06 - acc: 1.0000 - val_loss: 1.0130 - val_acc: 0.9293\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.0325e-06 - acc: 1.0000 - val_loss: 1.0132 - val_acc: 0.9293\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.7487e-06 - acc: 1.0000 - val_loss: 1.0357 - val_acc: 0.9265\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 5.7059e-06 - acc: 1.0000 - val_loss: 1.0351 - val_acc: 0.9293\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.6733e-06 - acc: 1.0000 - val_loss: 1.0352 - val_acc: 0.9293\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.2637e-06 - acc: 1.0000 - val_loss: 1.0508 - val_acc: 0.9293\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 4.3013e-06 - acc: 1.0000 - val_loss: 1.0541 - val_acc: 0.9293\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.5516e-06 - acc: 1.0000 - val_loss: 1.0629 - val_acc: 0.9293\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.4630e-06 - acc: 1.0000 - val_loss: 1.0696 - val_acc: 0.9293\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8296e-06 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.9293\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.0967e-06 - acc: 1.0000 - val_loss: 1.0820 - val_acc: 0.9293\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6392e-06 - acc: 1.0000 - val_loss: 1.0859 - val_acc: 0.9307\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.4546e-06 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.9307\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.6860e-06 - acc: 1.0000 - val_loss: 1.0994 - val_acc: 0.9307\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.4240e-06 - acc: 1.0000 - val_loss: 1.1030 - val_acc: 0.9307\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.1290e-06 - acc: 1.0000 - val_loss: 1.1046 - val_acc: 0.9279\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.9608e-06 - acc: 1.0000 - val_loss: 1.1212 - val_acc: 0.9307\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 2.2909e-06 - acc: 1.0000 - val_loss: 1.1257 - val_acc: 0.9307\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.7926e-06 - acc: 1.0000 - val_loss: 1.1266 - val_acc: 0.9293\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.6420e-06 - acc: 1.0000 - val_loss: 1.1340 - val_acc: 0.9293\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.4639e-06 - acc: 1.0000 - val_loss: 1.1367 - val_acc: 0.9293\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.4299e-06 - acc: 1.0000 - val_loss: 1.1454 - val_acc: 0.9293\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.3024e-06 - acc: 1.0000 - val_loss: 1.1524 - val_acc: 0.9293\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3300e-06 - acc: 1.0000 - val_loss: 1.1428 - val_acc: 0.9279\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.2322e-06 - acc: 1.0000 - val_loss: 1.1669 - val_acc: 0.9293\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.0389e-06 - acc: 1.0000 - val_loss: 1.1683 - val_acc: 0.9293\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 9.3941e-07 - acc: 1.0000 - val_loss: 1.1787 - val_acc: 0.9293\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.4052e-07 - acc: 1.0000 - val_loss: 1.1832 - val_acc: 0.9293\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.5127e-07 - acc: 1.0000 - val_loss: 1.1919 - val_acc: 0.9293\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.8152e-07 - acc: 1.0000 - val_loss: 1.1978 - val_acc: 0.9293\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.9787e-07 - acc: 1.0000 - val_loss: 1.1970 - val_acc: 0.9293\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 6.9392e-07 - acc: 1.0000 - val_loss: 1.2001 - val_acc: 0.9293\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.6273e-07 - acc: 1.0000 - val_loss: 1.2136 - val_acc: 0.9293\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 6.5611e-07 - acc: 1.0000 - val_loss: 1.2014 - val_acc: 0.9293\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.2550e-07 - acc: 1.0000 - val_loss: 1.2160 - val_acc: 0.9293\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.3107e-07 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.9293\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 5.0448e-07 - acc: 1.0000 - val_loss: 1.2344 - val_acc: 0.9293\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.6505e-07 - acc: 1.0000 - val_loss: 1.2369 - val_acc: 0.9307\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 4.5059e-07 - acc: 1.0000 - val_loss: 1.2425 - val_acc: 0.9293\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8653e-07 - acc: 1.0000 - val_loss: 1.2496 - val_acc: 0.9307\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.6517e-07 - acc: 1.0000 - val_loss: 1.2565 - val_acc: 0.9307\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.8685e-07 - acc: 1.0000 - val_loss: 1.2570 - val_acc: 0.9307\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 3.5452e-07 - acc: 1.0000 - val_loss: 1.2624 - val_acc: 0.9307\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.2309e-07 - acc: 1.0000 - val_loss: 1.2738 - val_acc: 0.9293\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 3.0478e-07 - acc: 1.0000 - val_loss: 1.2789 - val_acc: 0.9293\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7280e-07 - acc: 1.0000 - val_loss: 1.2861 - val_acc: 0.9293\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.7395e-07 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.9307\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.3274e-07 - acc: 1.0000 - val_loss: 1.2990 - val_acc: 0.9293\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.3803e-07 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.9293\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.5259e-07 - acc: 1.0000 - val_loss: 1.2925 - val_acc: 0.9265\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 2.6776e-07 - acc: 1.0000 - val_loss: 1.3206 - val_acc: 0.9293\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.9615e-07 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.9293\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.8754e-07 - acc: 1.0000 - val_loss: 1.3246 - val_acc: 0.9307\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.7078e-07 - acc: 1.0000 - val_loss: 1.3318 - val_acc: 0.9293\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5356e-07 - acc: 1.0000 - val_loss: 1.3395 - val_acc: 0.9293\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.5513e-07 - acc: 1.0000 - val_loss: 1.3424 - val_acc: 0.9307\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.5000e-07 - acc: 1.0000 - val_loss: 1.3449 - val_acc: 0.9293\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.3742e-07 - acc: 1.0000 - val_loss: 1.3503 - val_acc: 0.9293\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1552e-07 - acc: 1.0000 - val_loss: 1.3618 - val_acc: 0.9293\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.1366e-07 - acc: 1.0000 - val_loss: 1.3622 - val_acc: 0.9293\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 1.1474e-07 - acc: 1.0000 - val_loss: 1.3700 - val_acc: 0.9293\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.0224e-07 - acc: 1.0000 - val_loss: 1.3726 - val_acc: 0.9293\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 8.9364e-08 - acc: 1.0000 - val_loss: 1.3841 - val_acc: 0.9279\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 9.0150e-08 - acc: 1.0000 - val_loss: 1.3907 - val_acc: 0.9279\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 8.3320e-08 - acc: 1.0000 - val_loss: 1.3926 - val_acc: 0.9293\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 7.8685e-08 - acc: 1.0000 - val_loss: 1.4022 - val_acc: 0.9279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TvOoheZWvQF",
        "outputId": "b315e5ee-1366-4338-d936-9e23cff89661"
      },
      "source": [
        "## load model and  evaluate data\n",
        "\n",
        "# model_1 = keras.models.load_model('best_model_1.h5')\n",
        "\n",
        "test_loss, test_acc = model_1.evaluate(x_test, y_test)\n",
        "print(\"測試分類正確率: \", test_acc)\n",
        "print(\"測試資料loss: \", test_loss)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 6ms/step - loss: 0.9282 - acc: 0.9455\n",
            "測試分類正確率:  0.9454545378684998\n",
            "測試資料loss:  0.9281845688819885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ExLfRiGhbuP",
        "outputId": "22fb8228-5dde-4b77-9a04-f809b8c053cd"
      },
      "source": [
        "test_loss, test_acc = model_2.evaluate(x_test, y_test)\n",
        "print(\"測試分類正確率: \", test_acc)\n",
        "print(\"測試資料loss: \", test_loss)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7883 - acc: 0.9530\n",
            "測試分類正確率:  0.9530302882194519\n",
            "測試資料loss:  0.7883424758911133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwfryTwhe1A",
        "outputId": "43e99310-bc1a-41f6-96b4-1e4612a1e9c9"
      },
      "source": [
        "test_loss, test_acc = model_3.evaluate(x_test, y_test)\n",
        "print(\"測試分類正確率: \", test_acc)\n",
        "print(\"測試資料loss: \", test_loss)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 5ms/step - loss: 0.7422 - acc: 0.9492\n",
            "測試分類正確率:  0.9492424130439758\n",
            "測試資料loss:  0.7422130703926086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsPg36vWhgbA",
        "outputId": "c68540c9-2d3c-47d8-a5e9-a9fc07401652"
      },
      "source": [
        "test_loss, test_acc = model_4.evaluate(x_test, y_test)\n",
        "print(\"測試分類正確率: \", test_acc)\n",
        "print(\"測試資料loss: \", test_loss)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 5ms/step - loss: 0.8972 - acc: 0.9455\n",
            "測試分類正確率:  0.9454545378684998\n",
            "測試資料loss:  0.8972229957580566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "AnhiKOqyWzRA",
        "outputId": "8386042b-40d8-434d-cca8-c5efa92ab6c1"
      },
      "source": [
        "## 觀察訓練的情況, 主要針對效果以及overfitting\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history_1.history['acc'])\n",
        "plt.plot(history_1.history['val_acc'])\n",
        "plt.title(\"model acc\")\n",
        "plt.ylabel('acc', fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNkw_1o4XCG8",
        "outputId": "02190156-78ce-4c0f-b770-bea0119ae931"
      },
      "source": [
        "## 論文是透過4個emsemble, 因為初始化問題, 在更穩定一些\n",
        "\n",
        "pred_1 = model_1.predict(x_test)\n",
        "pred_2 = model_2.predict(x_test)\n",
        "pred_3 = model_3.predict(x_test)\n",
        "pred_4 = model_4.predict(x_test)\n",
        "\n",
        "pred = (pred_1 + pred_2 + pred_3 + pred_4) / 4\n",
        "\n",
        "values = keras.metrics.sparse_categorical_accuracy(y_test, pred)   # 給出每一個是否預測正確(1: 正確, 0: 不正確)\n",
        "acc = sum(values) / len(values)\n",
        "print(acc)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.955303, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y5a_IyGcR8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Fake\n",
    "- 學習 Deep fake 原理\n",
    "- 學習如何使用 keras 實做 Deep fake, 試著想出反制方法。\n",
    "- 想一個 Deep fake 應用場景\n",
    "- 產品化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepfake 介紹\n",
    "- 介紹:\n",
    "    - 利用深度學習將人臉交換，通常用於video。\n",
    "    - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *資料處理\n",
    "- 將影片轉化為圖片檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 autoencoder 建立模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T22:29:14.760559Z",
     "start_time": "2021-10-19T22:28:47.687993Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T22:35:21.108792Z",
     "start_time": "2021-10-19T22:35:21.094197Z"
    }
   },
   "outputs": [],
   "source": [
    "# datasets creation and splitting\n",
    "\n",
    "def create_dataset(path):\n",
    "    images = []\n",
    "    for diraname, _, filnames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            image = cv2.imread(os.path.join(dirname, filename))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255.0\n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T22:42:55.898626Z",
     "start_time": "2021-10-19T22:42:55.883053Z"
    }
   },
   "outputs": [],
   "source": [
    "# faces_1 = create_dataset('/kaggle/input/presidentsfacesdataset/trump/')\n",
    "# faces_2 = create_dataset('/kaggle/input/presidentsfacesdataset/biden/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T22:44:46.531723Z",
     "start_time": "2021-10-19T22:44:46.515762Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(faces_1, faces_1, test_size=0.20, random_state=0)\n",
    "# X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(faces_2, faces_2, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:06:14.409811Z",
     "start_time": "2021-10-19T23:06:14.399811Z"
    }
   },
   "outputs": [],
   "source": [
    "# autuencoders 建立\n",
    "\n",
    "def get_encoder():\n",
    "    input_img = layers.Input(shape=(120, 120, 3))\n",
    "    x = layers.Conv2D(256,kernel_size=5, strides=2, padding='same',activation='relu')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(512,kernel_size=5, strides=2, padding='same',activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(1024,kernel_size=5, strides=2, padding='same',activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(3*3*1024)(x)\n",
    "    encoded = layers.Reshape((3,3,1024))(x)\n",
    "    encoder = keras.Model(input_img, encoded,name=\"encoder\")    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:08:37.543505Z",
     "start_time": "2021-10-19T23:08:36.874996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 120, 120, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 60, 60, 256)       19456     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 15, 15, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 1024)        13108224  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9216)              37757952  \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 3, 3, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 54,162,944\n",
      "Trainable params: 54,162,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "# del encoder   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:08:38.406503Z",
     "start_time": "2021-10-19T23:08:37.547503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 3, 3, 1024)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 2, 2, 1024)        26215424  \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 2, 2, 512)         13107712  \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 2, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 43200)             44280000  \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 120, 120, 3)       0         \n",
      "=================================================================\n",
      "Total params: 86,880,192\n",
      "Trainable params: 86,880,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder\n",
    "\n",
    "def get_decoder():\n",
    "    decoder_input= layers.Input(shape=((3,3,1024)))\n",
    "    x = layers.Conv2D(1024,kernel_size=5, strides=2, padding='same',activation='relu')(decoder_input)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(512,kernel_size=5, strides=2, padding='same',activation='relu')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(256,kernel_size=5, strides=2, padding='same',activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(np.prod((120, 120, 3)))(x)\n",
    "    decoded = layers.Reshape((120, 120, 3))(x)\n",
    "    decoder = keras.Model(decoder_input, decoded,name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "decoder = get_decoder()\n",
    "decoder.summary()\n",
    "\n",
    "# del decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:10:32.906069Z",
     "start_time": "2021-10-19T23:10:32.798134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 120, 120, 3)]     0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 3, 3, 1024)        54162944  \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 120, 120, 3)       86880192  \n",
      "=================================================================\n",
      "Total params: 141,043,136\n",
      "Trainable params: 141,043,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aband\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "# 得到一個基本單位的autoencoder, 接下來只要創建2個, 且訓練好即可做swap!\n",
    "\n",
    "def get_autoencoder():\n",
    "    auto_input = layers.Input(shape=(120, 120, 3))\n",
    "    encoded = encoder(auto_input)\n",
    "    decoded = decoder(encoded)\n",
    "    \n",
    "    autoencoder = keras.Model(auto_input, decoded, name='autoencoder')\n",
    "    autoencoder.compile(optimizer=keras.optimizers.Adam(lr=5e-5, beta_1=0.5, beta_2=0.999), loss='mse')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = get_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:22:34.988377Z",
     "start_time": "2021-10-19T23:22:34.981383Z"
    }
   },
   "outputs": [],
   "source": [
    "# swapping encoder and decoders in Keras\n",
    "\n",
    "\n",
    "# # TO LOAD ONLY THE ENCODER A\n",
    "# encoder_a = keras.Model(autoencoder_a.layers[1].input, autoencoder_a.layers[1].output)\n",
    "# # TO LOAD ONLY THE DECODER A\n",
    "# decoder_a = keras.Model(autoencoder_a.layers[2].input, autoencoder_a.layers[2].output)\n",
    "# # TO LOAD ONLY THE ENCODER B\n",
    "# encoder_b = keras.Model(autoencoder_b.layers[1].input, autoencoder_b.layers[1].output)\n",
    "# # TO LOAD ONLY THE DECODER B\n",
    "# decoder_b = keras.Model(autoencoder_b.layers[2].input, autoencoder_b.layers[2].output)\n",
    " \n",
    "# # TO TRANSFORM SRC IMAGES\n",
    "# input_test = encoder_a.predict(np.array([X_test_a[30]]))\n",
    "# output_test = decoder_b.predict(input_test)\n",
    " \n",
    "# # TO TRANSFORM DST IMAGES\n",
    "# input_test = encoder_b.predict(np.array([X_test_b[30]]))\n",
    "# output_test = decoder_a.predict(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit6893c7013b164b1189a865dcaea9fb2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

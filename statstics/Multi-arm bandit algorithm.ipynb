{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Multi-Armed Bandit (MAB) 演算法](https://vwo.com/blog/multi-armed-bandit-algorithm/)\n",
    "定義：一種檢驗方法，常用於網站測試。對比於傳統的統計學實驗設計方法，可以更快速的做出決策，尤其針對有多種策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:11:46.535754Z",
     "start_time": "2021-10-09T04:11:46.515758Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:17:27.307136Z",
     "start_time": "2021-10-09T04:17:27.287137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15175389894853386\n",
      "[('C', 0.5), ('A', 0.3), ('B', 0.2)]\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# 隨機產生一個數(均勻分配)\n",
    "# a = np.random.rand()\n",
    "a = random.random()\n",
    "print(a)\n",
    "\n",
    "# 將策略按照機率排序\n",
    "strategy = {'A': 0.3, 'B': 0.2, 'C': 0.5}\n",
    "max_strategy = sorted(strategy.items(), key=lambda x: x[1], reverse=True)\n",
    "print(max_strategy)\n",
    "\n",
    "# 透過策略機率產生選項\n",
    "s = random.choices(population=list(strategy.keys()), weights=strategy.values(), k=1)[0]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:18:13.036600Z",
     "start_time": "2021-10-09T04:18:12.964307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 2964, 'B': 1976, 'C': 5060}\n"
     ]
    }
   ],
   "source": [
    "# 測試是否真的按照機率\n",
    "d = {'A': 0, 'B': 0, 'C': 0}\n",
    "for i in range(10000):\n",
    "    s = random.choices(population=list(strategy.keys()), weights=strategy.values(), k=1)[0]\n",
    "    d[s] += 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:16:48.355439Z",
     "start_time": "2021-10-09T04:16:48.346440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5592206228739368"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:21:38.011343Z",
     "start_time": "2021-10-09T04:21:37.988341Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def multi_arm_bandit(strategy: dict, epsilon: float):\n",
    "    \"\"\"\n",
    "        (epsilon-greedy algorith)版本: \n",
    "            意義:\n",
    "                改善了抽樣過程，加入了在實驗過程中學到的資訊，減少非最優處理的機率。\n",
    "                其中 epsilon 為超參數可控制。\n",
    "            步驟:\n",
    "                1. 產生一個介於0~1 之間的隨機數 a\n",
    "                2. 如果 a 若再 0 ~ epsilon 之間，則產生一個隨機數 b ，\n",
    "                    根據策略的不同範圍決定這次要 **使用** 哪一個策略。\n",
    "                3. 如果 a >= epsilon，則顯示目前為止 **使用** 機率最高的策略。\n",
    "            \n",
    "    \"\"\"\n",
    "    max_strategy = sorted(strategy.items(), key=lambda x: x[1], reverse=True)[0][0] # [('C', 0.5), ('A', 0.3), ('B', 0.2)]\n",
    "    a = random.random()\n",
    "    \n",
    "    if a < epsilon:\n",
    "        return max_strategy\n",
    "    else:\n",
    "        s = random.choices(population=list(strategy.keys()), weights=strategy.values(), k=1)[0]\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T04:21:10.796159Z",
     "start_time": "2021-10-09T04:21:10.777157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_arm_bandit(strategy, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit6893c7013b164b1189a865dcaea9fb2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

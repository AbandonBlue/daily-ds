{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複習一些過往的code並慢慢整理自己的codebase，並且養成每日寫data science code的習慣!\n",
    "\n",
    "## 目標: 將過往code文件化、模組化，使其重複使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:25:31.119502Z",
     "start_time": "2022-11-06T10:25:12.978733Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import jieba\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day27 - Designing ML System(ch4), handling the lack of labels\n",
    "- **Weak Supervision**: 透過Label function，使用Heuristic 方式產生標籤資料。\n",
    "- Semi-supervision\n",
    "- Transfer Learning\n",
    "- Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立 Label Function(Programmatic labeling) 去建立標籤資料！其中的精神在於比起人工標籤，一樣有專家精神，且可以擴充！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:41:43.924115Z",
     "start_time": "2022-11-06T10:41:43.894087Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    假設是一個惡意留言檢測模型。\n",
    "\"\"\"\n",
    "\n",
    "def lf_has_fuck(data):\n",
    "    if 'fuck' in data:\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "def lf_has_bastard(data):\n",
    "    if 'bastard' in data:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "class ProgrammaticLabel():\n",
    "    def __init__(self, lfs):\n",
    "        \"\"\"\n",
    "            ProgrammatcLabeling 的實踐。\n",
    "        \"\"\"\n",
    "        self.lfs = lfs\n",
    "    \n",
    "    def label(self, data):\n",
    "        \"\"\"\n",
    "            還尚未完善，可能是透過投票或者滿足任一。\n",
    "        \"\"\"\n",
    "        if type(data) == type([]):\n",
    "            labels = []\n",
    "            for row_data in data:\n",
    "                for lf in self.lfs:\n",
    "                    label = lf(row_data)\n",
    "                    if label:\n",
    "                        labels.append(label)\n",
    "                        break\n",
    "                else:\n",
    "                    labels.append(label)\n",
    "            return labels\n",
    "                    \n",
    "        else:\n",
    "            for lf in self.lfs:\n",
    "                label = lf(data)\n",
    "                if label: return [label]\n",
    "            return [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:41:44.266529Z",
     "start_time": "2022-11-06T10:41:44.253599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\n",
    "    \"You are such a bastard. I don't wanna talk to anymore.\",\n",
    "    \"It's beatiful day. I wanna go outside and have fun.\",\n",
    "    \"Fuck!!!!!!!!!! Today is fucking crazy!!!!!\"\n",
    "]\n",
    "        \n",
    "labeler = ProgrammaticLabel([lf_has_bastard, lf_has_fuck])\n",
    "\n",
    "labeler.label(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-06T10:41:44.684337Z",
     "start_time": "2022-11-06T10:41:44.663802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Chill day!\"\n",
    "labeler.label(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day28 - Designing ML System(ch4), handling the lack of labels\n",
    "- Weak Supervision\n",
    "- **Semi-supervision**: 透過有限、少量的標籤資料當作初始，進而訓練模型，再在無標籤資料上進行預測，當做新的標籤資料。\n",
    "- Transfer Learning\n",
    "- Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用完整訓練資料(50000)\n",
    "2. 使用部分訓練資料(25000)+Semi-supervision(25000)\n",
    "3. 使用部分訓練資料(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:50:25.025310Z",
     "start_time": "2022-11-07T11:50:24.866311Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:49:28.048077Z",
     "start_time": "2022-11-07T11:49:26.575440Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:49:43.796933Z",
     "start_time": "2022-11-07T11:49:43.787943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:51:30.690626Z",
     "start_time": "2022-11-07T11:51:30.596636Z"
    }
   },
   "outputs": [],
   "source": [
    "# 切分資料\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.5, random_state=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:51:44.173925Z",
     "start_time": "2022-11-07T11:51:44.162922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 32, 32, 3), (25000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:53:04.979530Z",
     "start_time": "2022-11-07T11:53:04.471415Z"
    }
   },
   "outputs": [],
   "source": [
    "# 標準化資料\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T12:12:05.628008Z",
     "start_time": "2022-11-07T12:12:05.612014Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義模型\n",
    "\n",
    "def get_cnn_model(name):\n",
    "    \"\"\"\n",
    "        簡單驗證用。\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=2, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(units=10, activation='softmax')(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T12:12:09.468629Z",
     "start_time": "2022-11-07T12:12:09.464627Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T12:18:19.338486Z",
     "start_time": "2022-11-07T12:12:11.827471Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_ds\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 16)        208       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,498\n",
      "Trainable params: 11,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 36s 22ms/step - loss: 1.6175 - acc: 0.4247 - val_loss: 1.4021 - val_acc: 0.5028\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3429 - acc: 0.5294 - val_loss: 1.2912 - val_acc: 0.5462\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.2471 - acc: 0.5642 - val_loss: 1.2211 - val_acc: 0.5702\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.1766 - acc: 0.5911 - val_loss: 1.1499 - val_acc: 0.5941\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 1.1265 - acc: 0.6055 - val_loss: 1.1234 - val_acc: 0.6058\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0826 - acc: 0.6228 - val_loss: 1.0978 - val_acc: 0.6121\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0477 - acc: 0.6344 - val_loss: 1.0773 - val_acc: 0.6215\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.0232 - acc: 0.6455 - val_loss: 1.0650 - val_acc: 0.6277\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.9977 - acc: 0.6542 - val_loss: 1.0783 - val_acc: 0.6319\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.9837 - acc: 0.6590 - val_loss: 1.0201 - val_acc: 0.6461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23abba21748>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 全部資料\n",
    "\n",
    "full_ds_model = get_cnn_model('full_ds')\n",
    "full_ds_model.summary()\n",
    "full_ds_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "full_ds_model.fit(\n",
    "    np.concatenate([x_train, x_val], axis=0), \n",
    "    np.concatenate([y_train, y_val], axis=0), \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T12:42:25.209379Z",
     "start_time": "2022-11-07T12:38:59.415957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"semi-supervised\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 16)        208       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,498\n",
      "Trainable params: 11,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 1.8294 - acc: 0.3483 - val_loss: 1.5658 - val_acc: 0.4515\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 1.5147 - acc: 0.4632 - val_loss: 1.4289 - val_acc: 0.4978\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 1.3880 - acc: 0.5146 - val_loss: 1.3561 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 1.2908 - acc: 0.5502 - val_loss: 1.2567 - val_acc: 0.5561\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.2247 - acc: 0.5764 - val_loss: 1.2167 - val_acc: 0.5705\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.1762 - acc: 0.5909 - val_loss: 1.2012 - val_acc: 0.5749\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 1.1386 - acc: 0.6047 - val_loss: 1.1700 - val_acc: 0.5902\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 37s 48ms/step - loss: 1.1083 - acc: 0.6135 - val_loss: 1.1579 - val_acc: 0.5933\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 31s 40ms/step - loss: 1.0767 - acc: 0.6284 - val_loss: 1.1416 - val_acc: 0.5993\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 1.0588 - acc: 0.6317 - val_loss: 1.1431 - val_acc: 0.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23abdf875f8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 部分資料+semi-supervised(過程可以更精緻，比如是迭代產生新標籤，目前利用的是最差的)\n",
    "\n",
    "\n",
    "semi_model = get_cnn_model('semi-supervised')\n",
    "semi_model.summary()\n",
    "semi_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "semi_model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T12:47:22.382502Z",
     "start_time": "2022-11-07T12:42:25.218380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7894 - acc: 0.7517 - val_loss: 1.1918 - val_acc: 0.6105\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 0.7625 - acc: 0.7604 - val_loss: 1.2079 - val_acc: 0.6074\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7463 - acc: 0.7658 - val_loss: 1.2257 - val_acc: 0.6138\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7362 - acc: 0.7678 - val_loss: 1.2226 - val_acc: 0.6139\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7278 - acc: 0.7703 - val_loss: 1.2418 - val_acc: 0.6117\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7224 - acc: 0.7697 - val_loss: 1.2159 - val_acc: 0.6172\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7165 - acc: 0.7723 - val_loss: 1.2421 - val_acc: 0.6153\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7108 - acc: 0.7748 - val_loss: 1.2760 - val_acc: 0.6075\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7085 - acc: 0.7742 - val_loss: 1.2255 - val_acc: 0.6172\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7033 - acc: 0.7746 - val_loss: 1.2208 - val_acc: 0.6195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23abe056080>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_semi = np.argmax(semi_model.predict(x_val), axis=1)\n",
    "\n",
    "\n",
    "semi_model.fit(\n",
    "    np.concatenate([x_train, x_val], axis=0), \n",
    "    np.concatenate([y_train, y_val_semi.reshape(-1, 1)], axis=0),\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:41:47.536210Z",
     "start_time": "2022-11-08T12:39:38.836997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"part_of_ds\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 32, 32, 16)        208       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,498\n",
      "Trainable params: 11,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 12s 14ms/step - loss: 1.7363 - acc: 0.3792 - val_loss: 1.4955 - val_acc: 0.4657\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.4487 - acc: 0.4877 - val_loss: 1.3786 - val_acc: 0.5135\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.3519 - acc: 0.5248 - val_loss: 1.3232 - val_acc: 0.5268\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.2824 - acc: 0.5491 - val_loss: 1.2885 - val_acc: 0.5405\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 1.2276 - acc: 0.5714 - val_loss: 1.2526 - val_acc: 0.5560\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.1829 - acc: 0.5846 - val_loss: 1.2052 - val_acc: 0.5762\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 1.1431 - acc: 0.6007 - val_loss: 1.1793 - val_acc: 0.5865\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 1.1080 - acc: 0.6172 - val_loss: 1.1849 - val_acc: 0.5825\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.0775 - acc: 0.6259 - val_loss: 1.1607 - val_acc: 0.5975\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 1.0554 - acc: 0.6340 - val_loss: 1.1656 - val_acc: 0.5913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ac129aa20>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 部分資料\n",
    "\n",
    "\n",
    "part_of_ds_model = get_cnn_model('part_of_ds')\n",
    "part_of_ds_model.summary()\n",
    "part_of_ds_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "part_of_ds_model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day29 - Designing ML System(ch4), handling the lack of labels\n",
    "- Weak Supervision\n",
    "- Semi-supervision\n",
    "- Transfer Learning\n",
    "- **Active Learning**: 透過改善標籤品質的效率，去減少需要的資料，比如分類模型最不確定答案的資料、或者多個不同參數模型容易出錯的資料等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 分出訓練、測試資料\n",
    "2. 訓練模型，然後預測測試資料，從中挑選預測信心最小的，也就是最大的類別也很大的那種，當作active learning標籤\n",
    "3. 將其標籤，然後丟入訓練資料一起重新訓練 vs 隨機選擇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:42:55.303180Z",
     "start_time": "2022-11-08T12:42:55.288186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 32, 32, 3), (25000, 32, 32, 3))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 分出訓練、測試資料\n",
    "\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:43:58.065051Z",
     "start_time": "2022-11-08T12:43:53.920085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 2. 直接用Day28的模型來用\n",
    "\n",
    "y_val_predicted = part_of_ds_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:51:45.879946Z",
     "start_time": "2022-11-08T12:51:45.782951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_the_most_uncertain(y, top_k=10000):\n",
    "    return np.argsort(y.min(axis=1))[-top_k:] # 由小到大排序\n",
    "\n",
    "\n",
    "# 取得最不確定的前10000筆\n",
    "val_indices = get_the_most_uncertain(y_val_predicted)\n",
    "x_new_label_by_active_learning = x_val[val_indices]\n",
    "y_new_label_by_active_learning = y_val[val_indices]\n",
    "\n",
    "print(x_new_label_by_active_learning.shape, y_new_label_by_active_learning.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T13:10:45.618230Z",
     "start_time": "2022-11-08T13:04:01.075286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.7416 - acc: 0.3828 - val_loss: 1.4133 - val_acc: 0.5145\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 25s 23ms/step - loss: 1.4447 - acc: 0.4938 - val_loss: 1.2991 - val_acc: 0.5435\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 22s 20ms/step - loss: 1.3471 - acc: 0.5305 - val_loss: 1.2467 - val_acc: 0.5627\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 26s 24ms/step - loss: 1.2901 - acc: 0.5499 - val_loss: 1.1937 - val_acc: 0.5844\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 21s 20ms/step - loss: 1.2437 - acc: 0.5672 - val_loss: 1.1883 - val_acc: 0.5815\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 21s 19ms/step - loss: 1.2060 - acc: 0.5819 - val_loss: 1.1410 - val_acc: 0.6025\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 21s 19ms/step - loss: 1.1701 - acc: 0.5965 - val_loss: 1.1514 - val_acc: 0.5941\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 22s 20ms/step - loss: 1.1388 - acc: 0.6039 - val_loss: 1.0995 - val_acc: 0.6139\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 24s 22ms/step - loss: 1.1103 - acc: 0.6170 - val_loss: 1.0857 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1094/1094 [==============================] - 22s 20ms/step - loss: 1.0897 - acc: 0.6220 - val_loss: 1.0828 - val_acc: 0.6192\n",
      "Epoch 11/20\n",
      "1094/1094 [==============================] - 21s 19ms/step - loss: 1.0738 - acc: 0.6273 - val_loss: 1.0634 - val_acc: 0.6310\n",
      "Epoch 12/20\n",
      "1094/1094 [==============================] - 19s 18ms/step - loss: 1.0572 - acc: 0.6343 - val_loss: 1.0693 - val_acc: 0.6274\n",
      "Epoch 13/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 1.0424 - acc: 0.6391 - val_loss: 1.0899 - val_acc: 0.6211\n",
      "Epoch 14/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.0286 - acc: 0.6447 - val_loss: 1.0519 - val_acc: 0.6313\n",
      "Epoch 15/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.0201 - acc: 0.6466 - val_loss: 1.0529 - val_acc: 0.6350\n",
      "Epoch 16/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.0070 - acc: 0.6504 - val_loss: 1.0636 - val_acc: 0.6316\n",
      "Epoch 17/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9982 - acc: 0.6537 - val_loss: 1.0558 - val_acc: 0.6341\n",
      "Epoch 18/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 0.9891 - acc: 0.6566 - val_loss: 1.0342 - val_acc: 0.6425\n",
      "Epoch 19/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9805 - acc: 0.6617 - val_loss: 1.0291 - val_acc: 0.6420\n",
      "Epoch 20/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9758 - acc: 0.6631 - val_loss: 1.0250 - val_acc: 0.6468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ac5fc3e48>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 將其標籤，然後丟入訓練資料一起重新訓練 vs 隨機選擇\n",
    "\n",
    "\n",
    "x_train_active_learning = np.concatenate([x_train, x_new_label_by_active_learning])\n",
    "y_train_active_learning = np.concatenate([y_train, y_new_label_by_active_learning])\n",
    "\n",
    "\n",
    "active_model = get_cnn_model('active_model')\n",
    "# active_model.summary()\n",
    "active_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "active_model.fit(\n",
    "    x_train_active_learning, \n",
    "    y_train_active_learning, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs*2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T13:17:04.548972Z",
     "start_time": "2022-11-08T13:10:45.627231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 21s 19ms/step - loss: 1.6639 - acc: 0.4114 - val_loss: 1.3936 - val_acc: 0.5101\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 19s 18ms/step - loss: 1.3337 - acc: 0.5333 - val_loss: 1.2698 - val_acc: 0.5584\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - loss: 1.2344 - acc: 0.5694 - val_loss: 1.2192 - val_acc: 0.5705\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 19s 18ms/step - loss: 1.1720 - acc: 0.5894 - val_loss: 1.1899 - val_acc: 0.5957\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.1310 - acc: 0.6071 - val_loss: 1.1549 - val_acc: 0.6025\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - loss: 1.0961 - acc: 0.6184 - val_loss: 1.1121 - val_acc: 0.6080\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - loss: 1.0699 - acc: 0.6286 - val_loss: 1.1182 - val_acc: 0.6142\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 19s 17ms/step - loss: 1.0442 - acc: 0.6382 - val_loss: 1.1048 - val_acc: 0.6155\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.0270 - acc: 0.6426 - val_loss: 1.0977 - val_acc: 0.6231\n",
      "Epoch 10/20\n",
      "1094/1094 [==============================] - 18s 16ms/step - loss: 1.0084 - acc: 0.6477 - val_loss: 1.0658 - val_acc: 0.6251\n",
      "Epoch 11/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9923 - acc: 0.6533 - val_loss: 1.0612 - val_acc: 0.6344\n",
      "Epoch 12/20\n",
      "1094/1094 [==============================] - 16s 15ms/step - loss: 0.9784 - acc: 0.6586 - val_loss: 1.0446 - val_acc: 0.6372\n",
      "Epoch 13/20\n",
      "1094/1094 [==============================] - 17s 15ms/step - loss: 0.9636 - acc: 0.6639 - val_loss: 1.0613 - val_acc: 0.6349\n",
      "Epoch 14/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9563 - acc: 0.6675 - val_loss: 1.0723 - val_acc: 0.6269\n",
      "Epoch 15/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9471 - acc: 0.6679 - val_loss: 1.0409 - val_acc: 0.6428\n",
      "Epoch 16/20\n",
      "1094/1094 [==============================] - 19s 17ms/step - loss: 0.9327 - acc: 0.6751 - val_loss: 1.0239 - val_acc: 0.6444\n",
      "Epoch 17/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - loss: 0.9246 - acc: 0.6791 - val_loss: 1.0328 - val_acc: 0.6464\n",
      "Epoch 18/20\n",
      "1094/1094 [==============================] - 20s 18ms/step - loss: 0.9165 - acc: 0.6818 - val_loss: 1.0311 - val_acc: 0.6415\n",
      "Epoch 19/20\n",
      "1094/1094 [==============================] - 18s 17ms/step - loss: 0.9053 - acc: 0.6860 - val_loss: 1.0233 - val_acc: 0.6457\n",
      "Epoch 20/20\n",
      "1094/1094 [==============================] - 17s 16ms/step - loss: 0.9012 - acc: 0.6862 - val_loss: 1.0183 - val_acc: 0.6520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ac610a400>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機選擇\n",
    "_, x_val_random, _, y_val_random = train_test_split(x_val, y_val, test_size=0.5, random_state=222)\n",
    "\n",
    "x_val_random = x_val_random[:10000]\n",
    "y_val_random = y_val_random[:10000]\n",
    "\n",
    "x_train_random = np.concatenate([x_train, x_val_random])\n",
    "y_train_random = np.concatenate([y_train, y_val_random])\n",
    "\n",
    "\n",
    "random_model = get_cnn_model('random_model')\n",
    "random_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "random_model.fit(\n",
    "    x_train_random, \n",
    "    y_train_random, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs*2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上雖然只是一次嘗試，不太嚴謹，但可以看到大致上，active learning 產生標籤的方式可以讓模型在相同標籤下，學到的模型表現更佳。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day30 - Designing ML System(ch4), class imbalance\n",
    "1. Use the right metric to evaluate: like precision, recall, f1-score and more.\n",
    "2. Data-level method: like SMOTE and more data-aug method.\n",
    "3. Algorithm-level method: use the loss function to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day31 - Designing ML System(ch4), Data-augmentation\n",
    "1. **Single-label preserving**:\n",
    "    - CV: 翻轉等等操作\n",
    "    - NLP: 找到同義詞替代\n",
    "2. Perturbation\n",
    "3. Data Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T14:48:42.612181Z",
     "start_time": "2022-11-10T14:48:39.589937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\n",
      "plan\n",
      "a series of steps to be carried out or goals to be accomplished\n",
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "# 1. Single-label preserving: NLP\n",
    "import nltk\n",
    "\n",
    "\n",
    "# First, you're going to need to import wordnet:\n",
    "from nltk.corpus import wordnet\n",
    "  \n",
    "# Then, we're going to use the term \"program\" to find synsets like so:\n",
    "syns = wordnet.synsets(\"program\")\n",
    "  \n",
    "# An example of a synset:\n",
    "print(syns[0].name())\n",
    "  \n",
    "# Just the word:\n",
    "print(syns[0].lemmas()[0].name())\n",
    "  \n",
    "# Definition of that first synset:\n",
    "print(syns[0].definition())\n",
    "  \n",
    "# Examples of the word in use in sentences:\n",
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T14:51:22.929301Z",
     "start_time": "2022-11-10T14:51:22.915919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day32 - Designing ML System(ch4), Data-augmentation\n",
    "1. Single-label preserving:\n",
    "    - CV: 翻轉等等操作\n",
    "    - NLP: 找到同義詞替代\n",
    "2. **Perturbation**: 透過擾動\n",
    "3. Data Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T16:51:47.982243Z",
     "start_time": "2022-11-11T16:51:47.963243Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用 BERT MLM 去做\n",
    "\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import BertTokenizer, TFBertModel, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T17:02:35.190618Z",
     "start_time": "2022-11-11T17:02:23.211418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mlm = TFBertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "# 資料科學涉及程式開發、數學、統計、機器學習以及領域知識，是目前很火紅的領域！\n",
    "inputs = tokenizer(\"[MASK]料科學涉及程式開發、數學、統計、[MASK]器學習以及領域知識，是目前很火紅的領域！\", return_tensors=\"tf\")\n",
    "inputs[\"label\"] = tokenizer(\"資料科學涉及程式開發、數學、統計、機器學習以及領域知識，是目前很火紅的領域！\", return_tensors=\"tf\")[\"input_ids\"]\n",
    "outputs = mlm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T17:02:38.002511Z",
     "start_time": "2022-11-11T17:02:37.978519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 40), dtype=int32, numpy=\n",
      "array([[ 101,  103, 3160, 4906, 2119, 3868, 1350, 4923, 2466, 7274, 4634,\n",
      "         510, 3149, 2119,  510, 5186, 6243,  510,  103, 1690, 2119, 5424,\n",
      "         809, 1350, 7526, 1818, 4761, 6352, 8024, 3221, 4680, 1184, 2523,\n",
      "        4125, 5148, 4638, 7526, 1818, 8013,  102]])>, 'token_type_ids': <tf.Tensor: shape=(1, 40), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 40), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>, 'label': <tf.Tensor: shape=(1, 40), dtype=int32, numpy=\n",
      "array([[ 101, 6536, 3160, 4906, 2119, 3868, 1350, 4923, 2466, 7274, 4634,\n",
      "         510, 3149, 2119,  510, 5186, 6243,  510, 3582, 1690, 2119, 5424,\n",
      "         809, 1350, 7526, 1818, 4761, 6352, 8024, 3221, 4680, 1184, 2523,\n",
      "        4125, 5148, 4638, 7526, 1818, 8013,  102]])>}\n",
      "\n",
      "TFMaskedLMOutput(loss=None, logits=<tf.Tensor: shape=(1, 40, 21128), dtype=float32, numpy=\n",
      "array([[[ -8.194936 ,  -8.188677 ,  -8.2302475, ...,  -7.314594 ,\n",
      "          -7.5289955,  -7.516975 ],\n",
      "        [-12.622639 , -12.048158 , -12.810743 , ...,  -9.61366  ,\n",
      "         -11.88516  , -11.776322 ],\n",
      "        [-10.551324 , -10.688338 , -10.402301 , ...,  -9.451062 ,\n",
      "         -10.049694 ,  -6.6133513],\n",
      "        ...,\n",
      "        [-13.929754 , -15.854769 , -15.094104 , ..., -11.281798 ,\n",
      "         -14.726072 , -17.975765 ],\n",
      "        [-10.756553 , -11.06151  , -10.9729185, ...,  -7.4358554,\n",
      "          -8.307789 ,  -8.203906 ],\n",
      "        [-10.283023 , -10.416541 , -10.480475 , ...,  -7.2778997,\n",
      "          -9.478504 ,  -8.979976 ]]], dtype=float32)>, hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print()\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T17:08:51.086595Z",
     "start_time": "2022-11-11T17:08:51.064595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "，/資/料/科/學/涉/及/程/式/開/發/、/數/學/、/統/計/、/機/器/學/習/以/及/領/域/知/識/，/是/目/前/很/火/紅/的/領/域/！/料/"
     ]
    }
   ],
   "source": [
    "# 找到最可能的結果\n",
    "import numpy as np\n",
    "\n",
    "for id_ in np.argmax(outputs['logits'], axis=-1)[0]:\n",
    "    #print(id_)\n",
    "    print(tokenizer.decode(token_ids=int(id_)), end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T17:16:47.781355Z",
     "start_time": "2022-11-11T17:16:47.767355Z"
    }
   },
   "outputs": [],
   "source": [
    "# 隨機擾動字\n",
    "import random\n",
    "\n",
    "sentence = '資料科學涉及程式開發、數學、統計、機器學習以及領域知識，是目前很火紅的領域！'\n",
    "\n",
    "\n",
    "def get_random_mlm_sentence(sentence):\n",
    "    length = len(sentence)\n",
    "    idx = random.randint(0, length)\n",
    "    sent = list(sentence)\n",
    "    sent[idx] = '[MASK]'\n",
    "    sent = ''.join(sent)\n",
    "    print(sent)\n",
    "    \n",
    "    inputs = tokenizer(sent, return_tensors='tf')\n",
    "    inputs['label'] = tokenizer(sentence, return_tensors='tf')['input_ids']\n",
    "    outputs = mlm(inputs)\n",
    "    \n",
    "    out_sentence = []\n",
    "    for id_ in np.argmax(outputs['logits'], axis=-1)[0]:\n",
    "        #print(id_)\n",
    "        word = tokenizer.decode(token_ids=int(id_))\n",
    "        out_sentence.append(word)\n",
    "    \n",
    "    return ''.join(out_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T17:17:39.256363Z",
     "start_time": "2022-11-11T17:17:38.857368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料科學涉及程式開發、數學、統計、機器學習以及領域知識，是目前很[MASK]紅的領域！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'，資料科學涉及程式開發、數學、統計、機器學習以及領域知識，是目前很火紅的領域！的'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_mlm_sentence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "發現頭跟尾巴有點問題，要想一下怎麼解決。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
